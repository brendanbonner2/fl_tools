
    <html>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <link rel="stylesheet" type="css" href="styles/latex.css">
    <body>
    <h1>Machine Learning</h1><p style="page-break-before: always"><h2>1.1&emsp;Welcome to the course</h2><div class="u-typography-bold-intro">
<p>Hello everybody and welcome to CA684 Machine Learning, ‘Data Representation and Feature Engineering’. This course is the first in a series of five courses under the Dublin City University Machine Learning series.</p>
<p>Your lead educator is Professor Tomás Ward who is the AIB chair of Data Analytics in the School of Computing at Dublin City University. His research lies in the application of machine learning to sensors for the purposes of tracking human health, performance and decision making in the real world.</p>
<p>In this course you are going to learn about machine learning, which is a very exciting branch of artificial intelligence.</p>
<p>I am sure you are well aware of how artificial intelligence is transforming our world in many positive ways. Machine Learning is a branch of AI which is arguably having the most impact. From speech recognition to driverless vehicles, from music recommendation to medical diagnosis, machine learning is improving our lives everyday. Who would not want to know more about this field, its basic principles and how to apply it to a wide range of problems?</p>
<p>In this program we are concerned with the development of algorithms which learn from data. In essence that is what machine learning is. We are going to look at basic principles, examine some well-known algorithms and develop some practical skills that we will apply to tackle a real world research challenge that I hope you will find interesting and exciting.</p>
<p>This is a fast moving, exciting field which attracts some of the most innovative scientists and engineers in the world – so let’s just jump in!</p>
<p>There are five courses in the Machine learning program:</p>
<ul>
<li>
<p><strong>Introduction, Data Representation and Feature Engineering</strong> which deals with taking data from the real world and arranging it in different ways to facilitate computers learning from this data.</p>
</li>
<li>
<p><strong>Bayesian and Information Based Learning.</strong> This section deals with some introductory machine learning algorithms which are useful for beginners. We also learn some practical implementation skills here.</p>
</li>
<li>
<p><strong>Error Based Learning and Ensemble Approaches.</strong> Here we introduce further machine learning methods, but perhaps the most useful is the idea that we can combine a number of machine learning methods to produce superior performance in many situations.</p>
</li>
<li>
<p><strong>Similarity Based Measures and Machine Learning Evaluation Metrics.</strong> In this section we add more machine learning methods to our repertoire but more importantly we spend some time thinking about how best to evaluate our machine learning models.</p>
</li>
<li>
<p><strong>Neural Networks and Reinforcement Learning.</strong> In this final section we learn about some exciting machine learning methods that my researchers and I use a lot in our own work. The ideas here are loosely modelled on aspects of biological intelligence found in human brains.</p>
</li>
</ul>
<h3 id="moving-through-the-course">Moving through the course</h3>
<p><em>We suggest that you complete 2 weeks of content on the FutureLearn platform per 1 academic week. This should support your progression through the course.</em></p>
<h3 id="comments-online">Comments online</h3>
<p>There are no lectures, so the comments facility is of huge importance. This is the place where you interact with your lead educator, and equally importantly, with your fellow students. There will be many opportunities for you to reflect on your learning and engage in conversations with other learners. We encourage you to use these sessions to ask questions, respond to other learners and to help each other. We look forward to finding out your opinions in the comments section at the end of many of the steps. The lead educator will be monitoring your comments and will drop in regularly to answer any queries you may have.</p>
<h3 id="next-step">Next step</h3>
<p>Click forward to the next step in the course.</p>
<p>The FutureLearn site keeps track of which step you are on, so when you return you see how far you have got.</p>
<p>So let’s get started!</p>
<p><img alt="Statement of funding from Skillnet Ireland stating that this course has been grant aided by Skillnet Ireland" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/14/0b/hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/14/0b/small_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 320w, https://ugc.futurelearn.com/uploads/assets/14/0b/hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 648w, https://ugc.futurelearn.com/uploads/assets/14/0b/large_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 729w, https://ugc.futurelearn.com/uploads/assets/14/0b/large_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 2x"/></p>
<div class="video_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.2&emsp;Assessment details</h2><div class="u-typography-bold-intro">
<p>Module CA684 Machine Learning is assessed through continuous assessment and a written exam.</p>
<h3 id="continuous-assessment">Continuous assessment</h3>
<ul>
<li>The continuous assessment portion of your module will account for <strong>25%</strong> of the overall module mark and is comprised of <strong>one practical</strong>.</li>
</ul>
<p>Details about this assessment will be released during topic 4 of the second course in this program, <strong>Bayesian and Information Based Learning</strong>.</p>
<p>The following table gives important information about your practical.</p>
<table>
<thead>
<tr>
<th><strong>Assignment Section Title and Topic</strong></th>
<th><strong>Assignment Release Date</strong></th>
<th><strong>Assignment Submission Deadline</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Course 2: Bayesian and Information Based Learning</strong>: Topic 4</td>
<td>10 February 2020</td>
<td>27 April 2020</td>
</tr>
</tbody>
</table>
<h3 id="written-exam">Written exam</h3>
<p>Your written exam will account for 75% of the module mark.</p>
<p><em>Note</em>: Throughout this program, you will be asked to complete a number of coding exercises after many of the steps. These will not form part of your final mark but I will be dropping in to the comments to discuss the exercises with all of you as you try them.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.3&emsp;Getting started</h2><div class="u-typography-bold-intro">
<p>If this is the first course you are starting on FutureLearn, you might need some basic introduction to the platform.</p>
<p>You may find it useful to go through this <a href="https://www.futurelearn.com/using-futurelearn">Using FutureLearn</a> guide and read this <a href="https://about.futurelearn.com/blog/in-course-navigation">FutureLearn blog post</a> explaining the in-course navigation.</p>
<h3 id="social-learning---discussions-and-peer-support">Social Learning - Discussions and Peer Support</h3>
<p>FutureLearn believes in the power of learning through conversation. Learners can leave comments and have a conversation on every step of a course - just click on the pink plus symbol (+) to open the comments area. You’ll also notice Discussion steps - they offer a more structured dialogue on important topics.
We encourage you to ask questions, leave comments and participate in discussions.</p>
<h3 id="basic-rules--of--online-communication">Basic rules  of  online communication</h3>
<ul>
<li>Leave comments, no essays (unless you are asked to write an essay!). Comments should be brief and to the point.</li>
<li>Remember that not all learners are native English speakers. Explain any acronyms you use and try to avoid jargon.</li>
<li>
<p>Be polite when you disagree with others. If you have to argue a point, make sure it is the idea, not the person you are criticising. Remember that other learners come from different cultures and backgrounds; they are of different age and experience. When posting comments, please remember that these will be visible to all the learners registered on the course. Make sure you only share information that you would be happy to be publicly visible. Don’t say anything that you wouldn’t say in person.</p>
</li>
<li>There is an option to report messages and users that are not adhering to the basic rules of online communication. If you find offensive content click the ‘<strong>Report</strong>’ flag icon. FutureLearn moderators will review it and remove if the comment is in breach of rules.</li>
</ul>
<h3 id="additional-resources">Additional Resources</h3>
<p>From time to time you might see two additional sections at the end of the step - <strong>Downloads</strong> and <strong>See also</strong>.</p>
<p><strong>Downloads</strong> are usually PDFs and are provided to help your learning. They might include transcripts, extracts, articles and information sheets that you may want to save for future reference.</p>
<p><strong>See Also</strong> are links to external pages, also provided to help your learning. Remember that any links you click on within the FutureLearn platform will open in the same window. You will need to use your browser ‘back’ button to return to your course.</p>
<h3 id="progress-tracking">Progress Tracking</h3>
<p>When you are ready to move forward, make sure to click on the pink ‘<strong>Mark as complete</strong>’ button at the bottom of each step. This will update your progress page so you’ll be able to track which steps you’ve completed.</p>
<h3 id="prerequisites">Prerequisites</h3>
<p>This course assumes a basic knowledge of computer programming in Python, statistics, basic calculus and linear algebra.</p>
<h3 id="is-there-anything-else">Is there anything else?</h3>
<p>If you have read all the resources provided above, and still have questions, go to the <a href="https://about.futurelearn.com/about/faq?category=course-sign-up-and-completion">FutureLearn FAQs</a> page.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.4&emsp;Meet and greet</h2><div class="u-typography-bold-intro">
<p>A central tenet of our learning approach is social and peer learning.</p>
<p>Therefore, we encourage you to collaborate with your fellow learners. You can do this by sharing ideas and information by posting comments, asking questions, and participating in discussions. You can also click ‘like’ whenever you think a comment or question is particularly interesting or observant.</p>
<p>We would like you to introduce yourself and tell us why you have joined the course.</p>
<p>Use these questions to help guide your responses:</p>
<ul>
<li>Where do you come from?</li>
<li>Why are you interested in this course?</li>
<li>What do you hope to achieve by completing this course?</li>
</ul>
<p>We look forward to reading all your responses in the comments section at the bottom of this step. Go on, get involved!</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.5&emsp;Welcome to Topic 1 </h2><div class="u-typography-bold-intro">
<p>Hi there and welcome to Topic 1.</p>
<p>In this topic we will look at the bigger picture around machine learning and its relationship with Artificial Intelligence.  We will reflect on just what is machine learning, how to recognise it when we see it and what some of the basic data preparation steps are to aid in more effective application of machine learning algorithms.</p>
<p>The course will briefly look at a definition of machine learning, an exploration of tasks machine learning is currently good at, some speculation around what it might be good at in the future and some practical skills.</p>
<p>When it comes to practical skills we will start with data and in particular suitable forms of representation for better machine learning and pre-processing steps that can improve performance.  We conclude the module with an introduction to some practical Python-based tools for exploring and manipulating data to facilitate easier implementation of well-known machine learning ideas.</p>
<p>We expect you to participate in comments when asked under each step.</p>
<p>So let’s get started!</p>
</div><p><h2>1.6&emsp;The disruptive impact of Artificial Intelligence</h2><div class="u-typography-bold-intro">
<p>Artificial Intelligence is transforming and disrupting industries across the world.</p>
<p>There are many well-known industries such as Amazon, Netflix and Google which make use of Machine Learning and Artificial Intelligence to create their intelligent applications. For example, Amazon’s retail, Netflix’s movie distribution, Google’s advertising and many more.</p>
<p>Many people, however, have become concerned about how AI has automated tasks and the implications this will have for their jobs. While advances in AI and robotics may have highlighted negative consequences for certain industries such as manufacturing, there are others in which AI has been seen as a boon, for example in the area of medicine where innovations in AI, robotics and digital technology have led to improved outcomes for patients.</p>
<h3 id="further-listening">Further listening</h3>
<p>The Economist’s Babbage podcast on science and technology explores innovations and discoveries making the news each week. Of particular note is their  <a href="https://www.economist.com/podcasts/2019/10/09/the-promise-and-peril-of-ai">The promise of AI podcasts</a> in which guests discuss the general topic of AI, its applications, risks and benefits.</p>
<p>The BBCs Business Daily, <a href="https://www.bbc.co.uk/sounds/play/p04v84pv">The Future of Work</a> podcast also discusses the implications that advances in AI and automation will have on the way humans live and work and contrasts the current situation, now called the <a href="https://www.bernardmarr.com/default.asp?contentID=966">‘Fourth Industrial Revolution’</a> to the previous industrial revolutions.</p>
<p>The Guardian’s Science Weekly podcast reports on current discoveries in science and technology. Of particular interest is their interview with Professor Stuart Russell. <a href="https://www.theguardian.com/technology/audio/2019/oct/18/stuart-russell-on-why-now-is-the-time-to-start-thinking-about-superintelligent-ai-science-weekly-podcast">Professor Russell</a> discusses superintelligent AI and speculates on how AI might be cleverer than humans in the future.</p>
<p><sub><strong>References:</strong></sub></p>
<p><sub>The Economist (2019) ‘The promise and peril of AI’, Babbage from Economist Radio, podcast, 9 Oct, available: https://www.economist.com/podcasts/2019/10/09/the-promise-and-peril-of-ai [accessed 21 Oct 2019]</sub></p>
<p><sub>BBC News World Service (2017) ‘The future of work’, Business Daily [podcast], 7 Mar, available:
https://www.bbc.co.uk/sounds/play/p04v84pv [accessed 21 Oct 2019]<sub></sub></sub></p>
<p><sub>The Guardian (2019) ‘Stuart Russell on why now is the time to start thinking about superintelligent AI’, Science Weekly [podcast], 18 Oct, available:
https://www.theguardian.com/technology/audio/2019/oct/18/stuart-russell-on-why-now-is-the-time-to-start-thinking-about-superintelligent-ai-science-weekly-podcast [accessed 21 Oct 2019]<sub></sub></sub></p>
<p><sub> Marr, B. (2019) ‘Why everyone must get ready for 4th Industrial Revolution’ Bernard Marr &amp; Co, available:
https://www.bernardmarr.com/default.asp?contentID=966 [accessed 22 Oct 2019]<sub></sub></sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.7&emsp;What is Machine Learning?</h2><div class="u-typography-bold-intro">
<p>In broad terms, Machine Learning is an algorithm which learns from data.</p>
<p>“A computer program is said to learn from experience <strong>E</strong> with respect to some class of tasks <strong>T</strong> and performance measure <strong>P,</strong> if its performance at tasks in <strong>T,</strong> as measured by <strong>P,</strong> improves with experience <strong>E.”</strong> (Mitchell, 1997)</p>
<ul>
<li>The Task <strong>T</strong></li>
<li>The Performance Measures <strong>P</strong></li>
<li>The Experience <strong>E</strong></li>
</ul>
<p>An alternative way of looking at machine learning is in terms of the figure below. We have a machine learning model which is what we are trying to build. We have data which is used as part of an experience to develop and refine a model. Initially our model is not well adjusted to perform the task well. We capture how well the model is at the task through a cost function of some sort which measures performance. Using this performance measure we use some sort of optimization procedure to adjust our model so that it becomes better at the task.</p>
<h3 id="the-components-of-machine-learning">The components of machine learning</h3>
<p><img alt="The components of machine learning image - model - optimization algorithm - cot function - data" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/a8/54/hero_a854c99a-c409-4ab2-b3d2-f79be803747b.png" srcset="https://ugc.futurelearn.com/uploads/assets/a8/54/small_hero_a854c99a-c409-4ab2-b3d2-f79be803747b.png 320w, https://ugc.futurelearn.com/uploads/assets/a8/54/hero_a854c99a-c409-4ab2-b3d2-f79be803747b.png 648w, https://ugc.futurelearn.com/uploads/assets/a8/54/large_hero_a854c99a-c409-4ab2-b3d2-f79be803747b.png 729w, https://ugc.futurelearn.com/uploads/assets/a8/54/large_hero_a854c99a-c409-4ab2-b3d2-f79be803747b.png 2x"/></p>
<h3 id="tell-us-what-you-think">Tell us what you think!</h3>
<p>Machine learning is transforming more and more areas of our everyday lives, creating new opportunities and careers for suitably trained professionals.</p>
<p>In the comments section below tell us which careers you think Machine Learning is creating and the benefits this is having on organisations.</p>
<p>Contribute to the discussion by reviewing comments made by other learners. Remember to ‘like’ comments you find useful or interesting.</p>
<p><sub><strong>References</strong></sub></p>
<p><sub>Mitchell, T.M. (1997), <em>Machine Learning</em>, New York: McGraw-Hill.</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.8&emsp;Machine learning tasks</h2><div class="u-typography-bold-intro">
<p><sub>Source: VoIP Troubleshooter.com, <em>The Open Speech Repository</em></sub></p>
<p><img alt="Machine Learning tasks machine.Yellow gear wheels concept" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/ef/e3/hero_efe31a63-8716-48ab-9c6d-c167fb2646a8.png" srcset="https://ugc.futurelearn.com/uploads/assets/ef/e3/small_hero_efe31a63-8716-48ab-9c6d-c167fb2646a8.png 320w, https://ugc.futurelearn.com/uploads/assets/ef/e3/hero_efe31a63-8716-48ab-9c6d-c167fb2646a8.png 648w, https://ugc.futurelearn.com/uploads/assets/ef/e3/large_hero_efe31a63-8716-48ab-9c6d-c167fb2646a8.png 729w, https://ugc.futurelearn.com/uploads/assets/ef/e3/large_hero_efe31a63-8716-48ab-9c6d-c167fb2646a8.png 2x"/>
<sub>© Shutterstock</sub></p>
<p>We are now going to focus on some examples of machine learning tasks.</p>
<p>For example, self driving cars have several tasks, but one important task is recognizing objects! So it is a classification task of some sort.</p>
<p>In machine learning, we focus on tasks which are difficult to solve with a fixed set of rules designed by a human. The task is not learning by itself. Instead, we simply add a learning ability to our programs in an effort to perform well on some tasks.</p>
<p>For example, we want a robot which we have built to juggle. We could hard code in the seemingly well-structured kinematics associated with juggling that we might capture from observing jugglers. But, it is unlikely to be very robust as there are always errors and perturbations in the real world which will cause our rote-learning robotic juggler to fail.</p>
<p>It might be better to give the robot the ability to closely monitor and observe the effect of its actions based on the errors, to learn to juggle effectively?</p>
<ul>
<li>
<p>Many machine learning tasks are developed in the context of describing how they should process an <strong>example.</strong></p>
</li>
<li>
<p>An <strong>example</strong> is an instance of some object, event, circumstance or a pattern of information that we wish our ML algorithm to handle. It is the <strong>task.</strong></p>
</li>
</ul>
<p>An example is a collection of features, in other words data, which have been captured from our object, event, circumstance via “sensors” which capture the essential characteristics of the task.</p>
<ul>
<li>E.g. a face recognition task could be driven by a small number of features such as distance between eyes, distance nose to mouth, etc.</li>
</ul>
<p>Each example is represented typically as a vector <script type="math/tex">x \in R ^n</script>where each <script type="math/tex">x_i</script>  is a feature of the example.</p>
<p>Now let’s apply this idea to a sound wave. Listen to the audio file above. Each feature in this sound file is the amplitude of the sound wave (speech clip) at each time sample.</p>
<p>Let’s take a look at other examples of tasks and as we go we will pay attention to feature vectors which arise in some of these examples. This will help us when we go deeper into data representation next week.</p>
<p><sub><strong>References:</strong></sub></p>
<p><sub>VoIP Troubleshooter.com, <em>The Open Speech Repository</em>, available: http://www.voiptroubleshooter.com/ [accessed 23 Oct 2019]</sub></p>
</div><p><h2>1.9&emsp;Regression task</h2><div class="u-typography-bold-intro">
<p>Another example of a machine learning task is regression.</p>
<p>Let’s consider a sales manager trying to predict sales figures for the next month. They have a great deal of data at their disposal including:</p>
<ul>
<li>Historic sales data</li>
<li>Competitor pricing</li>
<li>Economic conditions as well as</li>
<li>Their sales team’s insights.</li>
</ul>
<p>How are they going to break down this data into information they can use? They must be able to understand, analyse and interpret this data into useful information. To do this, they use a type of data analysis called <strong>regression</strong>.</p>
<p><img alt="Data regression Intelligence - Predict y continuous output Diagram" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/04/6a/hero_046ae890-ee9b-4d33-8aa7-67d506865e58.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/04/6a/small_hero_046ae890-ee9b-4d33-8aa7-67d506865e58.PNG 320w, https://ugc.futurelearn.com/uploads/assets/04/6a/hero_046ae890-ee9b-4d33-8aa7-67d506865e58.PNG 648w, https://ugc.futurelearn.com/uploads/assets/04/6a/large_hero_046ae890-ee9b-4d33-8aa7-67d506865e58.PNG 729w, https://ugc.futurelearn.com/uploads/assets/04/6a/large_hero_046ae890-ee9b-4d33-8aa7-67d506865e58.PNG 2x"/></p>
<p>Regression is the statistical technique of predicting variable(s) from other variables(s).
Regression is a statistical approach to predict the outcome of a quantity, (i.e) predicting variable(s) from other variables(s)</p>
<p>In this type of task, the computer program is asked to predict a numerical value given some input. To solve this task, the learning algorithm is asked to output a function <script type="math/tex">f: R^n \rightarrow R</script>. This type of task is similar to classification, except that the format of output is different.</p>
<p><strong>Examples of regression tasks</strong>
The following are examples of regression tasks.</p>
<p><strong>Example 1:</strong> Prediction of the expected claim amount that an insured person will make (used to set insurance premiums), or the prediction of future prices of securities. These kinds of predictions are also used for algorithmic trading.</p>
<p><img alt="Black &amp; White image of a computer screen showing  a graph of the stock market performance" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/b7/66/hero_b7660caa-217c-461c-adfe-c33097e406ec.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/b7/66/small_hero_b7660caa-217c-461c-adfe-c33097e406ec.jpg 320w, https://ugc.futurelearn.com/uploads/assets/b7/66/hero_b7660caa-217c-461c-adfe-c33097e406ec.jpg 648w, https://ugc.futurelearn.com/uploads/assets/b7/66/large_hero_b7660caa-217c-461c-adfe-c33097e406ec.jpg 729w, https://ugc.futurelearn.com/uploads/assets/b7/66/large_hero_b7660caa-217c-461c-adfe-c33097e406ec.jpg 2x"/></p>
<p><img alt="Top of the range black sports car" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/2a/66/hero_2a665894-74db-4d24-b852-4c4cdf86e913.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/2a/66/small_hero_2a665894-74db-4d24-b852-4c4cdf86e913.jpg 320w, https://ugc.futurelearn.com/uploads/assets/2a/66/hero_2a665894-74db-4d24-b852-4c4cdf86e913.jpg 648w, https://ugc.futurelearn.com/uploads/assets/2a/66/large_hero_2a665894-74db-4d24-b852-4c4cdf86e913.jpg 729w, https://ugc.futurelearn.com/uploads/assets/2a/66/large_hero_2a665894-74db-4d24-b852-4c4cdf86e913.jpg 2x"/></p>
<p><strong>Example 2:</strong> Predicting prices of a house with the help of the features such as house size, price etc.</p>
<p><img alt="Arial picture of housing estates" src="https://ugc.futurelearn.com/uploads/assets/61/26/6126a98c-05d1-4678-b039-f88bde6cf136.png"/></p>
<p>Other examples include:</p>
<ul>
<li>
<p>Predicting the number of visitors to a restaurant depending upon the restaurant’s reservation and visitation data.</p>
</li>
<li>
<p>Predicting the age of the person depending upon his height, weight and health conditions.</p>
</li>
<li>
<p>Predicting the number of music albums that will be sold next month.</p>
</li>
</ul>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.10&emsp;Classification task</h2><div class="u-typography-bold-intro">
<p><strong>Of all machine learning tasks, it is perhaps the classification task which is most ubiquitous or well known.</strong></p>
<p>Let’s consider examples of persons or things that need to be grouped for analysis. These could include:</p>
<ul>
<li>Classifying whether hospital patients have a disease or not</li>
<li>Identifying cars vs trucks on a motorway</li>
<li>Classifying foods as carbohydrates or proteins</li>
</ul>
<p>These are all examples of predefined classes and the outcome of the classifications mentioned above. This sort of problem corresponds to the <strong>classification task</strong> in machine learning.</p>
<p>Therefore, <strong>disease or no disease</strong> are the predefined classes, as are <strong>car or truck.</strong> The outcome has to be one of only two options in these examples. This corresponds to the classification task in machine learning.</p>
<p>Classification is about predicting a label of the class. In general, the computer program learns from the input given to it and classifies the new observation with the help of the learning.</p>
<p><img alt="diagram of classification ALGORITHM - Data  Cylinder - Classification square - Intelligence Square - each with a formula" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/1f/5d/hero_1f5d839b-0acf-4a80-a3b3-270f8aee9b6e.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/1f/5d/small_hero_1f5d839b-0acf-4a80-a3b3-270f8aee9b6e.PNG 320w, https://ugc.futurelearn.com/uploads/assets/1f/5d/hero_1f5d839b-0acf-4a80-a3b3-270f8aee9b6e.PNG 648w, https://ugc.futurelearn.com/uploads/assets/1f/5d/large_hero_1f5d839b-0acf-4a80-a3b3-270f8aee9b6e.PNG 729w, https://ugc.futurelearn.com/uploads/assets/1f/5d/large_hero_1f5d839b-0acf-4a80-a3b3-270f8aee9b6e.PNG 2x"/></p>
<p>In general, we ask our Machine Learning algorithm to decide which of k categories our input x belongs to.</p>
<p><script type="math/tex">y = f(x)</script> means we are assigning an example described by a feature vector x to a category which we have labelled with a numerical code <script type="math/tex">1,...k</script>.</p>
<p>In the diagram above, there are variations. For example, <script type="math/tex">f</script> could produce a probability distribution over these classes, i.e class 1 has 80% chance of being the target, Class 2 is 10% etc.</p>
<p><strong>Example 1:</strong> Spam filtering: Classifying the text of an email to be spam or non- spam.</p>
<p><img alt="Spam filtering diagram image of square with the words filtering by Text: Sender :IP -with arrows pointing to Spam or not spam -  2nd image of list" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/1c/09/hero_1c09084c-4b92-48e6-a692-a70600bfec20.png" srcset="https://ugc.futurelearn.com/uploads/assets/1c/09/small_hero_1c09084c-4b92-48e6-a692-a70600bfec20.png 320w, https://ugc.futurelearn.com/uploads/assets/1c/09/hero_1c09084c-4b92-48e6-a692-a70600bfec20.png 648w, https://ugc.futurelearn.com/uploads/assets/1c/09/large_hero_1c09084c-4b92-48e6-a692-a70600bfec20.png 729w, https://ugc.futurelearn.com/uploads/assets/1c/09/large_hero_1c09084c-4b92-48e6-a692-a70600bfec20.png 2x"/></p>
<p><strong>Example 2:</strong> Multi-class classifier: Image classification (Classification of dolls with an image given as input)</p>
<p><img alt="Image of a doll with image classification - top predictions Barbie - LOL doll or Baby Annabell" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/3f/b9/hero_3fb921e3-c87c-42b7-8870-5c4f699ea00f.png" srcset="https://ugc.futurelearn.com/uploads/assets/3f/b9/small_hero_3fb921e3-c87c-42b7-8870-5c4f699ea00f.png 320w, https://ugc.futurelearn.com/uploads/assets/3f/b9/hero_3fb921e3-c87c-42b7-8870-5c4f699ea00f.png 648w, https://ugc.futurelearn.com/uploads/assets/3f/b9/large_hero_3fb921e3-c87c-42b7-8870-5c4f699ea00f.png 729w, https://ugc.futurelearn.com/uploads/assets/3f/b9/large_hero_3fb921e3-c87c-42b7-8870-5c4f699ea00f.png 2x"/></p>
<p><strong>Example 3:</strong> Personalised medical diagnosis: Disease classifier model which classifies the health condition of a person depending upon the features such as exercise habits, blood samples etc.</p>
<p><img alt="Images inside a box of a watch - skeleton - medical symbol with the wording Input: x Health related data with a second box containing the wording : Flu - Pneumonia - Healthy -  At risk of heart disease - Output: y Diagnosis" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/91/7d/hero_917d2a12-8068-4e72-9e04-3a14d4fb3d96.png" srcset="https://ugc.futurelearn.com/uploads/assets/91/7d/small_hero_917d2a12-8068-4e72-9e04-3a14d4fb3d96.png 320w, https://ugc.futurelearn.com/uploads/assets/91/7d/hero_917d2a12-8068-4e72-9e04-3a14d4fb3d96.png 648w, https://ugc.futurelearn.com/uploads/assets/91/7d/large_hero_917d2a12-8068-4e72-9e04-3a14d4fb3d96.png 729w, https://ugc.futurelearn.com/uploads/assets/91/7d/large_hero_917d2a12-8068-4e72-9e04-3a14d4fb3d96.png 2x"/></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.11&emsp;Similarity task</h2><div class="u-typography-bold-intro">
<p>Similarity is a machine learning method which makes use of the nearest neighbour approach to identify the similarity between objects based on algorithmic distance functions.</p>
<p>In information retrieval the aim is to extract information resources relevant to an information need which you can achieve in many ways. The end goal is to extract the relevant resources. In machine learning, the objective is to learn good models of reality in order to regress, classify, or describe the data. The retrieval task here makes use of the nearest neighbour (similarity) approach to retrieve the relevant information.</p>
<h3 id="retrieval">Retrieval</h3>
<p>When we do a Google search, we are actually searching Google’s web index. Google organizes web pages into something searchable. For example, if you search for “Investigation”, it might pull sites with the words “investigative”, “investigation” and “investigator”. This refers to retrieval of information.</p>
<p>Retrieval is the search for related items.</p>
<p><img alt="Diagram  for retrieval - 3 shapes with Data input - Nearest neighbour Learn - Intelligence with formulas written on them" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/30/b6/hero_30b6a154-ce16-4712-b2a5-0c73deafa811.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/30/b6/small_hero_30b6a154-ce16-4712-b2a5-0c73deafa811.PNG 320w, https://ugc.futurelearn.com/uploads/assets/30/b6/hero_30b6a154-ce16-4712-b2a5-0c73deafa811.PNG 648w, https://ugc.futurelearn.com/uploads/assets/30/b6/large_hero_30b6a154-ce16-4712-b2a5-0c73deafa811.PNG 729w, https://ugc.futurelearn.com/uploads/assets/30/b6/large_hero_30b6a154-ce16-4712-b2a5-0c73deafa811.PNG 2x"/></p>
<p><img alt="Retrieval applications - useful in a wide variety of tasks: - 4 images - a hand holding a remote control - streaming content; a watch - product recommendations; a cats head - images; a tablet - News/Blogs" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/12/62/hero_12629792-cb35-47d3-9389-3711fbe3a81c.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/12/62/small_hero_12629792-cb35-47d3-9389-3711fbe3a81c.jpg 320w, https://ugc.futurelearn.com/uploads/assets/12/62/hero_12629792-cb35-47d3-9389-3711fbe3a81c.jpg 648w, https://ugc.futurelearn.com/uploads/assets/12/62/large_hero_12629792-cb35-47d3-9389-3711fbe3a81c.jpg 729w, https://ugc.futurelearn.com/uploads/assets/12/62/large_hero_12629792-cb35-47d3-9389-3711fbe3a81c.jpg 2x"/></p>
<h3 id="examples">Examples:</h3>
<ul>
<li>Retrieve the nearest neighbour article based on the space of all articles, organised by the similarity of text.</li>
</ul>
<p><img alt="Nearest neighbour diagran showing 2 sets of article files side by side - Retrieve nearest neighbour OR retrieve group of nearest neighbours wording" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/ac/d8/hero_acd834b8-f3f6-46eb-9a79-331b294308c2.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/ac/d8/small_hero_acd834b8-f3f6-46eb-9a79-331b294308c2.jpg 320w, https://ugc.futurelearn.com/uploads/assets/ac/d8/hero_acd834b8-f3f6-46eb-9a79-331b294308c2.jpg 648w, https://ugc.futurelearn.com/uploads/assets/ac/d8/large_hero_acd834b8-f3f6-46eb-9a79-331b294308c2.jpg 729w, https://ugc.futurelearn.com/uploads/assets/ac/d8/large_hero_acd834b8-f3f6-46eb-9a79-331b294308c2.jpg 2x"/></p>
<ul>
<li>Connecting people in social networks (based on the location, workplace etc).</li>
</ul>
<p><img alt=" 6 people with the wording - Connecting people on Social networks - recommended connections based on: Age - Location - Workplace - Interests etc" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/5f/d1/hero_5fd16507-d2a1-4271-955c-14be61d6f6db.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/5f/d1/small_hero_5fd16507-d2a1-4271-955c-14be61d6f6db.jpg 320w, https://ugc.futurelearn.com/uploads/assets/5f/d1/hero_5fd16507-d2a1-4271-955c-14be61d6f6db.jpg 648w, https://ugc.futurelearn.com/uploads/assets/5f/d1/large_hero_5fd16507-d2a1-4271-955c-14be61d6f6db.jpg 729w, https://ugc.futurelearn.com/uploads/assets/5f/d1/large_hero_5fd16507-d2a1-4271-955c-14be61d6f6db.jpg 2x"/></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.12&emsp;Clustering task</h2><div class="u-typography-bold-intro">
<p>Let’s consider a person working in the retail industry who is asked by a manager to provide data about the shopping patterns of their customers.</p>
<p>This is an example of an unsupervised learning problem, where you are unfamiliar with, or don’t know exactly  what you are looking for. This is where we can build relationships, by grouping together data of similar instances. This is known as clustering.</p>
<h3 id="what-is-clustering">What is clustering?</h3>
<p>Clustering is discovering groups of similar inputs.</p>
<p><img alt="3 shapes with wording in each : Data input X; Clustering;  and Intelligence output Z" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/35/af/hero_35afc602-0e16-439b-881a-0745e4214626.png" srcset="https://ugc.futurelearn.com/uploads/assets/35/af/small_hero_35afc602-0e16-439b-881a-0745e4214626.png 320w, https://ugc.futurelearn.com/uploads/assets/35/af/hero_35afc602-0e16-439b-881a-0745e4214626.png 648w, https://ugc.futurelearn.com/uploads/assets/35/af/large_hero_35afc602-0e16-439b-881a-0745e4214626.png 729w, https://ugc.futurelearn.com/uploads/assets/35/af/large_hero_35afc602-0e16-439b-881a-0745e4214626.png 2x"/></p>
<p>Therefore, if we are searching for images of oceans a cluster of images of oceans will be retrieved. So if you are looking for information on a search engine about the Atlantic Ocean then it is important that documents that are in some sense related or similar to your web query are retrieved. Clustering could be part of solution for identifying similar content to that specified by your search term.</p>
<h3 id="embedding">Embedding</h3>
<p>Machine learning can be used for embedding images to visualize data, embedding semantically similar words based on the idea that “a word is characterized by the company it keeps”, or embedding audio to perhaps find similar music.  A very compelling and ubiquitous application is the algorithm <a href="https://code.google.com/archive/p/word2vec/">Word2Vec</a> developed at Google. For those of you who are interested in going deep on this, take a look at this excellent blog post  - <a href="https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/">The amazing power of word vectors</a>. Alternatively the first 6 or 7 slides of this excellent <a href="https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture">Google introduction</a> are useful for explaining the concept of embeddings.</p>
<p><img alt="image" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/90/99/hero_9099552b-cff1-434c-a241-d6a63f8346c2.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/90/99/small_hero_9099552b-cff1-434c-a241-d6a63f8346c2.PNG 320w, https://ugc.futurelearn.com/uploads/assets/90/99/hero_9099552b-cff1-434c-a241-d6a63f8346c2.PNG 648w, https://ugc.futurelearn.com/uploads/assets/90/99/large_hero_9099552b-cff1-434c-a241-d6a63f8346c2.PNG 729w, https://ugc.futurelearn.com/uploads/assets/90/99/large_hero_9099552b-cff1-434c-a241-d6a63f8346c2.PNG 2x"/>
<sub>Source: Google Cloud. Available <a href="https://cloud.google.com/solutions/machine-learning/overview-extracting-and-serving-feature-embeddings-for-machine-learning">here</a>.</sub></p>
<p><sub><strong>References:</strong></sub></p>
<p><sub>Colyer, A. (2012) ‘The amazing power of word vectors’, <em>the morning paper</em>, 21 Apr, available: https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/ [accessed 23 Oct 2019]</sub></p>
<p><sub>Google Developers (2019) <em>Machine Learning Crash Course</em>, available: https://developers.google.com/machine-learning/crash-course [accessed 12 Nov 2019)</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.13&emsp;The Performance Measure P</h2><div class="u-typography-bold-intro">
<p>So an important aspect to the development of machine learning is determining if our machine learning method is any good at the task T it has been designed to perform (classification, regression and similarity)?</p>
<p>We need to evaluate this objectively and quantitatively. The evaluation metrics depend upon the task T and the application.</p>
<p>For classification tasks we might use the <strong>accuracy</strong> of the machine learning model, i.e. how often is the algorithm classifying things correctly. In such cases we might measure the percentage of examples that the model gets right. We could just as well measure the percentage of examples that the model gets wrong. We could call this the <strong>error rate.</strong></p>
<p>How we calculate the performance in practice is also important. Usually we will want to test using data the model has not seen before. This is referred to as <strong>a test set.</strong> We will explore many ways to evaluate performance later in this course but for now just tag it as an important piece of the machine learning challenge.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.14&emsp;The Experience - Supervised Learning</h2><div class="u-typography-bold-intro">
<p>We have seen some examples of tasks and thought a little about performance. Now let’s examine the experience part of our story.</p>
<h3 id="the-experience-e">The experience E</h3>
<p>Machine Learning takes place through an algorithm being exposed to a dataset which is a collection of examples, each of which can be considered a data point. This exposure constitutes the experience, E we have referred to.  Depending on whether this exposure is accompanied with information on the true class that an example belongs to, we call the learning either supervised or unsupervised.</p>
<h3 id="supervised-learning">Supervised learning</h3>
<p>Supervised learning describes an experience E in which the algorithm is exposed to a dataset where each data point has features/attributes but also has a <strong>target feature.</strong> This is the class label and is the result of the classification of the training examples through another means, perhaps by a human expert.</p>
<p>Example: Let’s take a brain computer interface example. We have many examples of patterns of brain activity when the person is thinking of moving their left hand and many examples tagged for when they are moving their right hand. Using this dataset we can train a supervised learning algorithm to assign new data points to either the “Left” or “Right” category/label.</p>
<p>In supervised learning we have a specific target which we know in advance we are trying to predict. Another example is a SPAM/HAM detector. We need examples which have ground truth attached so we can measure directly how well we are doing.</p>
<p>If it was a regression task where we are trying to predict tomorrow’s temperature or a stock price, we can measure directly how well we have done using historical data or indeed through waiting for tomorrow’s data. It is clear and easy to determine accuracy.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.15&emsp;The Experience - Unsupervised Learning</h2><div class="u-typography-bold-intro">
<p>In the previous step we learnt that Machine Learning takes place through an algorithm being exposed to a dataset which constitutes the experience, <strong>E.</strong></p>
<h3 id="unsupervised-learning">Unsupervised learning</h3>
<p>Unsupervised learning describes an experience E, in which the algorithm is exposed to a dataset where each data point has features/attributes but has no <strong>target feature</strong> with which to structure the data. The algorithm has to learn the properties of the structure of the dataset. We are often trying to identify clusters in the data where the cluster represent similar data points.</p>
<p>Some points to note:</p>
<ul>
<li>
<p>We are not looking for something specific here. We are trying to learn about the data, discover structure, discover patterns, discover unusual patterns.</p>
</li>
<li>
<p>This does not require labelled data but obviously we can apply this to labelled data to determine what structures might be relevant to the labels.</p>
</li>
<li>
<p>Evaluation is different as we don’t have labels so cannot say how accurate it is.</p>
</li>
<li>
<p>We can use qualitative evaluation. So we can look at the data and as a human ask ourselves the question of whether or not it helps us understand our data.</p>
</li>
<li>
<p>We could do indirectly by using any robust patterns which emerge as features, i.e. attribute-values pairs which act as input to a supervised learning algorithm and then see if the performance of that classifier is improved.</p>
</li>
<li>
<p>Semi-supervised is when you have lots of unlabelled data and some labelled data. You use the unsupervised learning to improve the supervised part.</p>
</li>
</ul>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.16&emsp;Generative vs Discriminative Learning</h2><div class="u-typography-bold-intro">
<p>In the previous step, we learned that supervised and unsupervised learning is a way of categorising Machine Learning algorithms.</p>
<p>Another way is to distinguish between generative and discriminative learning.</p>
<h3 id="generative-learning">Generative learning</h3>
<p>In generative models we have a probabilistic model for each class output. This means that the whole population for a class is characterised in some way. The decision boundary then is the point at which one class becomes more likely than any other. Both labelled or unlabelled data can be used. The boundary is decided after the models are developed.</p>
<h3 id="discriminative-learning">Discriminative learning</h3>
<p>Discriminative learning is focused on the discovery of a decision boundary. This only works on labelled data in a supervised learning context. Discriminative algorithms are focused on the data points closest to each other in the classes and are focused on finding a boundary which separates the classes. Data instances far from the other classes are not as important as those which are closer.</p>
<p>At the moment the above concepts might seem a little abstract but we will provide examples of these later.</p>
<p><sub><strong>Reference/Suggested reading:</strong></sub></p>
<p><sub>Joshi, Prathap M. (2018) <a href="https://medium.com/@mlengineer/generative-and-discriminative-models-af5637a66a3">‘Generative VS Discriminative Models’, <em>Medium</em>, 30 Aug, available:</a> [accessed 12 Nov 2019]</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.17&emsp;Different tasks</h2><div class="u-typography-bold-intro">
<p>Now that you have learnt about different tasks, we would like you to discuss the following tasks in the comments section below.</p>
<ul>
<li>Denoising</li>
<li>Transcription</li>
<li>Machine Translation</li>
<li>Anomaly Detection</li>
<li>Synthesis</li>
<li>Imputation</li>
</ul>
<p>We would like you to tell us:</p>
<ul>
<li>How you would categorise each of the tasks listed</li>
<li>Give other applications of these tasks.</li>
</ul>
<p>There is no one right answer, but we have given you some examples below to help you with your decision.</p>
<hr/>
<h3 id="task-example--denoising">Task Example : Denoising</h3>
<p>Such a task involves the Machine Learning taking input as <script type="math/tex">\bar{x}\in R^n</script> which has been corrupted in some way by a process from its noise-free version <script type="math/tex">x \in R^n</script>  here the task is to predict the clean version of <script type="math/tex">x</script> given <script type="math/tex">\bar{x}</script> . This is also considered as the statistical problem of modelling the conditional probability distribution <script type="math/tex">p(x \mid \bar{x}</script>).</p>
<p>The figures below demonstrate clean and noisy ECG waveforms. We can consider the clean version as <script type="math/tex">x</script> and the noisy version as <script type="math/tex">\bar{x}</script>.</p>
<p><img alt="Clean ECG Noisy ECG" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/c0/75/hero_c0752f19-b934-4b44-9ab4-6f8b43ffb431.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/c0/75/small_hero_c0752f19-b934-4b44-9ab4-6f8b43ffb431.PNG 320w, https://ugc.futurelearn.com/uploads/assets/c0/75/hero_c0752f19-b934-4b44-9ab4-6f8b43ffb431.PNG 648w, https://ugc.futurelearn.com/uploads/assets/c0/75/large_hero_c0752f19-b934-4b44-9ab4-6f8b43ffb431.PNG 729w, https://ugc.futurelearn.com/uploads/assets/c0/75/large_hero_c0752f19-b934-4b44-9ab4-6f8b43ffb431.PNG 2x"/></p>
<hr/>
<h3 id="task-example--transcription">Task Example : Transcription</h3>
<p>Here the Machine Learning system is given input with a loose structure and asked to map to it into a discrete structured form.</p>
<p>A good example is speech recognition where an idiosyncratic audio signal of your voice is mapped to text. Another example is optical character recognition where we take handwritten zip codes and map these to a Unicode version, i.e. a standard digital format.</p>
<p>Speech recognition is used in various applications where we can talk to our computers/phones instead of typing.</p>
<p><strong>Considering all the tasks which we came across till now, to which task of machine learning would you categorise transcription?</strong></p>
<hr/>
<h3 id="task-example--machine-translation">Task Example : Machine Translation</h3>
<p>Here the Machine Learning system is mapping from one structured input to another.</p>
<p>An example of this is <a href="https://translate.google.com">Google Translate</a> for text. We can combine with transcription (previous example) to get translation of spoken language rather than requiring it to be written.</p>
<p><strong>Can you come up with any other applications like Google Translate which does Machine Translation?</strong></p>
<p><strong>What are the different sectors which you might feel that Machine Translation would be of greater use?</strong></p>
<hr/>
<h3 id="task-example--anomaly-detection">Task Example : Anomaly Detection</h3>
<p>In this task the Machine Learning algorithm flags data which is atypical. A classic example is fraud detection. An interesting example in the context of health is the fraud detection in clinical trials.</p>
<p>Another example would be detecting the disturbances in ecosystem, which can be natural or due to diseases, insects etc.</p>
<p><strong>Could you categorise to which branch of Machine Learning (Supervised/Unsupervised) does Anomaly detection fall?</strong></p>
<hr/>
<h3 id="task-example--synthesis">Task Example : Synthesis</h3>
<p>Here the Machine Learning algorithm has the task of generating new examples of the data that are similar to the training data but which are not directly the training data. 
Facial generation is a classic example here.</p>
<p></p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
Source: <a href="https://www.youtube.com/user/Bloomberg">Bloomberg</a>
<hr/>
<h3 id="task-example--imputation">Task Example : Imputation</h3>
<p>Here the Machine Learning algorithm is given a new example <script type="math/tex">x</script> it has not seen before but with some of its components missing. The task here is to estimate the missing components based on the training data and the components which are present.</p>
<p>Take a look at the video below which uses a style-based generator architecture for Generative Adversarial Networks.
</p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
Source: <a href="https://www.youtube.com/channel/UCRtoHpUxLBJ95IU-p-4T_iA">Tero Karras FI</a>
<p>The missing values can be replaced/imputed by calculating the mean/median of the non-missing values in the column and then replacing the missing values in each column separately, which can only be done on the numeric data.</p>
<p>There are several other imputation methods available which will be looked into later on.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.19&emsp;Review of Topic 1</h2><div class="u-typography-bold-intro">
<p>Congratulations on completing Topic 1.</p>
<p>Now that you have finished reading about this topic you should have picked up a much more solid understanding of what machine learning is and what it is not. You should now understand how machine learning is in essence an algorithm, or perhaps a set of algorithms which together learn from data to become useful as some task.</p>
<p>You will have learned that there are many types of tasks for which machine learning is suitable and that there are several different ways in which machine learning algorithms can learn from such data. You should have an appreciation of just how powerful machine learning can be in terms of disrupting older ways of doing things, introducing new business opportunities and creating a better future.</p>
<p>I hope you now appreciate just how exciting this field is and in particular the importance of data to the algorithms we will explore. Speaking of data, let’s understand how best we can represent information from the real world in the form of data and how best to represent it for machine learning purposes.</p>
<p>In the next topic we take a step towards understanding this a little better.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p style="page-break-before: always"><h2>2.1&emsp;Welcome to Topic 2</h2><div class="u-typography-bold-intro">
<p>Hello everyone, I hope you enjoyed the first topic of this course and that you now have an appreciation for the bigger picture around the topic of  machine learning.</p>
<p>In Topic 2 we are going to focus on the details of data and its representation. Data is essential for learning and good quality data, represented appropriately can really accelerate the learning process for our machine learning algorithms.  We will take a look at some fundamental types of data which lend themselves best to specific machine learning tasks before advancing to creating sets of these as features vectors. At the end of this topic we will have laid down good foundations for thinking about data including exposure to some real world examples.</p>
<p>By the way, we will again expect you to participate in comments when asked under each step.</p>
<p>OK, let’s get started!</p>
<div class="video_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.2&emsp;Overview of data representation</h2><div class="u-typography-bold-intro">
<p>Before we jump into data representation, let’s remember how we defined machine learning.</p>
<p>You should recall that Machine Learning is the study of algorithms that <strong>improve their performance</strong> at some <strong>task</strong> with <strong>experience.</strong></p>
<p><img alt="image of algiorithm - Training Examples -  Learning algorithm  - Preditor" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/3c/7e/hero_3c7ef962-68b7-4bd0-8ade-ea255cd616ff.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/3c/7e/small_hero_3c7ef962-68b7-4bd0-8ade-ea255cd616ff.jpg 320w, https://ugc.futurelearn.com/uploads/assets/3c/7e/hero_3c7ef962-68b7-4bd0-8ade-ea255cd616ff.jpg 648w, https://ugc.futurelearn.com/uploads/assets/3c/7e/large_hero_3c7ef962-68b7-4bd0-8ade-ea255cd616ff.jpg 729w, https://ugc.futurelearn.com/uploads/assets/3c/7e/large_hero_3c7ef962-68b7-4bd0-8ade-ea255cd616ff.jpg 2x"/></p>
<p>If we are to learn from data we need some way to represent our data mathematically so that it lends itself to representation on computer systems.</p>
<p>So how do we do that? Well, it depends on what we are trying to do. For example, if we are developing a system which uses a camera to decide if someone is performing a physical exercise correctly then this is a very different data representation problem to a banking application where we are deciding whether we will lend money to a customer.</p>
<p>However, both scenarios need to extract data from these tasks and that data needs to be organised in a consistent and useful way. The approach here is to introduce the idea of attribute-value pairs.</p>
<h3 id="attribute-pairs">Attribute pairs</h3>
<p>In this topic we are going to look at the important concept of attribute-value pairs in Machine Learning. Attribute-value pairs are simply a way of arranging data in computer systems that map easily to our own cognitive models of things.</p>
<p>For example, let’s say we are developing a piece of software which matches people for the purposes of car-pooling. As a starting point we might describe a person in terms of their name, height, weight, birthday, home address, work address and favourite movies. This is not the most fun way to describe a person but it is a pretty functional description at least.</p>
<p>We consider these different aspects of a person as “attributes”. Each person has an attribute value, i.e.</p>
<p><img alt="image of a beautiful girl with her attributed detailed - sustomer ID : Name: Height Weight: Birthday: Home Address: Work Address : Favourite movie." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/80/d1/hero_80d1afd0-849d-4d54-ab2c-8397036c1a76.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/80/d1/small_hero_80d1afd0-849d-4d54-ab2c-8397036c1a76.jpg 320w, https://ugc.futurelearn.com/uploads/assets/80/d1/hero_80d1afd0-849d-4d54-ab2c-8397036c1a76.jpg 648w, https://ugc.futurelearn.com/uploads/assets/80/d1/large_hero_80d1afd0-849d-4d54-ab2c-8397036c1a76.jpg 729w, https://ugc.futurelearn.com/uploads/assets/80/d1/large_hero_80d1afd0-849d-4d54-ab2c-8397036c1a76.jpg 2x"/></p>
<p>Each customer is stored on the system as a group of attributes and the corresponding values for that customer. Hence we have a list of attribute-value pairs for each customer. In computing we often refer to such a list of features as a vector (i.e. a one-dimensional array) which should not be confused with the concept of vectors used in engineering and mathematics where a vector refers to a mathematical entity - a quantity which has both magnitude and direction.</p>
<p>In the next step we will take a deeper dive into this topic.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.3&emsp;Attribute value pairs</h2><div class="u-typography-bold-intro">
<p>In the previous step we introduced the concept of attribute-value pairs.</p>
<p>Attribute-value pairs are a fundamental representation of data in computer systems and various applications. This is a good way of storing and modelling real-world data.</p>
<p>Taking our example from the previous step we know that we can represent our customer as a set of attribute value pairs, as follows:</p>
<p><img alt="image of a beautiful girl with her attributed detailed - sustomer ID : Name: Height Weight: Birthday: Home Address: Work Address : Favourite movie." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/54/86/hero_5486fde0-01fa-4a1c-aa89-75f569515ae8.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/54/86/small_hero_5486fde0-01fa-4a1c-aa89-75f569515ae8.jpg 320w, https://ugc.futurelearn.com/uploads/assets/54/86/hero_5486fde0-01fa-4a1c-aa89-75f569515ae8.jpg 648w, https://ugc.futurelearn.com/uploads/assets/54/86/large_hero_5486fde0-01fa-4a1c-aa89-75f569515ae8.jpg 729w, https://ugc.futurelearn.com/uploads/assets/54/86/large_hero_5486fde0-01fa-4a1c-aa89-75f569515ae8.jpg 2x"/></p>
<p>From the example above we observe that attributes can be numbers or strings of text and within these attributes there are further differences such as different numeric values such as dates and different strings of text such as those between the favourite movie and address.</p>
<p>It is important that we  convert every dataset to a set of attribute value pairs. Generally there are three types of attributes.</p>
<p>These are:</p>
<ul>
<li>Categorical: i.e. labels or classes that represents finite and discrete</li>
<li>Ordinal: i.e. labels with an order (First, Second, Third)</li>
<li>Numeric: i.e. quantitative values represented are integers or real numbers</li>
</ul>
<p>Therefore, examples could be as follows:</p>
<ul>
<li>Categorical: wavy, straight, curly hair</li>
<li>Ordinal: First, second, third</li>
<li>Numeric: -100, 0, 1.414, 12 x <script type="math/tex">10^6</script></li>
</ul>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.4&emsp;Categorical attributes</h2><div class="u-typography-bold-intro">
<p>Categorical attributes are discrete values with each instance falling into a finite set of categories. These categories are mutually exclusive.</p>
<p>Categories are usually encoded as numbers (just a representation) and they require no natural ordering of categories. Only equality testing (=, ! =) is meaningful, as numbers are what many of our machine learning algorithms work with. 
However encoding as numbers can lead to problems whereby numerical values can be interpreted as having meaning beyond their categorisation.</p>
<p>Take the example of a set of car brands. E.g. {Ford, Toyota, Honda, Audi, BMW}. We assign the indices as follows:</p>
<p><img alt="Categorical attributes  car logos for Ford, Toyota, Honda, Audi, BMW" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/93/b5/hero_93b5310c-314c-49f8-b370-1a4b19ff4569.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/93/b5/small_hero_93b5310c-314c-49f8-b370-1a4b19ff4569.jpg 320w, https://ugc.futurelearn.com/uploads/assets/93/b5/hero_93b5310c-314c-49f8-b370-1a4b19ff4569.jpg 648w, https://ugc.futurelearn.com/uploads/assets/93/b5/large_hero_93b5310c-314c-49f8-b370-1a4b19ff4569.jpg 729w, https://ugc.futurelearn.com/uploads/assets/93/b5/large_hero_93b5310c-314c-49f8-b370-1a4b19ff4569.jpg 2x"/></p>
<p>However, where there is no natural ordering of the values, e.g. Honda &gt; Toyota does not make sense. Our ML algorithms may attempt to learn relationships from this variable which can lead to issues with performance.</p>
<p><a href="https://en.wikipedia.org/wiki/One-hot">One Hot</a> Encoding is a solution for this sort of problem. You can learn a little about this problem and One Hot Encoding <a href="https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b">here</a> or <a href="https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/">here</a>.</p>
<p><sub><strong>References</strong></sub></p>
<p><sub>Shaikh, R. (2018) ‘Choosing the right Encoding method - Label vs OneHot Encoder, <em>Towards Data Science</em>, 9 Nov, available: https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b [accessed 12 Nov 2019]</sub></p>
<p><sub>Brownlee, J. (2019) ‘How to One Hot Encode Sequence Data in Python’, <em>Machine Learning Mastery</em>, 14 Aug, available: https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/ [accessed 12 Nov 2019]</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.5&emsp;Ordinal attributes</h2><div class="u-typography-bold-intro">
<p>Ordinal attributes are labels with an order. Instances fall into one set of categories. There is a natural ordering to categories.</p>
<p><strong>Example 1</strong>: Education level: {none, school, university, postgraduate}
<strong>Example 2</strong>: Likert scale: {disagree, neutral, agree, strongly agree}</p>
<p>They can be encoded as numbers to preserve ordering. This would be meaningful to compare the data attributes whether they are greater than, less than or equal to one another.</p>
<p>Ordinal attributes cannot be added or subtracted from one another. They are in between categorical variables and quantitative variables.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.6&emsp;Numerical attributes</h2><div class="u-typography-bold-intro">
<p>Most of the open source data available for machine learning modelling has numerical attributes. These are quantitative attributes.</p>
<p>They can either be integers or real numbers. They can be added, subtracted, multiplied and also can be used to compute mean/variance. Integers are not always the same as real numbers.</p>
<p>In many circumstances the values of numerical attributes are best normalised. They should have zero mean and unit variance.</p>
<script type="math/tex; mode=display">x’ = \frac { x-mean} {std dev}</script>
<p>Sometimes you will want a range [0 1]. This can be achieved using Min-Max normalisation where the value of <script type="math/tex">x</script> falls in the range between 0 to 1.</p>
<script type="math/tex; mode=display">x’=\frac{(x-min)}{(max-min)}</script>
<p>The numerical attributes are sensitive to outliers, i.e. numbers unusually large or small. These outliers must be handled before normalisation. 
For further background reading on this matter, see <a href="https://medium.com/@swethalakshmanan14/how-when-and-why-should-you-normalise-standardize-rescale-your-data-3f083def38ff">How, When and Why Should You Normalise / Standard / Rescale Your Data?</a></p>
<h3 id="skewed-distributions">Skewed distributions</h3>
<p>What is skewed data?  Data is skewed when the curve is distorted or skewed in a statistical distribution.</p>
<p>In other words, they are systematic extreme values. The outliers are not really outliers but they skew the figures. These are exceptional but genuine data points.</p>
<p>For example personal wealth, some people have extreme amounts of wealth compared to the average person.</p>
<p>Such distributions can badly impact regression, kNN &amp; NB(k- Nearest Neighbours and Naive Bayes). Decision Trees are not impacted.</p>
<p>Simple fix is to take <script type="math/tex">\log(x)</script> if dealing with positive numbers only. Alternatively if positive and negative use <script type="math/tex">atan(x)</script> or some other squashing function then normalise.</p>
<p>The graph below shows an example of skewed distribution which has a long tail.</p>
<p><img alt="graph" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/96/8d/hero_968df2ae-ad6d-4561-b016-d55a71443bf5.png" srcset="https://ugc.futurelearn.com/uploads/assets/96/8d/small_hero_968df2ae-ad6d-4561-b016-d55a71443bf5.png 320w, https://ugc.futurelearn.com/uploads/assets/96/8d/hero_968df2ae-ad6d-4561-b016-d55a71443bf5.png 648w, https://ugc.futurelearn.com/uploads/assets/96/8d/large_hero_968df2ae-ad6d-4561-b016-d55a71443bf5.png 729w, https://ugc.futurelearn.com/uploads/assets/96/8d/large_hero_968df2ae-ad6d-4561-b016-d55a71443bf5.png 2x"/></p>
<h3 id="numerical-attributes-non-monotonic-effects">Numerical Attributes: Non-monotonic effects</h3>
<p>So for something like predicting risk of accidents given amount of traffic/unit time on a stretch of road you might imagine something monotonic.</p>
<p>The graph below explains the task of predicting the risk of accidents where it has the probability of accidents per unit time along y-axis and the cars per unit time entering the road along x-axis.</p>
<p><img alt="Graph Probability of accidents per unit time v cars per unit time entering road" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/09/68/hero_0968aeee-27fc-4b6d-92a5-465121cec399.png" srcset="https://ugc.futurelearn.com/uploads/assets/09/68/small_hero_0968aeee-27fc-4b6d-92a5-465121cec399.png 320w, https://ugc.futurelearn.com/uploads/assets/09/68/hero_0968aeee-27fc-4b6d-92a5-465121cec399.png 648w, https://ugc.futurelearn.com/uploads/assets/09/68/large_hero_0968aeee-27fc-4b6d-92a5-465121cec399.png 729w, https://ugc.futurelearn.com/uploads/assets/09/68/large_hero_0968aeee-27fc-4b6d-92a5-465121cec399.png 2x"/></p>
<p><img alt="Graph Probability of accidents per unit time v cars per unit time entering road" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/4b/19/hero_4b19253f-11d2-472d-b986-cc1b54971a41.png" srcset="https://ugc.futurelearn.com/uploads/assets/4b/19/small_hero_4b19253f-11d2-472d-b986-cc1b54971a41.png 320w, https://ugc.futurelearn.com/uploads/assets/4b/19/hero_4b19253f-11d2-472d-b986-cc1b54971a41.png 648w, https://ugc.futurelearn.com/uploads/assets/4b/19/large_hero_4b19253f-11d2-472d-b986-cc1b54971a41.png 729w, https://ugc.futurelearn.com/uploads/assets/4b/19/large_hero_4b19253f-11d2-472d-b986-cc1b54971a41.png 2x"/></p>
<p>However, as the number of cars entering increases, you eventually have gridlock, no movement no accidents, so we have non-monotonic relationship. This affects regression and naïve bayes, for example.</p>
<p>The graph below explains the gridlock situation which creates a non-monotonous relationship between the attributes.</p>
<p><img alt="Graph of Probability of accidents per unit time V Cars per unit entering road" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/2b/31/hero_2b31a3c1-c563-418a-9ec2-880de8f7201d.png" srcset="https://ugc.futurelearn.com/uploads/assets/2b/31/small_hero_2b31a3c1-c563-418a-9ec2-880de8f7201d.png 320w, https://ugc.futurelearn.com/uploads/assets/2b/31/hero_2b31a3c1-c563-418a-9ec2-880de8f7201d.png 648w, https://ugc.futurelearn.com/uploads/assets/2b/31/large_hero_2b31a3c1-c563-418a-9ec2-880de8f7201d.png 729w, https://ugc.futurelearn.com/uploads/assets/2b/31/large_hero_2b31a3c1-c563-418a-9ec2-880de8f7201d.png 2x"/></p>
<p><img alt="Graph of Probability of accidents per unit time V Cars per unit entering road" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/e3/82/hero_e382fef9-c5ac-4c99-a733-c18a935e77c5.png" srcset="https://ugc.futurelearn.com/uploads/assets/e3/82/small_hero_e382fef9-c5ac-4c99-a733-c18a935e77c5.png 320w, https://ugc.futurelearn.com/uploads/assets/e3/82/hero_e382fef9-c5ac-4c99-a733-c18a935e77c5.png 648w, https://ugc.futurelearn.com/uploads/assets/e3/82/large_hero_e382fef9-c5ac-4c99-a733-c18a935e77c5.png 729w, https://ugc.futurelearn.com/uploads/assets/e3/82/large_hero_e382fef9-c5ac-4c99-a733-c18a935e77c5.png 2x"/></p>
<h3 id="the-fix-for-non-monotonic-relationships-with-numerical-attributes">The fix for Non-monotonic relationships with numerical attributes</h3>
<p>The non-monotonic relationship can be fixed by converting the numerical attributes to ordinal variables using quantisation. In practice these conversions are often overlapped.  Machine Learning algorithms can work well with these ordinal variables.</p>
<p>The graph below explains the numerical attributes which are converted to ordinal attributes (10-20),(20-30) along x-axis which solves the non-monotonous relationship between the attributes.</p>
<p><img alt="Graph of Probability of accidents per unit time V cars per unit time entering road" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/fd/f1/hero_fdf12065-2d45-4cd0-bff2-94e30f6bba2d.png" srcset="https://ugc.futurelearn.com/uploads/assets/fd/f1/small_hero_fdf12065-2d45-4cd0-bff2-94e30f6bba2d.png 320w, https://ugc.futurelearn.com/uploads/assets/fd/f1/hero_fdf12065-2d45-4cd0-bff2-94e30f6bba2d.png 648w, https://ugc.futurelearn.com/uploads/assets/fd/f1/large_hero_fdf12065-2d45-4cd0-bff2-94e30f6bba2d.png 729w, https://ugc.futurelearn.com/uploads/assets/fd/f1/large_hero_fdf12065-2d45-4cd0-bff2-94e30f6bba2d.png 2x"/></p>
<p><sub><strong>References</strong></sub></p>
<p><sub>Lakshmanan, S. (2017) ‘How, When and Why Should You Normalize / Standardize / Rescale Your Data?’ <em>Medium</em>, May 19, available: 
https://medium.com/@swethalakshmanan14/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff [accessed 29 Nov 2019]</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.7&emsp;Real world examples</h2><div class="u-typography-bold-intro">
<p>We have seen types of attributes which are possibly useful or at least sound reasonable concepts.</p>
<p>Let’s now see how we might apply these to “things” we want our Machine Learning algorithm to learn about.</p>
<h3 id="so-what-sort-of-things-might-there-be">So what sort of “things” might there be?</h3>
<p>How about recognition of objects in images? Try out the Google Lens app. It allows you to take a photo of something and use that as a basis for a web search. Try it out.</p>
<p>How does that work? Let’s say we took a photo of a cat using Google Lens. What sort of representation do you think was used? At the earliest stage of the machine learning process that representation was a 2-dimensional array of pixel values.</p>
<p>In our research at DCU we have engaged in a task to predict memorability of short video clips. Some features which might require representation here are video frames.</p>
<p>How about memorability? In this case, memorability was simply a number between 0 and 1 which was calculated based on a recall survey carried out on a set of willing experimental subjects who were asked to view the videos.</p>
<p>We have also engaged in research around brain computer interfaces where we use machine learning to learn patterns in brain waves for the purposes of decoding what someone is thinking. This is a classification task.</p>
<p>What sort of representation do you think might have been used there? Discuss in the comments section.</p>
<p>It is clear that some tasks involve things which immediately suggest suitable attribute representations. The personal wealth example in the previous step was one such case. In this instance, you might just use the numerical value of funds available in a bank account which is not too complicated.</p>
<p>In the previous step we talked about converting numerical attributes to ordinal attributes in order to avoid non-monotonous relationships using an example of predicting the risk of accidents considering the number of cars entering per unit time. You might think our cars per unit time example is simple. It is a number such as 5 cars/per unit time, so it is an easy numeric attribute representation. However, if you build such a system where would that number have come from?</p>
<p>Cars exist in the real world, the machine learning algorithm exists in a digital world so how do we go from this real, noisy analog world to the clean and crisp digital domain? We make that transition from the real world to the digital world via sensors and a digitisation process.</p>
<p>We will briefly explore this in the next steps.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.8&emsp;Sensors</h2><div class="u-typography-bold-intro">
<p>As machine learning algorithms have been designed to work on digital computers (unlike our brains which are analogue) we require our inputs to have digital representations.</p>
<p>Once we have these features which we might even term raw features we can work with these to derive even more useful features. But without the basic raw representation of the real world we go nowhere. So, in general, how does this process happen?</p>
<p>We need a sensor and more strictly speaking a transducer as well. A sensor is something that measures some physical quantity such as light, heat, sound, chemical concentration levels, etc in a reliable, dependable way which supports calibration.  It is important that a sensor produces an electrical signal which changes with the physical quantity to be measured.</p>
<p>In many cases sensors come with a transducer part which converts energy from one form to another. Usually they are converting energy into electrical energy. This gives rise to an electrical signal which can readily be used as input for a computer system. For simplicity we will just refer to these things together as sensors.</p>
<p>There are many different types of sensors. Some sensors are directly manipulated using a keyboard or touchscreen to create input.  Other sensors, for example the sensor in the back of your wearable fitness tracker, uses light to measure changes in blood flow at your wrist which must then be feature-engineered to produce a heart rate signal.  Where sensors measure the physical world continuously we need to regularly sample the output and convert to numbers for ingestion into our machine learning process.</p>
<h3 id="please-comment">Please comment!</h3>
<p>In the comments section below tell us about other sensors we haven’t mentioned above. Be sure to ‘like’ or respond to any comments you find particularly interesting.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.9&emsp;Digitisation single sensor</h2><div class="u-typography-bold-intro">
<p>So, we need to convert our sensor into a digital form. How is this achieved?</p>
<p>It is achieved using the process of Analog-to-Digital conversion (ADC). This step involves electronic circuits which take the continuous signal measured by a sensor and sample it at regular intervals. This sampling needs to be done at a rate high enough to faithfully capture the characteristics of the signal. The samples then are represented as digital quantities such as an 8-bit (256 different levels), 16-bit (65,536 different levels), etc. In doing this we have discretised our continuous signal in terms of time and amplitude which involves some loss of information but if done properly this is not a problem.</p>
<p>So what do we end up with when we do this? In many cases when we are working with sensors, say a single sensor, then we end up with a time series of some sort. 
Let’s look at a good example - your wearable fitness tracker  - how does this measure your heart rate? Well it uses an optical sensing method called photoplethysmography (PPG).</p>
<p>A great paper detailing the PPG and how it works can be found <a href="https://iopscience.iop.org/article/10.1088/0967-3334/28/3/R01">here</a>.</p>
<p>The PPG output then is a measure of the received light reflecting back from the tissue under the wrist. It looks like below.</p>
<p><img alt="Graph" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/58/af/hero_58af4ee6-9f1d-4943-847a-992293609094.png" srcset="https://ugc.futurelearn.com/uploads/assets/58/af/small_hero_58af4ee6-9f1d-4943-847a-992293609094.png 320w, https://ugc.futurelearn.com/uploads/assets/58/af/hero_58af4ee6-9f1d-4943-847a-992293609094.png 648w, https://ugc.futurelearn.com/uploads/assets/58/af/large_hero_58af4ee6-9f1d-4943-847a-992293609094.png 729w, https://ugc.futurelearn.com/uploads/assets/58/af/large_hero_58af4ee6-9f1d-4943-847a-992293609094.png 2x"/></p>
<p><img alt="Graph" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/1e/b0/hero_1eb0cdbb-c801-40d0-8395-8074f2495013.png" srcset="https://ugc.futurelearn.com/uploads/assets/1e/b0/small_hero_1eb0cdbb-c801-40d0-8395-8074f2495013.png 320w, https://ugc.futurelearn.com/uploads/assets/1e/b0/hero_1eb0cdbb-c801-40d0-8395-8074f2495013.png 648w, https://ugc.futurelearn.com/uploads/assets/1e/b0/large_hero_1eb0cdbb-c801-40d0-8395-8074f2495013.png 729w, https://ugc.futurelearn.com/uploads/assets/1e/b0/large_hero_1eb0cdbb-c801-40d0-8395-8074f2495013.png 2x"/></p>
<p>Source: <a href="https://www.researchgate.net/figure/ECG-and-PPG-signals-in-one-plot_fig2_261469953">Pulse transition time in heamodynamic measurement: Methods, problems, hardware equipment and first results</a></p>
<p>The corresponding ECG, which is the conventional electrical means of capturing heart activity, is shown in red. This has also been digitized after it was sensed by electrodes attached to the chest and amplified using analog circuitry.</p>
<p>What do you notice about the PPG? It has a regularly repeating pattern. What does that represent? It is the pulsation of blood flow in your arteries associated with the beating of your heart. If you can count how many of these occur in a unit time you have a heart rate estimation. You can then use this in a machine learning algorithm for all sorts of AI tasks. For example, you could build a machine learning system to detect if someone is suffering from heart disease by taking this signal as input along with other potentially useful variables.</p>
<p>It can be seen that this is some sort of signal which is continuously changing. Now we need to ask ourselves how does that become a feature vector that I can process with code? We need to digitise it. We will look at this briefly in the next step.</p>
<p><sub><strong>References:</strong></sub></p>
<p><sub>Allen, J. (2007) ‘Photoplethysmography and its application in clinical physiological measurement’, IOP Science, 28(3), available: https://iopscience.iop.org/article/10.1088/0967-3334/28/3/R01 [accessed 12 Nov 2019]</sub></p>
<p><sub>Dvořák, Jan &amp; Havlík, Jan. (2013). Pulse transition time in heamodynamic measurement: Methods, problems, hardware equipment and first results. 1-3, available: https://www.researchgate.net/publication/261469953_Pulse_transition_time_in_heamodynamic_measurement_Methods_problems_hardware_equipment_and_first_results [accessed 12 Nov 2019]</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.10&emsp;Digitisation array sensors</h2><div class="u-typography-bold-intro">
<p>In the previous step we mentioned the digitisation process.</p>
<p>We digitise real world signals via <a href="https://en.wikipedia.org/wiki/Analog-to-digital_converter">analog-to-digital conversion</a> (ADC). There is also the opposite process called <a href="https://www.britannica.com/technology/digital-to-analog-conversion">digital-to-analog conversion</a> (DAC) which facilitates two way interaction between digital computers and these continuous phenomenon.</p>
<p>As we mentioned previously, ADC processes result in data which is sampled, and quantised. By doing this we turn out a continuous signal into a list of numbers. These can then form the basis for features, although in this time series they are not always the best features but we discuss this later.</p>
<h3 id="sampling">Sampling</h3>
<p>When we speak of sampling we mean that we regularly sample the output of a sensor at some sampling rate. We choose this sample rate to faithfully capture all the interesting changes in the signal. For example, if we use the optical signal in our wearable fitness tracker to estimate heart rate, we might sample at 10 samples per second. Actual sample rates used can be very different for reasons we won’t go into here. So now our heart rate sensor is giving us a new attribute every 100 ms.</p>
<h3 id="quantisation">Quantisation</h3>
<p>We also mention that our sensor output is quantised. What does that mean? Well on a digital computer we store data as data types of different sizes, We could use 8-bit, 16-bit, 32-bit, etc. Whatever the number of bits you use, you are quantising a continuous variable to a discrete one. For example, an 8-bit representation only supports 256 different levels. This means we assign the sensor output the nearest level from the 256 different levels available through the 8-bit representation. In effect we have lost a little bit of certainty about what our original signal was through this process but what we get in return is a consistent, numeric value which we now collect sample by sample.  We refer to this process as quantisation. Hopefully that makes this process which links the real world and our digital world a little clearer.</p>
<p>This ordered list of sample values is our list of attribute values for subsequent processing.</p>
<p>Lets now see what happens with a large array of sensors? This commonly occurs in image capture.</p>
<p>The image sensors which are used in most digital cameras use a <a href="https://en.wikipedia.org/wiki/Charge-coupled_device">charge-coupled device</a> (CCD). This is an image sensor which converts light into electrons by reading the value of the accumulated charge of each cell in the image. The CCD transports the charge across the chip and reads it at one corner of the array. Each pixel value converts to a digital value using ADC which measures the charge at each photosite and converts them into binary form.
The CCD sensors create high-quality, low noise images. However, they consume a considerable amount of power when compared to <a href="https://www.britannica.com/technology/complementary-metal-oxide-semiconductor">complementary metal oxide semiconductor</a> (CMOS) sensors. CCD sensors are more mature because they have been mass produced for a longer period of time and they tend to have high quality pixels.</p>
<p>If we take data from this CCD sensor array over time what do we get? A video of course. So we now have an understanding of some basic ideas in sensor processing and the origin of signals, images and video.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.12&emsp;Review of Topic 2</h2><div class="u-typography-bold-intro">
<p>Congratulations on completing Topic 2.</p>
<p>In this topic you have learned about the background to real data and its sources in various forms of sensors.</p>
<p>We began with a basic exposition on different variable types that we commonly use in machine learning problems. We learned about numerical data types, categorical data types and ordinal data.</p>
<p>Hopefully you will be able to reflect effectively on how best to harness different variable types for different problems.</p>
<p>Much more fun has been a brief introduction to sensors in the real world as sources of data. From health sensors to cameras we considered how the real world is translated into 1’s and 0’s for machine learning purposes.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p style="page-break-before: always"><h2>3.1&emsp;Welcome to Topic 3</h2><div class="u-typography-bold-intro">
<p>Hello everyone, in the last topic we spent some time looking at feature vectors for the purposes of machine learning.</p>
<p>We looked in particular at attribute-value pairs and different variable types which are commonly found in the context of such attributes. Our examples included categorical features, ordinal features, text and numerical features.</p>
<p>In this topic we are going to look at bringing this closer to the real world through examining some practical examples of data representation as they can occur with real world machine learning tasks.  We shall examine suitable feature representations for images, text and time series. Taken together these should give you an appreciation for the data representation challenge and the importance of giving attention to this stage of the machine learning development process.</p>
<p>We’ll look at bringing together the basics of attribute-values pairs we examined in the last topic, as well as practical machine learning task examples, to see how data representation happens in practice. We will go through a few representative examples such as:</p>
<ul>
<li>
<p>Image representation</p>
</li>
<li>
<p>Text representation</p>
</li>
<li>
<p>Time series</p>
</li>
<li>
<p>Video representation</p>
</li>
</ul>
<p>We cannot go into enormous depth on this topic and the examples we’ll develop are introductory in terms of their sophistication. However they will give you a clear picture of how different data representations are necessary for different types of data sources. We will see for example some of the features suitable for working with text and documents are very different in nature to those we might use for image representation. Let’s take a closer look.</p>
</div><p><h2>3.2&emsp;Images</h2><div class="u-typography-bold-intro">
<p>In this step, we will try to understand suitable representations for images. We will do this via an example.</p>
<p>During the last topic we mentioned an example of predicting road accident risk in real time based on a measure of traffic density as measured by cars/unit time on some stretch of road.</p>
<p>Before we even get to the machine learning task of predicting road accident risk which is a regression task, we have another machine learning task to undertake. This consists of taking the image stream from the traffic monitoring cameras and outputting an estimate of cars/per unit time.</p>
<p>We could of course count them manually, i.e. manual annotation, but here we might want to automate this boring job through AI. Let’s see what sort of data representation might be effective for such a challenge.</p>
<p>Let’s have a think about this cars per unit time task. Let’s imagine we have a traffic camera. For example, we show an image below from the cameras that are used on some of the roads around Dublin city in Ireland. How do we extract that useful attribute of “cars/unit time” which we need for our regression task?</p>
<p>It is not easy – we will first need to produce this attribute as the output of a preliminary machine learning task which takes each frame from the camera and estimates the numbers of cars in the picture. What are the good image attributes to use for the Machine Learning task of estimating the number of cars in a frame?</p>
<p>First of all, we see that traffic depends on the direction. Here there is significant traffic in one direction  and not much in the other – so maybe one idea is to split the image in two, notwithstanding the bend in the road. It is a fixed camera so we don’t need a clever algorithm for this. We could even “hardcode” this split.</p>
<p>What do we need to do then? It’s not obvious. We might need to “park” this problem for a moment and come back to it later. Let’s detour to something a little easier.</p>
<p><img alt="image of a motorway with various models of transportation" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/81/6e/hero_816e5ec8-e761-41e4-a617-a4ae67a4917d.png" srcset="https://ugc.futurelearn.com/uploads/assets/81/6e/small_hero_816e5ec8-e761-41e4-a617-a4ae67a4917d.png 320w, https://ugc.futurelearn.com/uploads/assets/81/6e/hero_816e5ec8-e761-41e4-a617-a4ae67a4917d.png 648w, https://ugc.futurelearn.com/uploads/assets/81/6e/large_hero_816e5ec8-e761-41e4-a617-a4ae67a4917d.png 729w, https://ugc.futurelearn.com/uploads/assets/81/6e/large_hero_816e5ec8-e761-41e4-a617-a4ae67a4917d.png 2x"/>
<sub>Source: <a href="https://www.tii.ie/">Transport Infrastructure Ireland</a></sub></p>
<p>Let’s start with a simpler image-based problem. How about handwritten digits? How does machine learning recognise handwritten characters?</p>
<p>The image below shows the handwritten characters of numbers from 0 to 9 from the MNIST database.</p>
<p><img alt="Handwritten numbers. 16 in each row from 0 to 9" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/6f/01/hero_6f0175ed-82e6-4368-93ee-8de706612de0.png" srcset="https://ugc.futurelearn.com/uploads/assets/6f/01/small_hero_6f0175ed-82e6-4368-93ee-8de706612de0.png 320w, https://ugc.futurelearn.com/uploads/assets/6f/01/hero_6f0175ed-82e6-4368-93ee-8de706612de0.png 648w, https://ugc.futurelearn.com/uploads/assets/6f/01/large_hero_6f0175ed-82e6-4368-93ee-8de706612de0.png 729w, https://ugc.futurelearn.com/uploads/assets/6f/01/large_hero_6f0175ed-82e6-4368-93ee-8de706612de0.png 2x"/></p>
<p>Source: <a href="https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png">Wikimedia</a></p>
<h3 id="handwritten-character-recognition">Handwritten character recognition</h3>
<p>Originally motivated by the need to automate zip code reading in the US postal service, handwritten character recognition was used to recognize the digits in the zip code in order to ensure the efficient delivery of  emails.</p>
<p>When it comes to the handwritten zip  code on envelopes we have:</p>
<ul>
<li>Variable colours of ink</li>
<li>Variable size</li>
<li>Variable handwriting style</li>
<li>Variations in digit representations looks at 8s for example – thick pen obscures loops</li>
<li>Lots and lots of variation – although humans recognize it very well</li>
</ul>
<p>What is a good possible representation for these digits?
Let’s scan it first and we end up with a bitmap and take it from there.</p>
<p>Each handwritten character is made up of 28 X 28 pixels. So we have 28 x 28 pixels which is 784 attributes. Each pixel can be RGB value, or if we consider just grayscale then 0-255 levels (8 bit per pixel) where 255 is black and 0 is white. Could also convert them to simply black and white through thresholding and attributes have values of 0 or 1. In any case we have a list of 784 attributes . 
For example:<br/>
<script type="math/tex">D = d_1, d_2, d_3, ...d_783, d_784</script>. Each pixel (<script type="math/tex">d_1, d_2, d_3</script>…) corresponds to an attribute.</p>
<p><img alt="Real time numbers recognition (MNIST) on an iPhone with CoreML from A to Z" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/9a/7c/hero_9a7c513c-4701-4f70-8468-c304b1896bd9.png" srcset="https://ugc.futurelearn.com/uploads/assets/9a/7c/small_hero_9a7c513c-4701-4f70-8468-c304b1896bd9.png 320w, https://ugc.futurelearn.com/uploads/assets/9a/7c/hero_9a7c513c-4701-4f70-8468-c304b1896bd9.png 648w, https://ugc.futurelearn.com/uploads/assets/9a/7c/large_hero_9a7c513c-4701-4f70-8468-c304b1896bd9.png 729w, https://ugc.futurelearn.com/uploads/assets/9a/7c/large_hero_9a7c513c-4701-4f70-8468-c304b1896bd9.png 2x"/></p>
<p>Source: <a href="https://www.liip.ch/en/blog/numbers-recognition-mnist-on-an-iphone-with-coreml-from-a-to-z">L//P blog</a></p>
<p>Pixels are good attributes for this problem. These are the averaged digits from the MNIST database of 60,000 digits.</p>
<h3 id="what-do-you-notice-in-the-image-above">What do you notice in the image above?</h3>
<p>Machine vision methods mean we can easily extract a digit, scale and fit to a bounding box such that we have 28 x 28 pixels and can centre it. As a result, the pixels have a strong relationship with the digits.</p>
<p>For example, the very centre pixel is always white for a zero and always black for an 8. So if we see that the centre pixel is white it is very likely that it is NOT a zero, right? 
It could be an 8 or indeed a 1 or a 3 etc., but very unlikely a 0. So we can build a probability distribution based on the pixels.</p>
<p><img alt="Distorted numbers image" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/1b/dc/hero_1bdc313d-f464-4e66-b0d7-2093c2207b31.png" srcset="https://ugc.futurelearn.com/uploads/assets/1b/dc/small_hero_1bdc313d-f464-4e66-b0d7-2093c2207b31.png 320w, https://ugc.futurelearn.com/uploads/assets/1b/dc/hero_1bdc313d-f464-4e66-b0d7-2093c2207b31.png 648w, https://ugc.futurelearn.com/uploads/assets/1b/dc/large_hero_1bdc313d-f464-4e66-b0d7-2093c2207b31.png 729w, https://ugc.futurelearn.com/uploads/assets/1b/dc/large_hero_1bdc313d-f464-4e66-b0d7-2093c2207b31.png 2x"/></p>
<p>Source: <a href="http://varianceexplained.org/r/digit-eda/">David Robinson</a></p>
<p>These look pretty consistent and suggest our pixel attributes will work well for this problem. So maybe pixels and their values are good enough for our original image task? Let’s return there. By the way, for these digits we are considering each digit to exist in a 784-dimensional space and relying on structure in that space per digit for our machine learning to work. In machine learning we often have to think of very high dimensional spaces which are obviously difficult to visualise. So, I suggest you take a look at this short 3 minute video below from the Google AI team which deals with this very issue. Many people have found it helpful.
</p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<p><sub><strong>References:</strong></sub></p>
<p><sub>Robinson, D. (2018) ‘Exploring handwritten digit classification: a tidy analysis of the MNIST dataset’ Variance Explained, 22 Jan,available: http://varianceexplained.org/r/digit-eda/ [accessed 18 Nov 2019]<sub></sub></sub></p>
<p><sub>T. (2018) ‘Real time numbers recognition (MNIST) on an iPhone with CoreML from A to Z’, <em>L//P</em>, 23 Oct, available: https://www.liip.ch/en/blog/numbers-recognition-mnist-on-an-iphone-with-coreml-from-a-to-z [accessed 25 Nov 2019]<sub></sub></sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.3&emsp;The problem with pixels</h2><div class="u-typography-bold-intro">
<p>So far so good with pixels.</p>
<p>Now let’s examine pixels as the fundamental representation for our original problem, which was essentially counting cars in an image.</p>
<p>Look at the image again. Imagine subsequent images which will contain cars in different positions in the frame. Pixels now have a much less clear relationship with the object we are trying to recognize compared to our handwritten digits challenge.  As well as looking for discrete cars, we might even want to recognize trucks or buses rather than cars. We want vehicles. The vehicles have different orientations in different parts of the images. There are different makes and models of cars and trucks, with differences, including colours. However, they still retain an overall vehicle-like property.</p>
<p>Far away vehicles look smaller than close up vehicles. Vehicles are viewed from the rear on the right hand side and from the front on the left hand side.</p>
<p>Look at shadows too, these change during the day as does light levels. Notice vehicles obstructing the view of other vehicles. The relationships with the raw pixels is definitely not trivial. It looks like we need some higher level attributes which emerge from pixels and their spatial relationships.</p>
<p><img alt="image of motorway with various models using it" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/f6/b4/hero_f6b424c0-0bbd-4777-91a1-2e87b82fb90f.png" srcset="https://ugc.futurelearn.com/uploads/assets/f6/b4/small_hero_f6b424c0-0bbd-4777-91a1-2e87b82fb90f.png 320w, https://ugc.futurelearn.com/uploads/assets/f6/b4/hero_f6b424c0-0bbd-4777-91a1-2e87b82fb90f.png 648w, https://ugc.futurelearn.com/uploads/assets/f6/b4/large_hero_f6b424c0-0bbd-4777-91a1-2e87b82fb90f.png 729w, https://ugc.futurelearn.com/uploads/assets/f6/b4/large_hero_f6b424c0-0bbd-4777-91a1-2e87b82fb90f.png 2x"/></p>
<p>The issue here is that the pixels in terms of their location, do not encode anything that makes different snapshots of cars more similar than say for other things in the frame.  It is more subtly distributed over the pixels.</p>
<p>We need some attributes that make all the different variations of cars (at different scales, colours, distances, orientations, etc.) more robustly similar. Ask yourself, when you look at the image to describe what features you believe are allowing you to be certain which things are cars. Which things are trucks and which things are just road fittings?</p>
<h3 id="alternatives-to-pixels-as-attributes">Alternatives to Pixels as Attributes</h3>
<p>So how should we represent the data in the image here?</p>
<p>We have a bitmap as raw input and let’s assume we use a more rudimentary machine learning algorithm to put suitable bounding boxes around objects that might be cars (we won’t say how, but perhaps we have a blocky <a href="https://en.wikipedia.org/wiki/Blob_detection">blob detector</a> sort of machine vision algorithm).</p>
<p><img alt="Image of vehicles on a a motorway with a car marked in a Green box" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/d4/2c/hero_d42c1918-b5a5-44a2-9afc-44846ea8531c.JPG" srcset="https://ugc.futurelearn.com/uploads/assets/d4/2c/small_hero_d42c1918-b5a5-44a2-9afc-44846ea8531c.JPG 320w, https://ugc.futurelearn.com/uploads/assets/d4/2c/hero_d42c1918-b5a5-44a2-9afc-44846ea8531c.JPG 648w, https://ugc.futurelearn.com/uploads/assets/d4/2c/large_hero_d42c1918-b5a5-44a2-9afc-44846ea8531c.JPG 729w, https://ugc.futurelearn.com/uploads/assets/d4/2c/large_hero_d42c1918-b5a5-44a2-9afc-44846ea8531c.JPG 2x"/></p>
<p>Figure: Example of a possible vehicle type entity extracted in the image.</p>
<p>There are lots of ways a machine vision course would teach you many many methods. For now we just want to get the concept. Below we see a car possibility.</p>
<p><img alt="distorted car image" src="https://ugc.futurelearn.com/uploads/assets/53/eb/53ebc02f-0fda-40f0-893c-eceb6c667bb1.png"/></p>
<p>We then need to go from this smaller bitmap to a list of attributes (which we will begin to call vectors for the rest of the course) which capture car-like visual appearance.</p>
<p>So, let’s state one thing. Cars seem to be ”boxy”. Let’s apply a horizontally oriented box detection algorithm similar to what we did to extract that car originally.</p>
<p>We see a group of boxes, smaller ones nested inside smaller ones. If we normalized the area of boxes to the largest box we might have a set of attributes based on area, number of boxes, that might be common enough among all cars? Perhaps…definitely an improvement over taking raw pixels as features.</p>
<p><img alt="Distorted image of car with a green box surround the car and two smaller green boxes in the larger box" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/41/bd/hero_41bdceac-6a9e-429d-85f1-991b76fc2a54.JPG" srcset="https://ugc.futurelearn.com/uploads/assets/41/bd/small_hero_41bdceac-6a9e-429d-85f1-991b76fc2a54.JPG 320w, https://ugc.futurelearn.com/uploads/assets/41/bd/hero_41bdceac-6a9e-429d-85f1-991b76fc2a54.JPG 648w, https://ugc.futurelearn.com/uploads/assets/41/bd/large_hero_41bdceac-6a9e-429d-85f1-991b76fc2a54.JPG 729w, https://ugc.futurelearn.com/uploads/assets/41/bd/large_hero_41bdceac-6a9e-429d-85f1-991b76fc2a54.JPG 2x"/></p>
<h3 id="other-attributes">Other Attributes</h3>
<p>After our segmentation we might look at other things. For example, if we look at the medium sized box, i.e. the window, this is always pretty dark, so maybe the colour of this box is something we might use. The number plate - the smallest box - is whiteish, while the outer box has a lot more variability.</p>
<p>Maybe some measure of colour is a feature to associate with each box? These are all good ideas. What we are ultimately striving for here is to have similar objects having similar feature representations.</p>
<p>We are getting somewhere now - this is the start of a representation that might be useful. We have had to work on it but its getting there.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.4&emsp;Attribute structure</h2><div class="u-typography-bold-intro">
<p>Let’s go further with our example.</p>
<p>We have been playing with the idea in this very particular case, and it’s a fairly arbitrary representation decision, that we are going to look at patches of the image based on some sort of block paradigm. Within each patch we are developing our own (naive) feature concept that we believe will work for cars based on say the presence of rectangular geometry in the image. It has potential but rectangles abound in this image.</p>
<p>Is there anything else special about the rectangular blocks in our vehicle candidates which serves to distinguish them from other entities in the image? Let’s try something. Let us look at the utility of attribute structure.</p>
<p><img alt="image of motorway with vehicles driving with Gantry above and 
 a distorted image of a car with a green marked line around it and 2 smaller green boxes in the big green box" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/cf/c9/hero_cfc9280b-aa47-410e-b602-09dbdf2ccb13.png" srcset="https://ugc.futurelearn.com/uploads/assets/cf/c9/small_hero_cfc9280b-aa47-410e-b602-09dbdf2ccb13.png 320w, https://ugc.futurelearn.com/uploads/assets/cf/c9/hero_cfc9280b-aa47-410e-b602-09dbdf2ccb13.png 648w, https://ugc.futurelearn.com/uploads/assets/cf/c9/large_hero_cfc9280b-aa47-410e-b602-09dbdf2ccb13.png 729w, https://ugc.futurelearn.com/uploads/assets/cf/c9/large_hero_cfc9280b-aa47-410e-b602-09dbdf2ccb13.png 2x"/></p>
<p>In the image above let us say we are wondering if the highlighted section of the gantry could be confused with a car. We extract it as below and blow it up to take a look side by side with our typical vehicle image.</p>
<p><img alt="3 green marked boxes on Gantry above motorway and a car marked with 3 green boxes driving on a motorway" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/91/1a/hero_911a35c4-e569-45ed-96f4-236e01623326.png" srcset="https://ugc.futurelearn.com/uploads/assets/91/1a/small_hero_911a35c4-e569-45ed-96f4-236e01623326.png 320w, https://ugc.futurelearn.com/uploads/assets/91/1a/hero_911a35c4-e569-45ed-96f4-236e01623326.png 648w, https://ugc.futurelearn.com/uploads/assets/91/1a/large_hero_911a35c4-e569-45ed-96f4-236e01623326.png 729w, https://ugc.futurelearn.com/uploads/assets/91/1a/large_hero_911a35c4-e569-45ed-96f4-236e01623326.png 2x"/></p>
<p>This is a little artificial, but if somehow we got the three boxes on the left, they would seem to have similar relative areas to the boxes in a genuine car – what actually distinguishes them?</p>
<p>Take a good look at the images beside each other.</p>
<p>If we have a flat structure for the attributes then the corresponding attributes vector is:</p>
<p><img alt="3 Green empty boxes on the left hand side of the diagram and 3 green boxes on the right hand side of the diagram" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/53/52/hero_53527f0c-4e16-48b8-a851-6c073f163247.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/53/52/small_hero_53527f0c-4e16-48b8-a851-6c073f163247.PNG 320w, https://ugc.futurelearn.com/uploads/assets/53/52/hero_53527f0c-4e16-48b8-a851-6c073f163247.PNG 648w, https://ugc.futurelearn.com/uploads/assets/53/52/large_hero_53527f0c-4e16-48b8-a851-6c073f163247.PNG 729w, https://ugc.futurelearn.com/uploads/assets/53/52/large_hero_53527f0c-4e16-48b8-a851-6c073f163247.PNG 2x"/></p>
<p>Also, did I not say we might normalise to the largest square in each sub image? If not, I am saying we will do it now. Can you think why it is a good idea? (think of vehicles near and far). Let us also say our value for each rectangle is simply its area. In this case I could use squares rather than rectangles and graphically represent the feature vectors are.</p>
<p><img alt="3 Green empty boxes on the left hand side of the diagram with a bracket surrounding them and D1 written outside bracket and 3 green boxes on the right hand side of the diagram with a bracket surrounding the boxes and D2 written outside the bracket" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/07/e0/hero_07e01535-c592-4128-9e80-358e121b6e97.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/07/e0/small_hero_07e01535-c592-4128-9e80-358e121b6e97.PNG 320w, https://ugc.futurelearn.com/uploads/assets/07/e0/hero_07e01535-c592-4128-9e80-358e121b6e97.PNG 648w, https://ugc.futurelearn.com/uploads/assets/07/e0/large_hero_07e01535-c592-4128-9e80-358e121b6e97.PNG 729w, https://ugc.futurelearn.com/uploads/assets/07/e0/large_hero_07e01535-c592-4128-9e80-358e121b6e97.PNG 2x"/></p>
<p>So these relative areas as attributes are a lot similar looking right?</p>
<p>Maybe we should bring in aspect ratio, i.e. rectangular nature seems important but what about the nested nature of the boxes  - that was clearly important - so how do we do that?</p>
<h3 id="integrating-structure-in-our-attributes">Integrating structure in our attributes</h3>
<ul>
<li>
<p>If we have each attribute considered in isolation we are missing 
 out on some important information potentially.</p>
</li>
<li>
<p>So we need to embed this structure in the attributes.</p>
<ul>
<li>We could, for example, use a tree structure and the attributes are the root to the leaf path.  Let’s say a node is a leaf of a tree, if the shape is contained within the node above. Let’s look at our car recognition problem. We call a large rectangle ’A’, a medium rectangle ‘B’ and a small rectangle ‘C’.</li>
</ul>
</li>
</ul>
<h3 id="example-of-our-car">Example of our car</h3>
<p><img alt="3 green marked boxes on overheard Gantry above motorway with separated boxes of A B C on the same line and a car marked with 3 green boxes driving on a motorway with a TRIANGLE diagram of A B C and arrows pointing from the A to the B and C   with sepaarate ABC box with 0's and 1's in with A B &amp; C forumula's in" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/71/9f/hero_719fcf6d-fda5-4650-ac2a-369e0bd65fe9.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/71/9f/small_hero_719fcf6d-fda5-4650-ac2a-369e0bd65fe9.PNG 320w, https://ugc.futurelearn.com/uploads/assets/71/9f/hero_719fcf6d-fda5-4650-ac2a-369e0bd65fe9.PNG 648w, https://ugc.futurelearn.com/uploads/assets/71/9f/large_hero_719fcf6d-fda5-4650-ac2a-369e0bd65fe9.PNG 729w, https://ugc.futurelearn.com/uploads/assets/71/9f/large_hero_719fcf6d-fda5-4650-ac2a-369e0bd65fe9.PNG 2x"/></p>
<p>Now, even with a simple set of very naive features based on boxes and relative areas in the image along with a notion of structure among these features we are beginning to see a feature set of small dimension (compare this to the 1000s of pixels originally) which might be useful for “car-like things”. These features might be a good starting point for developing  a machine learning algorithm to recognise cars in the image.</p>
<p>Clearly this is still not a trivial task, but what we have seen here are the sort of issues we have in terms of image representation and some solutions based on the creation of higher level features. We had to put a bit of feature engineering effort into this and you might even feel it is a bit of a hand crafted step given how it has been presented….and you would be correct!</p>
<p>The good news is that some of the most exciting Machine Learning techniques today, in particular deep learning methods based on convolutional neural networks, if given enough data, can automatically do this step themselves, i.e. you just present the raw images as input. But we are a long way at this point from talking about such technologies.</p>
<p>Let’s continue our data representation journey knowing that we have at least some idea of what we can do with images at this point.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.5&emsp;Text processing</h2><div class="u-typography-bold-intro">
<p>We are now going to look at suitable representations for text.</p>
<p>One useful representation in text processing is to use something called a “bag of words” representation. With this representation, we have a dictionary of all the words which are involved in a set of documents and our attribute-value pairs now consist of each of these words and the number of times each word appears in the document. Take a look at this Wikipedia article which describes the <strong>bag-of-words model</strong> <a href="https://en.wikipedia.org/wiki/Bag-of-words_model">here</a>.</p>
<p>This is a good description and you should certainly refer to it when it comes to your practical sessions in future weeks and in the assignment. Don’t forget!</p>
<p>We can use this bag of words representation to do useful things. We could stop here now that we have established a representation for text, e.g. the “bag of words” representation. However, let’s apply this in a machine learning task. By doing this you will appreciate the utility of the representation when used in a relevant machine learning task. You may also find this useful in your assignment.</p>
<p>So let’s go further and start with a task. Say we are doing an information retrieval task and we are looking for documents online which write about the same topic. We need to look at the similarity between these documents based on the words they contain. One idea is to develop similarity measures based on occurrence of words.</p>
<p><img alt="historic text" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/18/d2/hero_18d2b7a6-d7eb-4c9d-98ea-3d07e91be267.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/18/d2/small_hero_18d2b7a6-d7eb-4c9d-98ea-3d07e91be267.PNG 320w, https://ugc.futurelearn.com/uploads/assets/18/d2/hero_18d2b7a6-d7eb-4c9d-98ea-3d07e91be267.PNG 648w, https://ugc.futurelearn.com/uploads/assets/18/d2/large_hero_18d2b7a6-d7eb-4c9d-98ea-3d07e91be267.PNG 729w, https://ugc.futurelearn.com/uploads/assets/18/d2/large_hero_18d2b7a6-d7eb-4c9d-98ea-3d07e91be267.PNG 2x"/>
<sub>Source: <a href="https://www.testprepreview.com/modules/reading1.htm">TPR</a></sub></p>
<p>In the above text the words ”Magellan”,“Portugal” and “Spain” appear. Below we’ll highlight these key words and the number of times they occur in these texts.</p>
<p>In both texts the same words are mentioned as follows:</p>
<table>
<thead>
<tr>
<th>Word</th>
<th>Text 1 mentions</th>
<th>Text 2 mentions</th>
</tr>
</thead>
<tbody>
<tr>
<td>Magellan</td>
<td>1</td>
<td>2</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr>
<td>Portugal</td>
<td>2</td>
<td>1</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr>
<td>Spain</td>
<td>1</td>
<td>2</td>
</tr>
</tbody>
</table>
<p><img alt="historic text" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/f0/29/hero_f029f508-e5b7-4b46-9442-1ecde35b98cf.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/f0/29/small_hero_f029f508-e5b7-4b46-9442-1ecde35b98cf.PNG 320w, https://ugc.futurelearn.com/uploads/assets/f0/29/hero_f029f508-e5b7-4b46-9442-1ecde35b98cf.PNG 648w, https://ugc.futurelearn.com/uploads/assets/f0/29/large_hero_f029f508-e5b7-4b46-9442-1ecde35b98cf.PNG 729w, https://ugc.futurelearn.com/uploads/assets/f0/29/large_hero_f029f508-e5b7-4b46-9442-1ecde35b98cf.PNG 2x"/>
<sub>Source: <a href="https://www.testprepreview.com/modules/reading1.htm">TPR</a></sub></p>
<p>Now we’ll look at some words which are not so specific to the stories. They are only tangentially related and you would expect to see these in many texts. We have:</p>
<p><em>led</em><br/>
<em>became</em><br/>
<em>more</em><br/>
<em>later</em></p>
<p>We also have the sort of everyday words we would use in any conversation on any topic. Words such as “the” “of”, “is”, “when”, etc. These words don’t carry any topical information. They are not useful to us.</p>
<p>Finally we include a separate list for the words that are unique to each text.</p>
<table>
<thead>
<tr>
<th>Only in text 1</th>
<th>Common to both texts</th>
<th>Only in text 2</th>
</tr>
</thead>
<tbody>
<tr>
<td>century</td>
<td><strong>Magellan</strong></td>
<td>papal</td>
</tr>
<tr>
<td>age</td>
<td><strong>Portugal</strong></td>
<td>assigned</td>
</tr>
<tr>
<td>great</td>
<td><strong>Spain</strong></td>
<td>world</td>
</tr>
<tr>
<td>marine</td>
<td><em>led</em></td>
<td>degrees</td>
</tr>
<tr>
<td>terrestrial</td>
<td><em>became</em></td>
<td>land</td>
</tr>
<tr>
<td>exploration</td>
<td><em>more</em></td>
<td>prove</td>
</tr>
<tr>
<td>let</td>
<td><em>later</em></td>
<td>Spanish</td>
</tr>
<tr>
<td>first</td>
<td> </td>
<td>sail</td>
</tr>
<tr>
<td>expedition</td>
<td> </td>
<td>topography</td>
</tr>
<tr>
<td>intrigue</td>
<td> </td>
<td>search</td>
</tr>
<tr>
<td>court</td>
<td> </td>
<td>route</td>
</tr>
<tr>
<td>lost</td>
<td> </td>
<td>decree</td>
</tr>
<tr>
<td>king</td>
<td> </td>
<td>land</td>
</tr>
<tr>
<td>favor</td>
<td> </td>
<td>west</td>
</tr>
<tr>
<td>dismissed</td>
<td> </td>
<td>longitude</td>
</tr>
<tr>
<td>young</td>
<td> </td>
<td>east</td>
</tr>
<tr>
<td>Portuguese</td>
<td> </td>
<td>east indies</td>
</tr>
<tr>
<td>noble</td>
<td> </td>
<td>authority</td>
</tr>
<tr>
<td>served</td>
<td> </td>
<td>ships</td>
</tr>
<tr>
<td>became</td>
<td> </td>
<td>South America</td>
</tr>
<tr>
<td>involved</td>
<td> </td>
<td>water</td>
</tr>
<tr>
<td>quagmire</td>
<td> </td>
<td>continent</td>
</tr>
<tr>
<td>political</td>
<td> </td>
<td> </td>
</tr>
<tr>
<td>service</td>
<td> </td>
<td> </td>
</tr>
<tr>
<td>offered</td>
<td> </td>
<td> </td>
</tr>
<tr>
<td>future</td>
<td> </td>
<td> </td>
</tr>
<tr>
<td>Emperor</td>
<td> </td>
<td> </td>
</tr>
<tr>
<td>Charles</td>
<td> </td>
<td> </td>
</tr>
<tr>
<td>after</td>
<td> </td>
<td> </td>
</tr>
</tbody>
</table>
<p>Given this observation of how words are distributed across the two documents we can construct a feature vector based on occurrence of significant words which appear to relate to similarity of content in a document. We won’t develop this too deeply in this course but you can appreciate now how such a feature vector can characterise a document to some degree. This is the basis of the bag of words approach.</p>
<p>Having learnt about the ‘bag-of words’, how can we combine these texts into a similarity measure in order to measure the similarity of these documents, which will ultimately be regarded as a machine learning task?</p>
<p>We look at approaches for this similarity measure in the next step.</p>
<p><sub><strong>References</strong></sub></p>
<p><sub>TPR, Online Practice Tests (2019) ‘<em>Reading Comprehension Practice Test 1</em>’, available: https://www.testprepreview.com/modules/reading1.htm [accessed 13 Nov 2019]
</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.6&emsp;Vector space model</h2><div class="u-typography-bold-intro">
<p>We use the concept of a vector space model to establish a similarity measure.</p>
<p>With such an approach every document is a feature vector in some high dimensional space -  documents, captions, queries, etc. Words will often be the coordinate vectors in this vector space.</p>
<h3 id="questions-to-answerissues-to-consider">Questions to answer/issues to consider</h3>
<ul>
<li>What are the dimensions of that space (basis vectors)?</li>
<li>How to project documents/captions/queries to that space?</li>
<li>How to compare things in this space?</li>
</ul>
<p>The vector space model is our approach for doing this. To do this:</p>
<ul>
<li>We need to figure out the coordinate vectors</li>
<li>We need to project to that vector space and finally once we have everything up 
there how do we measure similarity?</li>
</ul>
<h3 id="dimensions">Dimensions</h3>
<p>What are the dimensions and coordinate vectors that we can use for a vector space here?</p>
<p>The way it is done is to use each word in the vocabulary as the basis. Clearly this is not an orthogonal basis, as words are not “independent” of each other. Also the dimensionality of the space is the same size as the vocabulary. There it is huge and growing as vocabulary expands. So it has all sorts of problems. However it turns out that it is still pretty effective and is the standard approach often used.</p>
<p>If this explanation is unclear for you take a look at the <a href="https://en.wikipedia.org/wiki/Vector_space_model">Vector Space Model</a> wikipedia entry which spends more time developing the idea.</p>
<h3 id="basic-vector-space-with-words-as-dimensions">Basic vector space with words as dimensions</h3>
<p>Here we adopt the basic vector space model where words are the coordinate vectors where every document is mapped to a point in this vector space.</p>
<p>The value along each dimension corresponds to the number of times that word appears in the document, for example distance moved along the “Tulip” axis is the number of times the word “Tulip” occurs in the document.  We express the coordinates in the order of Lily, Tulip and Rose. So the first coordinate tells you how many times the word Lily occurs, the second coordinate tells you how many times the word Tulip appears and finally the third coordinate tells you how many times the word Rose appears in the document.</p>
<p><img alt="basic vector space model diagram where words are the coordinate vectors - Rose Lily Tulip" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/5c/59/hero_5c596354-062e-46da-a132-ac5c971c15d3.png" srcset="https://ugc.futurelearn.com/uploads/assets/5c/59/small_hero_5c596354-062e-46da-a132-ac5c971c15d3.png 320w, https://ugc.futurelearn.com/uploads/assets/5c/59/hero_5c596354-062e-46da-a132-ac5c971c15d3.png 648w, https://ugc.futurelearn.com/uploads/assets/5c/59/large_hero_5c596354-062e-46da-a132-ac5c971c15d3.png 729w, https://ugc.futurelearn.com/uploads/assets/5c/59/large_hero_5c596354-062e-46da-a132-ac5c971c15d3.png 2x"/></p>
<p><img alt="vector space mode; diagram where words are the coordinate Vectors Rose Lily Tulip Arrow pointing upwards D1 position" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/cf/8a/hero_cf8abca4-a833-46fa-b5c8-a4985906a901.png" srcset="https://ugc.futurelearn.com/uploads/assets/cf/8a/small_hero_cf8abca4-a833-46fa-b5c8-a4985906a901.png 320w, https://ugc.futurelearn.com/uploads/assets/cf/8a/hero_cf8abca4-a833-46fa-b5c8-a4985906a901.png 648w, https://ugc.futurelearn.com/uploads/assets/cf/8a/large_hero_cf8abca4-a833-46fa-b5c8-a4985906a901.png 729w, https://ugc.futurelearn.com/uploads/assets/cf/8a/large_hero_cf8abca4-a833-46fa-b5c8-a4985906a901.png 2x"/></p>
<p>So we see the document <script type="math/tex">D1</script> which is simply a short piece of text, i.e. “rose rose rose” maps to the point (0,0,3) in this vector space.</p>
<p><img alt="vector space mode; diagram where words are the coordinate Vectors Rose Lily Tulip Arrow pointing upwards D1 position D2 position is also placed on this vector" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/ce/98/hero_ce982d27-7538-479c-a898-5da370c3b50d.png" srcset="https://ugc.futurelearn.com/uploads/assets/ce/98/small_hero_ce982d27-7538-479c-a898-5da370c3b50d.png 320w, https://ugc.futurelearn.com/uploads/assets/ce/98/hero_ce982d27-7538-479c-a898-5da370c3b50d.png 648w, https://ugc.futurelearn.com/uploads/assets/ce/98/large_hero_ce982d27-7538-479c-a898-5da370c3b50d.png 729w, https://ugc.futurelearn.com/uploads/assets/ce/98/large_hero_ce982d27-7538-479c-a898-5da370c3b50d.png 2x"/></p>
<p>The document <script type="math/tex">D2</script> which is just the text “Rose Tulip” maps to (0,1,1)</p>
<p><img alt="vector space mode; diagram where words are the coordinate Vectors Rose Lily Tulip Arrow pointing upwards D1 position D2 and D3 positions are also placed on this vector" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/1a/26/hero_1a26b8e2-af84-4c3c-836e-6e8b3e67c199.png" srcset="https://ugc.futurelearn.com/uploads/assets/1a/26/small_hero_1a26b8e2-af84-4c3c-836e-6e8b3e67c199.png 320w, https://ugc.futurelearn.com/uploads/assets/1a/26/hero_1a26b8e2-af84-4c3c-836e-6e8b3e67c199.png 648w, https://ugc.futurelearn.com/uploads/assets/1a/26/large_hero_1a26b8e2-af84-4c3c-836e-6e8b3e67c199.png 729w, https://ugc.futurelearn.com/uploads/assets/1a/26/large_hero_1a26b8e2-af84-4c3c-836e-6e8b3e67c199.png 2x"/></p>
<p><script type="math/tex">D3</script>: “Tulip Rose” maps to (0,1,1)
Here <script type="math/tex">D3</script> is the same as <script type="math/tex">D2</script> even though the string is different. We are blatantly ignoring word order. As far as our vector space model is concerned there is no difference between <script type="math/tex">D2</script> and <script type="math/tex">D3</script></p>
<p><img alt="vector space mode; diagram where words are the coordinate Vectors Rose Lily Tulip Arrow pointing upwards through positions D4 and D1 positions D2 and D3 are also marked on this vector" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/de/0a/hero_de0a99d8-7bfb-4dc1-9703-63bae85b4d83.png" srcset="https://ugc.futurelearn.com/uploads/assets/de/0a/small_hero_de0a99d8-7bfb-4dc1-9703-63bae85b4d83.png 320w, https://ugc.futurelearn.com/uploads/assets/de/0a/hero_de0a99d8-7bfb-4dc1-9703-63bae85b4d83.png 648w, https://ugc.futurelearn.com/uploads/assets/de/0a/large_hero_de0a99d8-7bfb-4dc1-9703-63bae85b4d83.png 729w, https://ugc.futurelearn.com/uploads/assets/de/0a/large_hero_de0a99d8-7bfb-4dc1-9703-63bae85b4d83.png 2x"/></p>
<p><script type="math/tex">D4</script>: “Rose Rose” maps to (0,0,2)
Here <script type="math/tex">D4</script> is in the same direction as <script type="math/tex">D1</script> but shorter. Now if we had normalized our vectors then these would be the same point.</p>
<p><img alt="vector space mode; diagram where words are the coordinate Vectors Rose Lily Tulip Arrow pointing upwards through positions D4 and D1 positions D2 and D3 are also marked on this vector" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/65/df/hero_65dfbe7e-8fa0-463c-912b-d4d186d2616c.png" srcset="https://ugc.futurelearn.com/uploads/assets/65/df/small_hero_65dfbe7e-8fa0-463c-912b-d4d186d2616c.png 320w, https://ugc.futurelearn.com/uploads/assets/65/df/hero_65dfbe7e-8fa0-463c-912b-d4d186d2616c.png 648w, https://ugc.futurelearn.com/uploads/assets/65/df/large_hero_65dfbe7e-8fa0-463c-912b-d4d186d2616c.png 729w, https://ugc.futurelearn.com/uploads/assets/65/df/large_hero_65dfbe7e-8fa0-463c-912b-d4d186d2616c.png 2x"/></p>
<p><script type="math/tex">Q</script>: ”Rose Rose Tulip Lily Lily”, i.e. (2,1,2). Now that we have the new query <script type="math/tex">Q</script>, which of the existing documents is this most similar to?</p>
<p>How do we measure “similar”?</p>
<p>How about measuring how close it is to <script type="math/tex">D1</script>, <script type="math/tex">D2</script>, etc. in the vector space through using a Euclidean metric?</p>
<p>Or, more commonly with text, we will look at the angle between the vectors usually taken as the cosine angle between the vectors.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.7&emsp;Dot products</h2><div class="u-typography-bold-intro">
<p>Dot products are the computation of basic linear algebra which involves multiplication of vectors in a particular way.</p>
<p>The real world problems are modelled well and all the machine learning and deep learning algorithms use dot product multiplication most of the time</p>
<p>Let’s consider two document vectors <script type="math/tex">a</script> and <script type="math/tex">b</script>.<br/>
The similarity of document vectors <script type="math/tex">a</script> and <script type="math/tex">b</script>:<br/>
<script type="math/tex">a = [a_1, a_2, ...a_d] ,  b = [b_1, b_2, b_d]</script><br/>
<script type="math/tex">a^Tb = a_1b_1+...+a_db_d = \sum_ia_i b_i</script><br/>
The diagram below shows the dot product of two document  vectors a and b and their similarity is computed.</p>
<p><img alt="diagram below shows the dot product of two document  vectors a and b and their similarity is computed." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/bc/88/hero_bc8846f2-46e8-471f-9d47-12aafce0e43c.png" srcset="https://ugc.futurelearn.com/uploads/assets/bc/88/small_hero_bc8846f2-46e8-471f-9d47-12aafce0e43c.png 320w, https://ugc.futurelearn.com/uploads/assets/bc/88/hero_bc8846f2-46e8-471f-9d47-12aafce0e43c.png 648w, https://ugc.futurelearn.com/uploads/assets/bc/88/large_hero_bc8846f2-46e8-471f-9d47-12aafce0e43c.png 729w, https://ugc.futurelearn.com/uploads/assets/bc/88/large_hero_bc8846f2-46e8-471f-9d47-12aafce0e43c.png 2x"/></p>
<p>Geometrically, the length of projection of a onto b is highest if <script type="math/tex">a</script> and <script type="math/tex">b</script> point in the same direction. The length of projection is zero if a and b are orthogonal. This projection is dictated by the cosine of the angle between <script type="math/tex">a</script> and <script type="math/tex">b</script>. So the dot product is a measure of similarity. Geometrically it is maximum if the vectors are in the same direction.</p>
<p>The smaller the angle between the vectors the smaller the x projection you are going to see.</p>
<p>If they are orthogonal this means that two pieces of text have no words in common. All our vectors are either zero or positive, i.e. no negative components as this is counting of number of words. If vectors point in the same directions, they have exactly the same words in exactly the same proportions.</p>
<h3 id="so-how-does-this-dot-product-relate-to-the-euclidean-distance-between-a-and-b">So how does this dot product relate to the Euclidean distance between <script type="math/tex">a</script> and <script type="math/tex">b</script>?</h3>
<p>The relationship between the Euclidean distance which was the original similarity measure we were thinking of is closely bound with the dot product. A nice exposition of this can be found <a href="https://en.wikipedia.org/wiki/Euclidean_distance">here</a>.</p>
<p><script type="math/tex">\sum_i(a_i - b_i)^2</script>= <script type="math/tex">\sum_i(a_i^2 + b_i^2 - 2a_ib_i)</script> = <script type="math/tex">(\sum_ia_i^2)+(\sum_ib_i^2) -2(\sum_ia_ib_i)</script></p>
<p>If we consider a and b to have unit length then this is easier to think about, i.e.</p>
<script type="math/tex; mode=display">1 - a ^Tb = \frac {1}{2} {\mid \mid  a-b\mid\mid^2}</script>
<p>We can see that our dot product is directly related to a distance measure. So the closer feature vectors are together in the vector space, i.e. the shorter the Euclidean distance, the larger the dot product score.</p>
<h3 id="so-what-does-this-dot-product-tell-us-about-words-in-common">So what does this dot product tell us about words in common?</h3>
<p>Consider two sets <script type="math/tex">a</script> and <script type="math/tex">b</script> which are binary vectors, i.e. entries are 1 or a 0. We set <script type="math/tex">a_i  = 1</script> if word <script type="math/tex">i</script> occurs in <script type="math/tex">a</script>, otherwise <script type="math/tex">4a_i  = 0</script>.  If we adopt this encoding then</p>
<p><script type="math/tex">a^Tb = a_1b_1+ …+a_db_d</script> = # of words that belong to both <script type="math/tex">a</script> and <script type="math/tex">b</script></p>
<p>In short, the dot product is what we will use for our “similarity” measure throughout this text processing section as it has useful properties as we have just seen.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.8&emsp;Term weighting</h2><div class="u-typography-bold-intro">
<p>We now have a representation  - our vector space model and we have explored how to measure basic similarity.</p>
<p>What is still not entirely clear is if this is a good representation for machine learning tasks.  Let us explore why that is.</p>
<p>What we will do now is look at how we can build on our original similarity measure to make it more useful for machine learning tasks that are common with text (i.e. documents).  Probably the most important machine learning task with documents are information retrieval tasks. Such tasks are what happens when you use your search engine to look for further information on concepts you have seen in this course, e.g. searching for “How does a vector space model work” and then expecting your search engine to come back with well matched websites. A well matched website will be focussed on content that contains “vector space model” rather than websites which tell you how anything in general might work “How does a …. Work”. This sort of information retrieval is not trivial and some terms are clearly more important than others. This is what we explored at the beginning of this topic.</p>
<p>Other related but different document based machine learning tasks include what we might use if we want to check for plagiarism among student submissions - generally much longer documents are involved compared to the asymmetrical situation involved in information retrieval, i.e. short search queries against much longer target documents.</p>
<p>Where we are going with all this is that clearly some words - some terms in a document are more important than others. We saw this earlier in the topic but how do we take this into account? We do this through introducing the idea of a term weight.</p>
<h3 id="term-weight">Term Weight</h3>
<p>Term weight refers to the relative importance of a word in a document. Consider a document <script type="math/tex">D</script> and a query <script type="math/tex">Q</script>.  We consider <script type="math/tex">Q_w</script> as the weight of the word in the query. We consider <script type="math/tex">D_w</script> as the weight of the word in the document.</p>
<script type="math/tex; mode=display">s(Q,D) =  \sum_w Q_w D_w</script>
<p><script type="math/tex">s()</script> here is our similarity measure which is a sum of products over all words <script type="math/tex">w</script> in the vocabulary.</p>
<p>We can have a lot of fun and flexibility playing around with how we come up with <script type="math/tex">Q_w</script> and <script type="math/tex">D_w</script> precisely. We initially used word count which is a fine idea, but maybe we can do better, as not all words are equal as we established earlier in the week.</p>
<p>Let’s think about what is important in creating similarity measures. Clearly one obviously important thing is the present or absence of words. If the word is in common in both query and document then this is important. So if we set binary 1 and 0 for presence/absence then we are really just looking at the overlap of two sets of words.
This is called an “overlap” algorithm and is clearly a good starting point.</p>
<p><strong>Overlap measure</strong>: 
Presence or absence of most important words. This can be done by assigning weights to the words.</p>
<ul>
<li>Weight = 1 if word is present , 0 otherwise</li>
<li>Document = binary vector = set.  <script type="math/tex">s(Q,D) = \sum_{w}1_{w \in Q}\cdot 1_{w \in D}</script></li>
</ul>
<p>If we run this query <script type="math/tex">Q</script> against a set of documents then we will have a set of scores which can be ranked according to documents which have the most overlap with the query. If our query just has important key words such as “Vector Space Model” then this measure would be pretty good. But perhaps our search term is “How does a vector space model help people find good web pages on the internet?” then we might have problems.</p>
<h3 id="term-frequency">Term Frequency</h3>
<p>Maybe we need a little more cleverness. One thing we might notice is that important words tend to occur multiple times in a document. We could call this the term frequency <script type="math/tex">tf</script>. So far we can consider <script type="math/tex">tf_{w,D}</script> as the number of times w occurs in a document <script type="math/tex">D</script>.  So now a similarity measure is as follows:</p>
<script type="math/tex; mode=display">s(Q,D) = \sum_w tf_{w,Q} tf_{w,D}</script>
<p>But hang on. Surely this is biased towards longer documents as longer docs have a greater number of occurrences of the term. Let us fix this by normalizing by the document length <script type="math/tex">\mid D \mid</script></p>
<script type="math/tex; mode=display">s(Q,D) = \sum_wtf_{w,Q}\frac{tf_{w,D}}{\left | D \right |}</script>
<p>Let’s call a halt here for this step. Have a think about what you have just read.</p>
<h3 id="inverse-document-frequency">Inverse document frequency</h3>
<p>Now we are going to introduce another nuance. It seems sensible to look at rare or unusual words, as well as these are often important.</p>
<p>“Vector Space Model”, “Frequency”, “Weighting” rare but significant words. “How”, “does”, “work”, not so important. Words like “a”, “the”, “of” are the nuts and bolts of language holding things together so not important as commonly occur in all documents.</p>
<p>We should give more weight to uncommon words. We do this through weighting according to 
<script type="math/tex">\log\frac{ \mid L \mid} {df_W}</script></p>
<p><script type="math/tex">\mid L \mid</script> is the number of documents in a collection. <script type="math/tex">df_w</script> is the number of documents containing <script type="math/tex">w</script>. This gives us a new similarity measure which now takes care of normalization, looks for overlapping words and weights rarer words in our collection of documents to be searched.</p>
<script type="math/tex; mode=display">s(Q,D)=\sum_w\overbrace{tf_{w,Q}}^{Q_w} \cdot \overbrace{\frac{tf_{w,D}}{\left | D \right |}\cdot \log {\frac{ \left | L \right |}{df_w}}} ^{D_w}</script>
<p>The second component of our similarity measure is called the Inverse Document Frequency (idf) and is a useful heuristic for picking out the most important words. It could also be applied in the query weights <script type="math/tex">Q_w</script> . The logarithm is used here for keeping relative size of idf and tf components. You might find this <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">tf-idf</a> article useful if what you have read so far is unclear.</p>
<p>Let’s look at a good demonstration and explanation in action.</p>
<p>Check out this:</p>
<p><a href="https://www.kdnuggets.com/2018/08/wtf-tf-idf.html">KDnuggets tf-idf</a> article. <a href="https://www.kdnuggets.com/about/index.html">KDnuggets</a> is a useful website that you are likely to come across pretty often in your machine learning adventures.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.9&emsp;Frequency normalisation</h2><div class="u-typography-bold-intro">
<p>We are now going to further refine our similarity measures based on other characteristics of “matches” or document similarity that appeal to our intuition.</p>
<p>So let’s take the hypothetical query.</p>
<p><script type="math/tex">Q</script> – “vector linear”
<script type="math/tex">D_1</script>= “…vector, …, linear”, <script type="math/tex">D_2</script>=“…, vector,…, vector”
Is<script type="math/tex">D_1</script> or<script type="math/tex">D_2</script> more relevant to the search query?</p>
<p>It is a good question but really the first occurrence of the term is the most important thing in many cases. Repetition is not as important as this first initial occurrence. So we should try to limit the accrual of scoring through repetition. In other words we should squash the growth of term frequency. We can use an expression for term frequency as per the figure below.</p>
<p>For small <script type="math/tex">k</script> we get all the weighting from the initial occurrence and there is essentially no gain from subsequent occurrences. As we go for progressively larger values of <script type="math/tex">k</script> we approach a situation where each additional occurrence delivers a similar boost in the weighting. We can obviously tune <script type="math/tex">k</script> according to our needs.</p>
<p><img alt="term frequency–inverse document frequency Graph" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/24/7f/hero_247f0188-b312-40f0-b434-d759065bee3e.png" srcset="https://ugc.futurelearn.com/uploads/assets/24/7f/small_hero_247f0188-b312-40f0-b434-d759065bee3e.png 320w, https://ugc.futurelearn.com/uploads/assets/24/7f/hero_247f0188-b312-40f0-b434-d759065bee3e.png 648w, https://ugc.futurelearn.com/uploads/assets/24/7f/large_hero_247f0188-b312-40f0-b434-d759065bee3e.png 729w, https://ugc.futurelearn.com/uploads/assets/24/7f/large_hero_247f0188-b312-40f0-b434-d759065bee3e.png 2x"/></p>
<p>This is a nice idea. However thinking about it again, maybe there are situations when the number of repetitions is important. OK, you say, well just use a large <script type="math/tex">k</script> then. OK, but maybe if we have a long document then the repetitions are particularly important. For example the Wikipedia article (a document) for the entry <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">“tf-idf”</a>.</p>
<p>We will see the word “frequency” used a lot and its frequent occurrence is important in this relatively long document. So what turns out to be useful is taking account of the fact that repetitions of a word could be important in longer documents. So why don’t we take our parameter <script type="math/tex">k</script> and make it a function of document length?</p>
<script type="math/tex; mode=display">\frac{tf_{w,D}} {tf_{w,D} + \frac{k \mid D \mid}{avg \mid D \mid}}</script>
<p>For shorter documents occurrences of the word, beyond the first few, give diminishing weights, while for the longer than average documents in the collection of documents we give considerably more weight to repetitions.</p>
<p>This approach leads to this useful formula used for <strong>short</strong> queries and <strong>normal length</strong> documents</p>
<script type="math/tex; mode=display">s(Q,D) = \sum_w tf_{w,D}\cdot \frac{tf_{w,D}} {tf_{w,D} + \frac{k \mid D \mid}{avg \mid D \mid}} \cdot \log \frac{\mid L\mid}{df_w}</script>
<p>You can rank your documents in order of decreasing <script type="math/tex">s(Q,D)</script>, i.e. the bigger <script type="math/tex">s(Q,D)</script>, the better the match.</p>
<p>Variations of this algorithm have been used in the search engines for a long time.
Called the <strong>“tf.idf weighted sum”</strong> and they are effective.</p>
<h3 id="leads-to-this-useful-formula-used-in-queries">Leads to this useful formula used in queries:</h3>
<script type="math/tex; mode=display">s(Q,D) = \sum_w tf_{w,D}\cdot \frac{tf_{w,D}} {tf_{w,D} + \frac{k \mid D \mid}{avg \mid D \mid}} \cdot \log \frac{\mid L \mid}{df_w}</script>
<p>The frequency term tells us if the word is repeated in the query, then it’s probably important so lets weight according to count of this.</p>
<script type="math/tex; mode=display">s(Q,D) = \sum_wtf_{w,D}\cdot \frac{tf_{w,D}} {tf_{w,D} + \frac{k \mid D \mid}{avg \mid D \mid}} \cdot \log \frac{\mid L \mid}{df_w}</script>
<p>The last term gives weight to rare words, i.e. these rare words are important. This reduces weight to common words, i.e. common words in all the docs are not important.</p>
<script type="math/tex; mode=display">s(Q,D) = \sum_wtf_{w,D}\cdot \frac{tf_{w,D}} {tf_{w,D} + \frac{k \mid D \mid}{avg \mid D \mid}} \cdot \log \frac{\mid L \mid}{df_w}</script>
<h3 id="repetition-of-query-words-in-the-document-is-considered-positively">Repetition of query words in the document is considered positively</h3>
<script type="math/tex; mode=display">s(Q,D) = \sum_wtf_{w,D}\cdot \frac{tf_{w,D}} {tf_{w,D} + \frac{k \mid D \mid}{avg \mid D \mid}} \cdot \log \frac{\mid L \mid}{df_w}</script>
<p>Repetition of the same word is less important than the occurrence of different words, except for the case where the document is long.</p>
<p>So that was pretty epic! What we have really shown is that the vector space model with a bit of work is a useful representation for text. Some text processing smarts (more commonly known as natural language processing) is always useful, even if you only use it for your assignment. Our examination of some of the ideas involved may whet your appetite for deeper study outside this course.</p>
<p>Also, since I am sure you frequently reached for your search engine to find out more information as you went through this step, it is good to know the sort of algorithms which might have been involved in matching your search query to existing web documents.</p>
<h3 id="summary-of-text-representation">Summary of text representation</h3>
<ul>
<li>
<p>Bag of Words is a useful representation for text and leads to a feature vector.</p>
</li>
<li>
<p>Everything is a vector, one dimension per word. Rank by similarity of document vectors to query by using dot product or cosine of the angle between vectors.</p>
</li>
<li>
<p>Term weighting. The tf.idf measure is well loved and used and, when operating over the vector space model, does useful things.</p>
</li>
</ul>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.10&emsp;Time Series</h2><div class="u-typography-bold-intro">
<p>We have had a good look at images. We have certainly done text. What else is there?</p>
<h3 id="how-about-time-series">How about time series?</h3>
<p>Time Series consists of sequential numerical data where order is important.</p>
<p>Examples of time series include:</p>
<ul>
<li>Stock prices</li>
<li>Number of births per day</li>
<li>Daily temperature readings</li>
</ul>
<p><img alt="Time series graph - stock prices - number of births per day - daily temperature" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/0e/03/hero_0e03bbba-d7a8-4a44-8f67-d4015792829b.png" srcset="https://ugc.futurelearn.com/uploads/assets/0e/03/small_hero_0e03bbba-d7a8-4a44-8f67-d4015792829b.png 320w, https://ugc.futurelearn.com/uploads/assets/0e/03/hero_0e03bbba-d7a8-4a44-8f67-d4015792829b.png 648w, https://ugc.futurelearn.com/uploads/assets/0e/03/large_hero_0e03bbba-d7a8-4a44-8f67-d4015792829b.png 729w, https://ugc.futurelearn.com/uploads/assets/0e/03/large_hero_0e03bbba-d7a8-4a44-8f67-d4015792829b.png 2x"/>
Figure: <a href="https://www.google.com/search?q=dell+stock+price&amp;tbm=fin#scso=_v8LwXbTUA8mBhbIPqOm44A49:0">DELL stock price</a> taken using Google search (Finance). This is a time series.</p>
<p><img alt="Temperature Graph" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/b9/6a/hero_b96a7b84-e293-4bd7-b2f0-144699438f28.png" srcset="https://ugc.futurelearn.com/uploads/assets/b9/6a/small_hero_b96a7b84-e293-4bd7-b2f0-144699438f28.png 320w, https://ugc.futurelearn.com/uploads/assets/b9/6a/hero_b96a7b84-e293-4bd7-b2f0-144699438f28.png 648w, https://ugc.futurelearn.com/uploads/assets/b9/6a/large_hero_b96a7b84-e293-4bd7-b2f0-144699438f28.png 729w, https://ugc.futurelearn.com/uploads/assets/b9/6a/large_hero_b96a7b84-e293-4bd7-b2f0-144699438f28.png 2x"/></p>
<p>Figure: The temperature over the course of the day is a time series.</p>
<p>In the case of daily temperature readings, this relates to data taken from a sensor and is a common source of time series.</p>
<p>In the field of electronic and electrical engineering, the study of such time series is termed signal analysis and operations on such time series is called signal processing. 
Often, our challenges relate to the prediction of future samples in the time series or characterisation of patterns in the time series. This latter challenge is common in biomedical engineering applications of machine learning.</p>
<p>Can you think of other examples? Discuss in the comments section below.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.11&emsp;Special time series</h2><div class="u-typography-bold-intro">
<p>In the last step, we mentioned signal processing. This represents a really important opportunity for machine learning applied to time series.</p>
<p>Often, when people think of time series, they are thinking about our previous examples in the last step where we are looking at weather, say temperature readings and seeking to predict future weather. It is common for people to think about stock market prices as time series and fantasize about creating some prediction algorithm which will predict movement in a stock’s price or market dynamics. However, the most valuable and impactful side of machine learning and time series is when the time series arises from human behavior and physiology. I am going to call these special time series in this step, as I think they are particularly special due to their richness of information and how impactful they can be when used in the context of machine learning.</p>
<p>For example, on your smart phone you have a voice assistant. You can say “OK Google” or “Hey Siri” or whatever and your phone recognises the request and you have an opportunity to use your phone’s services through voice. Guess what, that is a machine learning task. It is a classification task. It is recognising words in patterns of sound. Those patterns of sound are captured by your phone’s microphone which is a sensor, turning sound pressure waves into changes in an electrical signal. This continuously varying electrical signal is digitised (remember that?) and produces a sequence of numbers a time series.</p>
<p><img alt="special time series graph" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/ef/f6/hero_eff60bb9-474b-408e-99ad-6651375a35f6.png" srcset="https://ugc.futurelearn.com/uploads/assets/ef/f6/small_hero_eff60bb9-474b-408e-99ad-6651375a35f6.png 320w, https://ugc.futurelearn.com/uploads/assets/ef/f6/hero_eff60bb9-474b-408e-99ad-6651375a35f6.png 648w, https://ugc.futurelearn.com/uploads/assets/ef/f6/large_hero_eff60bb9-474b-408e-99ad-6651375a35f6.png 729w, https://ugc.futurelearn.com/uploads/assets/ef/f6/large_hero_eff60bb9-474b-408e-99ad-6651375a35f6.png 2x"/></p>
<p><sub>Figure: Lead educator saying “Hey Siri”.</sub></p>
<p>That voice recording is a time series. Want to see? Here is 100 samples from near the start of the waveform.</p>
<p>-0.00807
-0.00668
-0.00512
-0.00325
-0.00131
0.00105
0.00370
0.00666
0.00977
0.01262
0.01568
0.01908
0.02209
0.02429
0.02610
0.02768
0.02878
0.02976
0.03075
0.03181
0.03271
0.03312
0.03349
0.03412
0.03514
0.03652
0.03806
0.03978
0.04165
0.04320
0.04487
0.04671
0.04818
0.04945
0.05003
0.04991
0.04962
0.04937
0.04932
0.04925
0.04886
0.04803
0.04699
0.04613
0.04551
0.04500
0.04474
0.04474
0.04486
0.04480
0.04471
0.04512
0.04571
0.04582
0.04547
0.04502
0.04458
0.04436
0.04440
0.04433
0.04421
0.04395
0.04364
0.04359
0.04365
0.04347
0.04310
0.04284
0.04247
0.04192
0.04157
0.04142
0.04128
0.04097
0.04016
0.03960
0.03950
0.03933
0.03956
0.04018
0.04087
0.04162
0.04249
0.04346
0.04442
0.04525
0.04603
0.04658
0.04646
0.04639
0.04651
0.04619
0.04569
0.04514
0.04469
0.04426
0.04367
0.04321
0.04309
0.04303</p>
<p>See? It is a time series! The amazingly robust voice recognition systems on your smartphones take in such raw samples as input, and attempt to identify the patterns which are your voice saying “Hey Siri”. Incredible!</p>
<p>That was an example of a univariate time series. Let’s look at another special and interesting signal (I am going to say signal a lot now when looking at these special time series).</p>
<p>Below, we have a single time series of the optical signal you might measure from a Fitbit or other wearable heart rate monitor.</p>
<p><img alt="Graph of heart rate - raw photoplethysmogram" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/c9/c6/hero_c9c6be50-b6d5-47a3-9ebf-befed2d90eb4.png" srcset="https://ugc.futurelearn.com/uploads/assets/c9/c6/small_hero_c9c6be50-b6d5-47a3-9ebf-befed2d90eb4.png 320w, https://ugc.futurelearn.com/uploads/assets/c9/c6/hero_c9c6be50-b6d5-47a3-9ebf-befed2d90eb4.png 648w, https://ugc.futurelearn.com/uploads/assets/c9/c6/large_hero_c9c6be50-b6d5-47a3-9ebf-befed2d90eb4.png 729w, https://ugc.futurelearn.com/uploads/assets/c9/c6/large_hero_c9c6be50-b6d5-47a3-9ebf-befed2d90eb4.png 2x"/></p>
<p><sub>Source: <a href="https://user-images.githubusercontent.com/9865941/52956852-3ccac000-3388-11e9-9bf0-5a3eff693367.png">GitHub</a></sub></p>
<p>This signal which is a photoplethysmograph or PPG is a measure of blood volume changes measured with light (you might have noticed a flashing green led on your fitness tracker). It has a wave-like nature which reflects the pulsations in arterial blood due to the beating of your heart and the subsequent pumping of blood down those arteries. If we can count the number of pulses per unit time we can come up with a measure of your heart rate which is what your fitness tracker should do.</p>
<p>An interesting machine learning challenge is to take that signal and see what we can infer from it. For example when a person is walking and running the optical signal is severely disturbed. A fun machine learning challenge then is to figure out what the person was doing based on the disturbance observed in the signal. If you want to see a solution to that, check out one of our student’s papers, <a href="https://arxiv.org/abs/1812.00668">An Interpretable Machine Vision Approach to Human Activity Recognition using Photoplethysmograph Sensor Data</a>.</p>
<h3 id="multivariate-time-series-classification-problem">Multivariate Time Series Classification Problem</h3>
<p>Instead of a single time series (or signal) we can have multiple sensors interrogated at the same time to produce multivariate time series. Here is a very interesting multivariate signal based on measures of electrical activity of the brain called the electroencephalogram (EEG). An interesting challenge with EEG is to determine what the brain is doing. For example, here is an EEG recorded in a hospital. Can we use the information across all the channels to determine if this person is having a seizure? This is an important challenge in epilepsy research and machine learning promises to be an impactful technology here.</p>
<p><img alt="EEG Absence seizure graph" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/8c/2d/hero_8c2db8f0-5b41-45af-9cd6-5f5e686fc31d.png" srcset="https://ugc.futurelearn.com/uploads/assets/8c/2d/small_hero_8c2db8f0-5b41-45af-9cd6-5f5e686fc31d.png 320w, https://ugc.futurelearn.com/uploads/assets/8c/2d/hero_8c2db8f0-5b41-45af-9cd6-5f5e686fc31d.png 648w, https://ugc.futurelearn.com/uploads/assets/8c/2d/large_hero_8c2db8f0-5b41-45af-9cd6-5f5e686fc31d.png 729w, https://ugc.futurelearn.com/uploads/assets/8c/2d/large_hero_8c2db8f0-5b41-45af-9cd6-5f5e686fc31d.png 2x"/></p>
<p><sub>Source: <a href="https://commons.wikimedia.org/wiki/File:EEG_Absence_seizure.png">Wikimedia</a></sub></p>
<p>Hopefully this will whet your appetite for the special time series we can measure via sensors from people which reflect their health and behavior. It is a very exciting part of machine learning now and in the future.</p>
<p>Take a look at what the IEEE (use your tf-idf skills here and Google “IEEE” if you don’t know the organisation) have to say about it in the video below.</p>
<p><img alt="Woman sitting in the back of the car talking on the phone" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/f4/eb/hero_f4eb9f39-40c8-404e-8e7b-49e721fbde92.png" srcset="https://ugc.futurelearn.com/uploads/assets/f4/eb/small_hero_f4eb9f39-40c8-404e-8e7b-49e721fbde92.png 320w, https://ugc.futurelearn.com/uploads/assets/f4/eb/hero_f4eb9f39-40c8-404e-8e7b-49e721fbde92.png 648w, https://ugc.futurelearn.com/uploads/assets/f4/eb/large_hero_f4eb9f39-40c8-404e-8e7b-49e721fbde92.png 729w, https://ugc.futurelearn.com/uploads/assets/f4/eb/large_hero_f4eb9f39-40c8-404e-8e7b-49e721fbde92.png 2x"/></p>
<p><a href="https://www.youtube.com/watch?v=mexN6d8QF9o">Signal Processing and Machine Learning</a></p>
<p><sub><strong>References</strong></sub></p>
<p><sub>Brophy, E., Viega, J., Wang, Z., Smeaton, A., Ward, T. (2018) ‘An Interpretable Machine Vision Approach to Human Activity Recognition using Photoplethysmograph Sensor Data’, <em>arXiv.org</em>, available: https://arxiv.org/abs/1812.00668 [accessed 20 Dec 2019]
</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.12&emsp;Special time series - Music representation</h2><div class="u-typography-bold-intro">
<p>I want to mention music here which is another special time series as far I am concerned.</p>
<p>What sort of representations are used here and perhaps more importantly what sort of machine learning tasks are relevant here? Let’s start with the last issue - machine learning tasks. A small but growing field in searching is “music information retrieval” which relates to processing music for all sorts of applications from “recommender systems” (think streaming music) to instruments extraction (think karaoke). From Shazam to Spotify this is growing in importance.  So what about representation? We cannot get too deep into this right now, but ultimately it is not too dissimilar to our speech recognition problem, except it’s even harder.</p>
<p>First of all though, we do have a time series. For example, here is a little musical tune.</p>
<p><img alt="Graph of a musical tune" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/07/03/hero_0703896c-cabe-40bb-b157-75902a7ed2d2.png" srcset="https://ugc.futurelearn.com/uploads/assets/07/03/small_hero_0703896c-cabe-40bb-b157-75902a7ed2d2.png 320w, https://ugc.futurelearn.com/uploads/assets/07/03/hero_0703896c-cabe-40bb-b157-75902a7ed2d2.png 648w, https://ugc.futurelearn.com/uploads/assets/07/03/large_hero_0703896c-cabe-40bb-b157-75902a7ed2d2.png 729w, https://ugc.futurelearn.com/uploads/assets/07/03/large_hero_0703896c-cabe-40bb-b157-75902a7ed2d2.png 2x"/>
Source: DCU</p>
<h3 id="what-features-might-we-go-with-at-this-stage">What features might we go with at this stage?</h3>
<p>If you were going down a deep learning route you might even just run with this univariate time series.</p>
<p>More commonly, some sort of spectral decomposition is done where we look at the time series as being built up from oscillations of various frequencies and amplitudes (computed via things such as Fourier transforms). These are roughly the musical notes we would whistle and hum, although it also contributes to the timbre of the instruments and other characterisation of the signal. If we plot these oscillations in terms of their contributions and frequencies we can generate what is termed a spectrum, which is a whole new domain to calculate features for music. The figure below is an illustration of such a spectrum for the first half of the signal above. Typically this sort of analysis is done on much shorter, overlapping time scales.</p>
<p><img alt="illustration of such a spectrum for the first half of the signal above. Typically this sort of analysis is done on much shorter, overlapping time scales." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/0e/a2/hero_0ea299bb-be28-4dcc-b5db-d7c79faa63a7.png" srcset="https://ugc.futurelearn.com/uploads/assets/0e/a2/small_hero_0ea299bb-be28-4dcc-b5db-d7c79faa63a7.png 320w, https://ugc.futurelearn.com/uploads/assets/0e/a2/hero_0ea299bb-be28-4dcc-b5db-d7c79faa63a7.png 648w, https://ugc.futurelearn.com/uploads/assets/0e/a2/large_hero_0ea299bb-be28-4dcc-b5db-d7c79faa63a7.png 729w, https://ugc.futurelearn.com/uploads/assets/0e/a2/large_hero_0ea299bb-be28-4dcc-b5db-d7c79faa63a7.png 2x"/></p>
<p>So already we can see how our feature possibilities are growing. This is an enormous area for such a deceptively simple thing, i.e. a time series.</p>
<p>We cannot go deep into music here but I am sure some of you are very interested in this so please explore. I found this <a href="https://en.wikipedia.org/wiki/Music_information_retrieval">Music information retrieval</a> article useful. I also enjoyed these great  introduction video and slides from Erlangen, <a href="https://www.audiolabs-erlangen.de/resources/MIR/2017_TutorialAudioMIR_ISMIR/">here</a>.</p>
<p><sub><strong>References</strong></sub></p>
<p><sub>
Wikipedia (2019) <em>Music information retrieval</em>, available: https://en.wikipedia.org/wiki/Music_information_retrieval [25 Nov 2019, 10.22].</sub></p>
<p><sub>Audio Laboratories Erlangen, (2017) <em>Tutorial: A Basic Introduction to Audio-Related Music Information Retrieval</em>, available [https://www.audiolabs-erlangen.de/resources/MIR/2017_TutorialAudioMIR_ISMIR/] [accessed 22 Nov 2019]]
</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.13&emsp;Video processing</h2><div class="u-typography-bold-intro">
<p>So we have seen time series, we have seen image processing, and we have seen text processing.</p>
<p>Video processing is a sequenced data where each sample is now an image. Suitable representation of video data is an enormous area and outside the scope of this course. In our assignment for this module we will take a look at video processing so there is an opportunity to explore there however we will make use of a few images per video for our prediction task to make things tractable. So, in short, be patient, there will be an opportunity later to look at representations.</p>
<p>Another reason we are not going to look deeply into existing approaches along the lines of what we have seen for text, images and time series is that the classical approach is even more complex and in the midst of complete disruption by deep learning.</p>
<p>So what I mean is if we were to carry on from the approaches we have looked at for other data, video representation would involve a visual bag-of-features clustered in some way before classification with something like a support vector machine (assuming we are interested in video classification). However, deep learning, and convolutional neural network approaches in particular, are removing the need for heavy feature engineering and representations. If you don’t believe me check out the following <a href="https://paperswithcode.com/task/video-classification">article</a>.</p>
<p>Having said all that, in the next course you will need to undertake an assignment which involves a prediction task on video. However, you will not need to operate on the video data directly as we will have pre-computed features for you, many of which have been automatically discovered through deep learning approaches, so you will be applying cutting edge (ish) features in your submissions!</p>
<p><sub><strong>References</strong></sub></p>
<p><sub> Papers with code, <em>Video Classification</em> (2018), available: https://paperswithcode.com/task/video-classification [accessed 22 Nov 2019] 
</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.15&emsp;Review of Topic 3</h2><div class="u-typography-bold-intro">
<p>Congratulations on completing Topic 3.</p>
<p>That was a tough topic for everyone. What did we learn? We learned that data representation is an enormous topic in its own right. We could only scratch the surface. We did learn about important real-world examples of data and suitable representations. Images were our starting point and while our initial examples seemed ok (digits), we quickly saw how things got complicated with “busier” images.</p>
<p>An emerging idea was a “bag of features” concept which was both suitable for images and text. In terms of text, that too escalated quickly, and we learned about how such a simple representation used with increasingly complex statistical measures such as tf.idf could be useful for real natural language processing tasks such as querying. We then looked at time series. It seemed innocuous enough but again we could see the complexity in representation when we move to special time series such as physiological signals and later music.</p>
<p>The good news is that we now have a handle on data representation and all its various forms. We can now proceed to doing a little feature engineering in order to get this universe of features under some sort of control for our machine learning applications.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p style="page-break-before: always"><h2>4.1&emsp;Welcome to Topic 4</h2><div class="u-typography-bold-intro">
<p>So here we are in Topic 4.</p>
<p>We are coming to the end of our adventures with data representation.  In the next course we will be able to progress to actual machine learning algorithms. However, before we go we want to spend some time on an important feature processing step which we can call feature engineering.</p>
<p>We saw in the last topic how easy it can be to come up with all sorts of attribute-value pairs which could be potentially useful candidates for machine learning purposes. However, is there such a thing as having too many features? Are all features equally useful? It might be useful to have a feature curation step or perhaps combine and transform feature to yield more computationally useful features?</p>
<p>In this topic we are going to take a quick look at some of the possibilities which exist here. This is an enormous topic of study in itself so we will just explore a few ideas to whet your appetite.</p>
<p>Ok, let’s take a look.</p>
</div><p><h2>4.2&emsp;Overview of feature engineering</h2><div class="u-typography-bold-intro">
<p>Here we briefly outline some of the main characteristics of feature engineering.</p>
<h3 id="feature-extraction-and-feature-selection">Feature extraction and feature selection</h3>
<p>Feature extraction projects the original high-dimensional features to a new feature space with low dimensionality, while feature selection directly selects a subset of relevant features. Both feature extraction and feature selection can improve learning performance, increase computational efficiency, decrease memory storage, and build better generalization models.</p>
<p>However, as feature extraction creates a set of new features, further analysis is problematic as we cannot retain the physical meanings of these features. In contrast, by keeping some of the original features, feature selection maintains the physical meanings of the original features and gives models better readability and interpretability.</p>
<h3 id="data-preparation">Data preparation</h3>
<p>Before we begin dealing with feature extraction or selection, an important first step concerns tidying up our dataset. Many features might be missing for specific instances. 
For example, imagine we have collected a dataset from patients visiting doctors’ offices. This dataset contains variables such as name, height, weight, blood pressure, resting heart rate, &amp; cholesterol level.</p>
<p>It is entirely conceivable that for some of these patients certain data are missing. Perhaps the cholesterol measurement did not arrive in time during the period when the record was taken. Perhaps the notes were taken by hand and the data entry person could not read the handwriting that had recorded the resting heart rate. It is not hard to imagine incomplete, even erroneous values.</p>
<p>In the next step, we will deal with outlier and missing data.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.3&emsp;Outliers and missing data</h2><div class="u-typography-bold-intro">
<p>Outliers, in the context of Machine Learning, refer to rare instances of a class which are far from those in the rest of the data.</p>
<p>Typical examples are extreme attribute values. You can detect these through the use of confidence intervals, and once detected, remove the extreme attribute values. You could, if you liked, then treat these attribute instances as missing and use some of the ideas we will see later for missing data. Of course, this assumes that the outlier was due to an error in collecting the attribute (such as a sensor malfunction, data entry issue, etc.) If it is a genuine data value then you must consider it as such.</p>
<p>A useful step when considering missing data is to try to understand <em>how</em> it is missing.  It could be for example:</p>
<ul>
<li>Missing completely at random</li>
<li>Missing at random</li>
<li>Not missing at random</li>
</ul>
<h3 id="missing-completely-at-random">Missing Completely at Random</h3>
<p>This refers to the case where data is missing randomly across all the dataset, i.e. there is no pattern to the missing data. A pattern to the missing data takes many forms. One example could be in the case of our doctors’ patients data where we see that data is missing more often when a specific doctor is on duty.</p>
<p>Statistical tests such as a t-test could be used to help identify if the data is missing completely at random or not. For example, we could take two large samples of data, one which contains missing data, and which does not, and see if test for any significance in the sample means.</p>
<h3 id="missing-at-random">Missing at random</h3>
<p>This refers to the example I gave previously where we might have a particular doctor who happens to be more prone to missing data, i.e. there is an increased likelihood of missing data within a sub-sample of the data. So it is random within this sub-sample.</p>
<h3 id="not-missing-at-random-nmar">Not missing at random (NMAR)</h3>
<p>If there is a pattern to the missing data such as a specific doctor never records blood pressure in our example.</p>
<h3 id="imputing-missing-data">Imputing missing data</h3>
<p>So how do we impute. Let’s go to the literature.  An oldie but goodie paper might be <a href="https://www.researchgate.net/publication/5826106_Out_of_Sight_Not_Out_of_Mind_Strategies_for_Handling_Missing_Data">Out of Sight, Not Out of Mind: Strategies for Handling Missing Data</a> (Buhi <em>et al</em>. 2008). Let’s discuss under the comments section.</p>
<p>A much more sophisticated example of imputing missing data using deep learning for time series - in this case medical time series - can be found in this paper entitled <a href="https://arxiv.org/abs/1902.05624">Quick and Easy Time Series Generation with  Established Image-based GANs</a> (Brophy <em>et al</em>. 2019).</p>
<p><sub><strong>References</strong></sub></p>
<p><sub>Buhi, Eric &amp; Goodson, Patricia &amp; Neilands, Torsten. (2008). ‘Out of Sight, Not Out of Mind: Strategies for Handling Missing Data’. <em>American journal of health behavior</em>. 32. 83-92. 10.5993/AJHB.32.1.8, available: https://www.researchgate.net/publication/5826106_Out_of_Sight_Not_Out_of_Mind_Strategies_for_Handling_Missing_Data</sub></p>
<p><sub>Brophy, E., Wang, Z. and Ward T.E. (2019). ‘Quick and Easy Time Series Generation with Established Image-based GANs’. <em>arXiv: 1902.05624v3</em>, available: https://arxiv.org/abs/1902.05624 </sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.4&emsp;Why do we need to do feature selection and extraction anyway?</h2><div class="u-typography-bold-intro">
<p>The idea of feature selection and extraction is to avoid the curse of dimensionality.</p>
<p>This refers to the fact that, as we move to higher dimension input feature spaces, the volume of the space grows rapidly and we end up with very few instances per unit volume, i.e. we have very sparse sampling of the space of possible instances making modelling difficult.</p>
<p>A good blog post, <strong>‘The Curse of Dimensionality in classification’</strong>, giving a high level description of the problem can be found <a href="https://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/">here</a>.</p>
<h3 id="feature-selection">Feature selection</h3>
<p>It is clear from what we have seen that a good feature engineering idea might be to choose a subset of the features available to reduce the dimension of the feature space. This act is called feature selection. One way of doing this is to try out different permutations of features increasing the numbers of features involved as you proceed and calculate machine learning performance.  This is rarely practical though. More efficient approaches include wrapper, filter and embedded methods. We do not explore these ideas in this course, but for those of you interested and looking for answers this <a href="https://en.wikipedia.org/wiki/Feature_selection">Wikipedia</a> page is a good jumping off point.</p>
<h3 id="feature-extraction">Feature extraction</h3>
<p>This refers to the process of generating new features typically with a view to reducing the dimension of the data space, eliminating redundancy among the original features.</p>
<p>Occasionally one might “blow up” the feature space, i.e, increase dimension to facilitate a better feature selection step later which produces a final lower dimension feature vector.</p>
<p>In general, the purpose is to reduce overfitting, improve machine learning performance and in some cases improve human interpretation of the features. For an example of the latter see later in this topic when we look at the pixels of our traffic image. The pixels are not informative to humans as a raw feature (i.e. a single pixel) but features such as “colour” or “sky” or “contains text” are likely to be. For those of you interested in feature extraction in the context of images please take a look at the entry on Image Processing <a href="https://en.wikipedia.org/wiki/Feature_extraction">here</a>.</p>
<h3 id="dimensionality-reduction">Dimensionality reduction</h3>
<p>We can also perform feature extraction through projecting the features as combinations to produce new features which in total have dimension less than the original. Principal Component Analysis is a well known way of doing this. An excellent description of how it works in the context of machine learning can be found <a href="https://www.visiondummy.com/2014/05/feature-extraction-using-pca/">here</a>.</p>
<h3 id="clustering">Clustering</h3>
<p>Clustering can be used to discover some sort of commonality among raw features which could reduce the dimension of the input vectors and/or which can improve the machine learning process. It allows us to find sub-populations (clusters!) in our data. This is an unsupervised learning task. It also allows us to see outliers which may not have been apparent with simple visualizations.</p>
<h3 id="types-of-clustering">Types of clustering</h3>
<p>There are different types of clustering. These may include:</p>
<ul>
<li>Monothetic clustering, i.e. based on a single characteristic</li>
<li>Polythetic clustering, i.e. based on multiple characteristics</li>
</ul>
<p>Alternatively, we can distinguish between clustering methods that have hard boundaries and those which have soft boundaries. We don’t spend a lot of time on clustering in this course but to make sure you know at least one clustering algorithm we will, in the next step, take a closer look at a common technique called k-means clustering.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.5&emsp;K-means clustering</h2><div class="u-typography-bold-intro">
<p>With k-means clustering, you do have to tell it in advance how many clusters you want it to find.</p>
<p>Obviously this is not ideal, but this algorithm is a great introduction algorithm and I suggest those of you really interested look at more sophisticated methods. My current favourite clustering method is spectral clustering. Check it out!</p>
<h3 id="step-1">Step 1</h3>
<p>Our input for this algorithm is a parameter <script type="math/tex">k</script> - which is the number of clusters we are asking the algorithm to find.</p>
<p>We have our data instances <script type="math/tex">d_1, d_i...d_M</script>.</p>
<p>As discussed earlier, each of these data instances are usually a set of attribute value pairs. Each <script type="math/tex">d</script> here is a data example.</p>
<p><img alt="cats and dogs" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/9d/3b/hero_9d3bf731-86e3-4597-bc45-b413bcc7ddc1.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/9d/3b/small_hero_9d3bf731-86e3-4597-bc45-b413bcc7ddc1.PNG 320w, https://ugc.futurelearn.com/uploads/assets/9d/3b/hero_9d3bf731-86e3-4597-bc45-b413bcc7ddc1.PNG 648w, https://ugc.futurelearn.com/uploads/assets/9d/3b/large_hero_9d3bf731-86e3-4597-bc45-b413bcc7ddc1.PNG 729w, https://ugc.futurelearn.com/uploads/assets/9d/3b/large_hero_9d3bf731-86e3-4597-bc45-b413bcc7ddc1.PNG 2x"/>
<sub>©Pixabay</sub></p>
<p>The data attributes can be images of cats and dogs. With the help of k-means clustering algorithm, the images of cats and dogs can be grouped separately.</p>
<p><img alt="examples of input data points with cats and dogs" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/0f/08/hero_0f084f64-f469-4544-aed8-7e6ac7840b11.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/0f/08/small_hero_0f084f64-f469-4544-aed8-7e6ac7840b11.PNG 320w, https://ugc.futurelearn.com/uploads/assets/0f/08/hero_0f084f64-f469-4544-aed8-7e6ac7840b11.PNG 648w, https://ugc.futurelearn.com/uploads/assets/0f/08/large_hero_0f084f64-f469-4544-aed8-7e6ac7840b11.PNG 729w, https://ugc.futurelearn.com/uploads/assets/0f/08/large_hero_0f084f64-f469-4544-aed8-7e6ac7840b11.PNG 2x"/>
<sub>©Pixabay</sub></p>
<p><img alt="examples of input data points with cats and dogs" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/9d/c0/hero_9dc00a2b-db29-45f4-86b9-28fb4a6e5ef0.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/9d/c0/small_hero_9dc00a2b-db29-45f4-86b9-28fb4a6e5ef0.PNG 320w, https://ugc.futurelearn.com/uploads/assets/9d/c0/hero_9dc00a2b-db29-45f4-86b9-28fb4a6e5ef0.PNG 648w, https://ugc.futurelearn.com/uploads/assets/9d/c0/large_hero_9dc00a2b-db29-45f4-86b9-28fb4a6e5ef0.PNG 729w, https://ugc.futurelearn.com/uploads/assets/9d/c0/large_hero_9dc00a2b-db29-45f4-86b9-28fb4a6e5ef0.PNG 2x"/>
<sub>©Pixabay</sub></p>
<p><img alt="examples of input data points with cats and dogs" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/cf/2d/hero_cf2da729-b020-4c53-b869-00b30145ee1d.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/cf/2d/small_hero_cf2da729-b020-4c53-b869-00b30145ee1d.PNG 320w, https://ugc.futurelearn.com/uploads/assets/cf/2d/hero_cf2da729-b020-4c53-b869-00b30145ee1d.PNG 648w, https://ugc.futurelearn.com/uploads/assets/cf/2d/large_hero_cf2da729-b020-4c53-b869-00b30145ee1d.PNG 729w, https://ugc.futurelearn.com/uploads/assets/cf/2d/large_hero_cf2da729-b020-4c53-b869-00b30145ee1d.PNG 2x"/>
<sub>©Pixabay</sub></p>
<p><img alt="examples of input data points with cats and dogs" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/65/13/hero_6513ef6a-f6f8-46c9-8f36-21791eb56f4b.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/65/13/small_hero_6513ef6a-f6f8-46c9-8f36-21791eb56f4b.PNG 320w, https://ugc.futurelearn.com/uploads/assets/65/13/hero_6513ef6a-f6f8-46c9-8f36-21791eb56f4b.PNG 648w, https://ugc.futurelearn.com/uploads/assets/65/13/large_hero_6513ef6a-f6f8-46c9-8f36-21791eb56f4b.PNG 729w, https://ugc.futurelearn.com/uploads/assets/65/13/large_hero_6513ef6a-f6f8-46c9-8f36-21791eb56f4b.PNG 2x"/></p>
<p><img alt="examples of input data points with cats and dogs" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/f1/18/hero_f11831a3-e878-4ed3-87e7-50f3dfae1156.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/f1/18/small_hero_f11831a3-e878-4ed3-87e7-50f3dfae1156.PNG 320w, https://ugc.futurelearn.com/uploads/assets/f1/18/hero_f11831a3-e878-4ed3-87e7-50f3dfae1156.PNG 648w, https://ugc.futurelearn.com/uploads/assets/f1/18/large_hero_f11831a3-e878-4ed3-87e7-50f3dfae1156.PNG 729w, https://ugc.futurelearn.com/uploads/assets/f1/18/large_hero_f11831a3-e878-4ed3-87e7-50f3dfae1156.PNG 2x"/></p>
<h3 id="step-2">Step 2</h3>
<p>Next, we randomly place our cluster locations in random locations. We will call these cluster centroids, <script type="math/tex">4c_j</script>. We have <script type="math/tex">k</script> of these. In our cats and dogs example we would expect <script type="math/tex">k</script>=2 so lets illustrate that with <script type="math/tex">X</script>’s.</p>
<p>Of course for any data you are likely to work with, this will be a much higher dimensional space.</p>
<p><img alt="Ear Morphology feature" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/d1/56/hero_d1566f0a-4331-4b42-b32b-092deb75b65b.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/d1/56/small_hero_d1566f0a-4331-4b42-b32b-092deb75b65b.PNG 320w, https://ugc.futurelearn.com/uploads/assets/d1/56/hero_d1566f0a-4331-4b42-b32b-092deb75b65b.PNG 648w, https://ugc.futurelearn.com/uploads/assets/d1/56/large_hero_d1566f0a-4331-4b42-b32b-092deb75b65b.PNG 729w, https://ugc.futurelearn.com/uploads/assets/d1/56/large_hero_d1566f0a-4331-4b42-b32b-092deb75b65b.PNG 2x"/></p>
<h3 id="step-3">Step 3</h3>
<p><strong>Now we iterate over the data points with the following step:</strong></p>
<p>Loop through every data instance <script type="math/tex">d_1, d_i...d_M</script>.
For each instance find the closest <script type="math/tex">ci</script>.
The closest is measured typically using Euclidean distance - so find minimum distance.
You then tag that data instance with the cluster identifier. For example, you might find that <script type="math/tex">d_{56}</script> is closest to <script type="math/tex">c_4</script>.
Therefore, you update your cluster membership list with this information.</p>
<p>The graph below shows the result. We have replaced the label for the features here for ease of representation on the plot and we now have points which are in the red cluster and some which are in the blue cluster.</p>
<p><img alt="iteration of data points" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/2f/d5/hero_2fd508c8-cf13-48d4-b289-25d6c7dfd3b7.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/2f/d5/small_hero_2fd508c8-cf13-48d4-b289-25d6c7dfd3b7.PNG 320w, https://ugc.futurelearn.com/uploads/assets/2f/d5/hero_2fd508c8-cf13-48d4-b289-25d6c7dfd3b7.PNG 648w, https://ugc.futurelearn.com/uploads/assets/2f/d5/large_hero_2fd508c8-cf13-48d4-b289-25d6c7dfd3b7.PNG 729w, https://ugc.futurelearn.com/uploads/assets/2f/d5/large_hero_2fd508c8-cf13-48d4-b289-25d6c7dfd3b7.PNG 2x"/></p>
<h3 id="step-4">Step 4</h3>
<p><strong>Now we iterate over the clusters with the following step.</strong></p>
<p>Loop through every cluster <script type="math/tex">c_1...c_j...c_k</script>
For each cluster <script type="math/tex">c_i</script> we calculate its new centroid location by taking the mean of data instances currently associated with that cluster.</p>
<p>We do this by taking the mean of each attribute across the data instances.</p>
<h3 id="step-5">Step 5</h3>
<p><strong>Now we simply go back to Step 3 where there is likely to be some changes in cluster memberships.</strong></p>
<p><strong>We repeat these steps until clusters converge.</strong> 
Below shows our cluster membership reassignment for our example.</p>
<p>Note the movement of the centroids and updating of the point memberships.
<img alt="K cluster" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/62/c3/hero_62c3e009-e1ba-4475-a6ba-46a2b9b161bf.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/62/c3/small_hero_62c3e009-e1ba-4475-a6ba-46a2b9b161bf.PNG 320w, https://ugc.futurelearn.com/uploads/assets/62/c3/hero_62c3e009-e1ba-4475-a6ba-46a2b9b161bf.PNG 648w, https://ugc.futurelearn.com/uploads/assets/62/c3/large_hero_62c3e009-e1ba-4475-a6ba-46a2b9b161bf.PNG 729w, https://ugc.futurelearn.com/uploads/assets/62/c3/large_hero_62c3e009-e1ba-4475-a6ba-46a2b9b161bf.PNG 2x"/></p>
<p>After many iterations we see our clusters and data memberships begin to converge. What we are left with does not look dissimilar to the original cats and dogs class membership which we used to derive the features.</p>
<p><img alt="K cluster" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/08/a8/hero_08a8fc18-93a4-4f86-9bf4-8229e34a89c2.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/08/a8/small_hero_08a8fc18-93a4-4f86-9bf4-8229e34a89c2.PNG 320w, https://ugc.futurelearn.com/uploads/assets/08/a8/hero_08a8fc18-93a4-4f86-9bf4-8229e34a89c2.PNG 648w, https://ugc.futurelearn.com/uploads/assets/08/a8/large_hero_08a8fc18-93a4-4f86-9bf4-8229e34a89c2.PNG 729w, https://ugc.futurelearn.com/uploads/assets/08/a8/large_hero_08a8fc18-93a4-4f86-9bf4-8229e34a89c2.PNG 2x"/></p>
<p>This is an unsupervised algorithm and it just so happens in our contrived example that the clusters match well the differences between cats and dogs. The algorithm has no idea what cats and dogs are - it is just clustering based on the structure in the data. It just so happens that the features we chose present structure related to cat-like and dog-like aspects of the images.</p>
<p>With a different choice of features we may instead have ended up with clusters which capture something else. Another example might be puppies/kittens (cluster 1) versus adult animals (cluster 2).</p>
<p>If you would like to see these steps animated please click <a href="https://www.youtube.com/watch?v=5I3Ei69I40s">here</a>.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.6&emsp;K-means convergence and choosing numbers of clusters</h2><div class="u-typography-bold-intro">
<p>Different starting points are likely to converge to different states.</p>
<h3 id="local-minima">Local minima</h3>
<p>It is best to run these several times with different initial starting conditions. This can be achieved by selecting clusters that have minimum overall distances. It is an important challenge and a good bet is to run many times depending on how separatable the clusters are.</p>
<p>Choosing the number of clusters is not trivial either. We may be able to guess the likely number of clusters from the number of classes we are wishing to distinguish later.</p>
<p>For example, if distinguishing apples from oranges and bananas in an image classification exercise we could try out <script type="math/tex">k=3</script> and see how that goes.</p>
<p>K-means is an active research area despite the apparent simplicity of the approach. Take a look at this September 2019 research paper - <a href="https://www.sciencedirect.com/science/article/pii/S0031320319301608"><em>How much can k-means be improved by using better initialization and repeats?</em></a> published in the high-quality <strong>Pattern Recognition</strong> journal.</p>
<p><strong>What is the issue in k-means that this paper addresses?</strong></p>
<p>Read the paper above and discuss in the comments section below.</p>
<p>This is like a journal club or reading group. Research teams in universities often use reading groups to keep abreast of the latest results and key papers in the area. Usually a member of the team will select a paper each week and ask the rest of the group to read it. So when the reading group actual meets, people are ready to discuss. In general, the person who selected the paper will lead the discussion. You can try this approach here.</p>
<p><sub><strong>References</strong></sub></p>
<p><sub>Fränti, P. and Sieranoja, S.(2018) ‘How much can k-means be improved by using better initialization and repeats?’, <em>Pattern Recognition</em>, 93, 95-112, available: https://www.sciencedirect.com/science/article/pii/S0031320319301608?via%3Dihub.
</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.7&emsp;Extrinsic evaluation of clustering and application to images</h2><div class="u-typography-bold-intro">
<p>You could also evaluate clustering through seeing if the clusters identified are useful as features for subsequent machine learning tasks.</p>
<p>Let’s take our recurring image processing challenge of identifying cars in a road monitoring camera image. Our raw input as before are pixels. However, these are not great attribute value pairs.</p>
<h3 id="why-is-that">Why is that?</h3>
<p>Single pixels are not very informative, we have so many pixels and each can take on values from a large set depending on camera or subsequent quantisation. So we do what we did before and perhaps break it down against a grid and calculate statistics on each patch.</p>
<p>You could also evaluate clustering through seeing if the clusters identified are useful as features for subsequent machine learning tasks. Let’s take our recurring image processing challenge of identifying cars in a road monitoring camera image which can be seen below.</p>
<p><img alt="Picture of a motorway with vehicles" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/61/32/hero_6132ca85-727f-4431-bac9-5ef03eaeef59.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/61/32/small_hero_6132ca85-727f-4431-bac9-5ef03eaeef59.PNG 320w, https://ugc.futurelearn.com/uploads/assets/61/32/hero_6132ca85-727f-4431-bac9-5ef03eaeef59.PNG 648w, https://ugc.futurelearn.com/uploads/assets/61/32/large_hero_6132ca85-727f-4431-bac9-5ef03eaeef59.PNG 729w, https://ugc.futurelearn.com/uploads/assets/61/32/large_hero_6132ca85-727f-4431-bac9-5ef03eaeef59.PNG 2x"/><br/>
<sub>Source: <a href="https://www.tii.ie/">Transport Infrastructure Ireland</a></sub></p>
<p>Our raw input as before are pixels. However these are not great attribute value pairs. 
 Why is that?</p>
<p>Single pixels are not very informative, we have so many pixels and each can take on values from a large set depending on camera or subsequent quantisation. So we do what we did before and perhaps break it down against a grid and calculate some statistics on each patch.</p>
<p>The patch grids can be seen in the diagram below:</p>
<p><img alt="image of a motorway with vehicles and a patch grid covering the image" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/c4/26/hero_c42691bc-bdec-4c88-b49e-0c8bcf436dad.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/c4/26/small_hero_c42691bc-bdec-4c88-b49e-0c8bcf436dad.PNG 320w, https://ugc.futurelearn.com/uploads/assets/c4/26/hero_c42691bc-bdec-4c88-b49e-0c8bcf436dad.PNG 648w, https://ugc.futurelearn.com/uploads/assets/c4/26/large_hero_c42691bc-bdec-4c88-b49e-0c8bcf436dad.PNG 729w, https://ugc.futurelearn.com/uploads/assets/c4/26/large_hero_c42691bc-bdec-4c88-b49e-0c8bcf436dad.PNG 2x"/>
<sub>Source: <a href="https://www.tii.ie/">Transport Infrastructure Ireland</a></sub></p>
<p>We could look at a colour histogram for each patch.  Clearly the top left hand patch is very different to more central patches.</p>
<p>We could look at edges or at higher level box shapes and their areas. We can record each patches location relative to the other patches. We can look at texture (i.e. stripiness, flat, dimpled, etc), we can look at many things.</p>
<p><img alt="image of motorway with vehicles and a patch green grid  covering the image with a red box on the green grid pointing to a formula" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/b4/fa/hero_b4fa9f9a-0a41-468d-a7a3-5732b6b16089.png" srcset="https://ugc.futurelearn.com/uploads/assets/b4/fa/small_hero_b4fa9f9a-0a41-468d-a7a3-5732b6b16089.png 320w, https://ugc.futurelearn.com/uploads/assets/b4/fa/hero_b4fa9f9a-0a41-468d-a7a3-5732b6b16089.png 648w, https://ugc.futurelearn.com/uploads/assets/b4/fa/large_hero_b4fa9f9a-0a41-468d-a7a3-5732b6b16089.png 729w, https://ugc.futurelearn.com/uploads/assets/b4/fa/large_hero_b4fa9f9a-0a41-468d-a7a3-5732b6b16089.png 2x"/>
<sub>Source: <a href="https://www.tii.ie/">Transport Infrastructure Ireland</a></sub></p>
<p>Therefore, 47th patch in instance d1 has attribute value pairs <script type="math/tex">f_1</script>, etc
And this set of features in this case has the appearance of “roadiness”. We would hope that patch above is similarly looking in terms of features as it too is a road.</p>
<p><img alt="image of motorway with vehicles and a patch green grid covering the image with 2 marked red boxes on the green grid pointing to 2 separate formulas" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/1f/3c/hero_1f3cde6c-ec99-4eca-9cac-30fc417ab5e0.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/1f/3c/small_hero_1f3cde6c-ec99-4eca-9cac-30fc417ab5e0.PNG 320w, https://ugc.futurelearn.com/uploads/assets/1f/3c/hero_1f3cde6c-ec99-4eca-9cac-30fc417ab5e0.PNG 648w, https://ugc.futurelearn.com/uploads/assets/1f/3c/large_hero_1f3cde6c-ec99-4eca-9cac-30fc417ab5e0.PNG 729w, https://ugc.futurelearn.com/uploads/assets/1f/3c/large_hero_1f3cde6c-ec99-4eca-9cac-30fc417ab5e0.PNG 2x"/>
<sub>Source: <a href="https://www.tii.ie/">Transport Infrastructure Ireland</a></sub></p>
<p>We would now hope that this patch has some differences compared with road patches. You would imagine the colour histogram is different and it does not have little boxes in it (i.e. for broken white lines in roads?) or straight edges. This patch should be close to the patch to its left and right in feature space and convey “skyness” if you like.</p>
<p>So we end up with a vector per patch based on some fairly low level machine vision features and then we have perhaps a “bag of words” where each “word” is the vector we have per patch.</p>
<p>For example, in the image above we would have {sky, sky, sky, road, tree, car, road, road,} or {sky:3, road:1, tree:1, car:1, road:2}</p>
<p>Obviously, these would be longer vectors with larger entries given the image we have seen, we are just trying to keep things simple here. You could have fun with such a representation but those labels we use require a person to step in and label them or indeed a classifier within our classifier for that stage.</p>
<p>So what we do next, (given that we are trying to look at clustering and its application), is hope that patch vectors that a human might have labelled as a “car” forms a cluster with other patches that a human might label as a car.</p>
<h3 id="so-how-is-this-done">So how is this done?</h3>
<p>This is done with our clustering algorithm. In this case we look at k-means.
So we now look at clustering all these vectors, i.e. clustering the patches that we produced.</p>
<p>This creation of clusters can be seen in the image below</p>
<p><img alt="image of motorway with vehicles with a patch green grid covering the image with 4 marked red boxed on the grid with an arrow pointing to the wording Sky Cluster and separately 3 red boxes with an arrow pointing to the wording Road Cluster" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/01/ad/hero_01ada4ae-ca68-4830-9de3-0ec2bc3644e3.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/01/ad/small_hero_01ada4ae-ca68-4830-9de3-0ec2bc3644e3.PNG 320w, https://ugc.futurelearn.com/uploads/assets/01/ad/hero_01ada4ae-ca68-4830-9de3-0ec2bc3644e3.PNG 648w, https://ugc.futurelearn.com/uploads/assets/01/ad/large_hero_01ada4ae-ca68-4830-9de3-0ec2bc3644e3.PNG 729w, https://ugc.futurelearn.com/uploads/assets/01/ad/large_hero_01ada4ae-ca68-4830-9de3-0ec2bc3644e3.PNG 2x"/>
<sub>Source: <a href="https://www.tii.ie/">Transport Infrastructure Ireland</a></sub></p>
<p>We hope then across all the images we have for training, that all the patches that look like sky, form one cluster while all the patches which look like cars form another cluster. This is done in an unsupervised way through something like k-means. BTW: See “<a href="https://en.wikipedia.org/wiki/Bag-of-words_model_in_computer_vision">Bag of Words Representation in Machine Vision</a>” for a more detailed explanation.</p>
<p>If we continue our example with the images, we can now replace our high dimension image with a much smaller set of features based on the clusters identified.
So with K-means we could cluster all the feature vectors per patch into a bunch of k clusters.</p>
<p>This means every patch in our image would have a cluster identifier associated with it, so instead of our 640 x 400 pixel image in our example we would have a “bag of cluster labels”.</p>
<p>It is a k-dimensional representation.</p>
<p>Our image would be {Cluster 1: 4, Cluster 2:1, Cluster 3:23, etc} where we have encoded here as cluster id: number of patches with that cluster label. This gives us a very compact representation of our image and we now can have lots of examples with a small number of dimensions, which is good for avoiding our curse of dimensionality.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.8&emsp;Practical skills</h2><div class="u-typography-bold-intro">
<p><img alt="Programmers working in a software developing company office - Shutterstock image number ID:602578049" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/f6/c7/hero_f6c7ef7a-13e9-45d7-9960-5312bfa7a5b1.png" srcset="https://ugc.futurelearn.com/uploads/assets/f6/c7/small_hero_f6c7ef7a-13e9-45d7-9960-5312bfa7a5b1.png 320w, https://ugc.futurelearn.com/uploads/assets/f6/c7/hero_f6c7ef7a-13e9-45d7-9960-5312bfa7a5b1.png 648w, https://ugc.futurelearn.com/uploads/assets/f6/c7/large_hero_f6c7ef7a-13e9-45d7-9960-5312bfa7a5b1.png 729w, https://ugc.futurelearn.com/uploads/assets/f6/c7/large_hero_f6c7ef7a-13e9-45d7-9960-5312bfa7a5b1.png 2x"/></p>
<p>In this step, we are just going to introduce you to some useful tools for machine learning.</p>
<h3 id="programming-languages">Programming languages</h3>
<p>I recommend that you learn <strong>Python</strong>, as it is a high-level programming language useful for all sorts of things from developing web applications to the implementation of signal processing pipelines. It is an interpretable language with an emphasis on readability which helps when sharing code and ideas.</p>
<p><a href="https://www.python.org/">Python</a> is easy to learn and can be learned quickly too.</p>
<p>I would recommend you start with a <a href="https://wiki.python.org/moin/BeginnersGuide">beginners guide to Python</a> and spend a few hours on the tutorials here choosing options according to your programming background and abilities.</p>
<p>Now, for those of you who already know Python and are crestfallen at missing an opportunity to learn something new, why don’t you take a look at <a href="https://www.r-project.org/">R</a>? The R language and environment is used by many of my research teams and is powerful, flexible and incredibly useful for data analysis. It can be used together with Python to do all kinds of interesting things. We won’t directly use R in these courses but you might decide to use it yourself in your own machine learning adventures or your own assignment. For those of you already feeling fully loaded learning Python you don’t need to learn R. I am just making sure everyone is kept busy!</p>
<h3 id="interactive-programming-environments">Interactive programming environments</h3>
<p>For educational purposes, we are going to take an interactive notebook-based approach. You will learn how to use <a href="https://en.wikipedia.org/wiki/Project_Jupyter">Jupyter notebooks</a>.</p>
<p>These provide a very quick and easy way to get up and running with Python and to quickly prototype ideas. It is based on the notion of runnable cells.</p>
<h3 id="citing-the-wikipedia-page-directly">Citing the wikipedia page directly:</h3>
<p>“Jupyter Notebook” (formerly IPython Notebooks) is a web-based interactive computational environment for creating Jupyter notebook documents. The “notebook” term can colloquially make reference to many different entities, mainly the Jupyter web application, Jupyter Python web server, or Jupyter document format depending on context. A Jupyter Notebook document is a JSON document, following a versioned schema, and containing an ordered list of input/output cells which can contain code, text (using Markdown), mathematics, plots and rich media, usually ending with the “.ipynb” extension.
A Jupyter Notebook can be converted to a number of open standard output formats (HTML, presentation slides, LaTeX, PDF, ReStructuredText, Markdown, Python) through “Download As” in the web interface, via the nbconvert library or “jupyter nbconvert” command line interface in a shell.
To simplify visualisation of Jupyter notebook documents on the web, the nbconvert library is provided as a service through NbViewer which can take a URL to any publicly available notebook document, convert it to HTML on the fly and display it to the user.</p>
<p><img alt="Jupyter Notebook interface" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/b6/15/hero_b61596e8-4306-467a-a9a9-7a66ea659cf1.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/b6/15/small_hero_b61596e8-4306-467a-a9a9-7a66ea659cf1.PNG 320w, https://ugc.futurelearn.com/uploads/assets/b6/15/hero_b61596e8-4306-467a-a9a9-7a66ea659cf1.PNG 648w, https://ugc.futurelearn.com/uploads/assets/b6/15/large_hero_b61596e8-4306-467a-a9a9-7a66ea659cf1.PNG 729w, https://ugc.futurelearn.com/uploads/assets/b6/15/large_hero_b61596e8-4306-467a-a9a9-7a66ea659cf1.PNG 2x"/>
Source: <a href="https://commons.wikimedia.org/wiki/File:Paws_notebook_showing_how_to_load_wikidata_item_dictionary.png">Wikimedia Commons</a></p>
<blockquote>
<p>“Jupyter Notebook provides a browser-based (read-eval-print-loop) REPL built upon a number of popular open-source libraries.”<br/>
<a href="https://www.tutorialandexample.com/jupyter-notebook-tutorial/">Tutorial And Example</a> (A tutorial website with real time examples).</p>
</blockquote>
<p>Jupyter supports <a href="https://julialang.org/">Julia</a>, <a href="https://www.r-project.org/about.html">R</a> and <a href="https://www.python.org/">Python</a> so we are well covered.</p>
<h3 id="getting-started-with-jupyter">Getting started with Jupyter.</h3>
<p>Many students like to host their own Jupyter environment such as through the use of <strong>Anaconda</strong>. It is free, powerful and easy to install. You can try it out <a href="https://www.anaconda.com/">here</a>.</p>
<h3 id="google-colab">Google Colab</h3>
<p>For many of you an even more convenient way to get stuck into Python and Jupyter notebooks is through Google’s Colab. Gain an overview of this Jupyter landscape <a href="https://www.datasciencecentral.com/profiles/blogs/all-about-using-jupyter-notebooks-and-google-colab">here</a>.</p>
<p>For Google Colab  your starting point is <a href="https://colab.research.google.com/">here</a>.
This contains some great tutorials which you should go through as you can see in the welcome screenshot in Colab below.</p>
<p><img alt="image of a man with Welcome to Google Colab" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/08/8a/hero_088ad5a1-51b4-4e06-85d9-096168173028.png" srcset="https://ugc.futurelearn.com/uploads/assets/08/8a/small_hero_088ad5a1-51b4-4e06-85d9-096168173028.png 320w, https://ugc.futurelearn.com/uploads/assets/08/8a/hero_088ad5a1-51b4-4e06-85d9-096168173028.png 648w, https://ugc.futurelearn.com/uploads/assets/08/8a/large_hero_088ad5a1-51b4-4e06-85d9-096168173028.png 729w, https://ugc.futurelearn.com/uploads/assets/08/8a/large_hero_088ad5a1-51b4-4e06-85d9-096168173028.png 2x"/></p>
<p>Figure: The first steps with Google’s Colab.</p>
<h3 id="how-far-should-i-go-with-python-and-jupyter-notebooks-before-moving-on">How far should I go with Python and Jupyter notebooks before moving on?</h3>
<p>Well, there will never be an exam question on the use of Jupyter or practical skills of this nature. Consequently there is no material to cover this week other than for you to gain familiarity with the language and the environments. Play with it, experiment, break it, fix it and explore. See what it can do. It should not be a chore.</p>
<h3 id="please-comment">Please comment!</h3>
<p>Let us know in the comments section below what you think about the different programming languages. What have you used before? Do you recommend one programming language over another?</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.10&emsp;Review of Topic 4</h2><div class="u-typography-bold-intro">
<p>Congratulations on completing topic 4 which focussed on feature engineering. In particular we looked at the curse of dimensionality and the importance of selecting features and if necessary creating entirely new features derived from our raw data. We spent some time on clustering which is both an unsupervised machine learning method and a means to generate really useful, lower dimension features for subsequent machine learning pipelines.</p>
<p>Most importantly, even though it was only a single step, you were introduced to Python and Google Colab as an environment for testing out machine learning ideas and designing and running data science experiments.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.11&emsp;What's Next?</h2><div class="u-typography-bold-intro">
<p>In the next course we are going to finally take all our knowledge of attribute-value pairs, our features and our feature engineering skills, and apply these with two machine learning algorithms.</p>
<p>In particular, we are going to examine two classic Machine Learning algorithms - Decision Trees and the Naive Bayes Classifier.  There are many variations of these classifiers which we will not cover in this material. However, the introduction and examples given should give you a solid understanding of the basic ideas and equip you well to learn about variations and enhancements of these basic ideas as they emerge in the field.</p>
<p>In addition, we will spend some time equipping you with some practical tools, based on well known packages for Python which you can use to put your knowledge into action.  We will also introduce an assignment, which is a significant piece of work that you can use to test your understanding and skills.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p style="page-break-before: always"><h2>1.1&emsp;Welcome to Course 2</h2><div class="u-typography-bold-intro">
<p>Hello and welcome to the course. This is the second course in a series of five courses under the Machine Learning program from Dublin City University.</p>
<p>There are many types of machine learning algorithms. In this course, we take a look at algorithms which make use of features based on the discriminative information they provide in arriving at classifications.  A specific example of such an algorithm is a Decision Tree which we explore in an introductory way.</p>
<p>We then proceed to an introduction to probabilistic classifiers such as Bayes Classifier and in particular the Naïve Bayes Classifier which is a good stepping off point for interested students seeking to learn more about Bayes Classification approaches.</p>
<h3 id="your-assignment">Your assignment</h3>
<p>At this point, we will know enough to be able to approach some machine learning challenges. We will, therefore, introduce a significant assignment which you should find challenging and exciting as it is a real-world research problem. This assignment will account for 25% of your marks for this program.</p>
<p>The assignment will involve the application of ideas we have encountered during the course. I can assure you that, daunting as the challenge will sound initially, you will surprise yourself with the progress you will be able to make with the knowledge and skills we will equip you with. We talk more about this later.</p>
<table>
<thead>
<tr>
<th>Assignment</th>
<th>Release date</th>
<th>Submission deadline</th>
</tr>
</thead>
<tbody>
<tr>
<td>Media Memorability</td>
<td>10 February 2020</td>
<td>27 April 2020</td>
</tr>
</tbody>
</table>
<p>To aid you on this journey, new practical skills will be introduced to round off this specific course, and we will continue to add to these over subsequent courses.</p>
<p>In our first topic of this course, we finally take a look at a real machine learning algorithm. At long last, I hear you say!</p>
<p>Our adventures in algorithms begin with an idea called Decision Trees. Decision Trees are the basis for many other variations and extensions that are applied in many real-world applications. What I like about Decision Trees personally is that they are intuitive to understand, easy to visualise, and produce outputs which are interpretable. By interpretable I mean we can trace back from the output and see what it was about a particular input feature vector that caused the algorithm to produce this particular output.  Let’s go ahead and see what I am talking about.</p>
<div class="video_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.2&emsp;Introduction to Decision Trees </h2><div class="u-typography-bold-intro">
<p>Decisions, decisions!</p>
<p>Where should we start our machine learning algorithm journey? Let’s start in an unusual place. We’ll begin with Ludology and board games. If you have ever played the board game <strong>“Guess Who!”</strong> then you will immediately appreciate how asking the right questions, based on character attributes, can quickly identify an individual. For those of you who don’t know the game “Guess Who” check it out here:
</p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<sub>Source: <strong>Triple S Games</strong></sub>
<p>A good strategy for winning ‘Guess Who’ is to ask questions which knock out half the characters every time. For example – you could ask “Is the character called Bob?”. This is not a good question because, on average, if the answer is “No”, then you have only eliminated 1 character. Of course, if the answer is “Yes” then you have won the game. This is what would be called a naïve or optimistic strategy because <strong>on average</strong>, i.e. if you play the game many times, you would have to be incredibly lucky for that to work out!</p>
<p>A better first question, believe it or not, for the game Guess Who is “Does the character have a big mouth”? If you ask that question you can expect to eliminate half the characters. If you try that every time you will have a much better chance of winning compared to a person taking the naïve strategy. This is what is called a “greedy approach” in terms of decision-making theory but, believe it or not, it is not the best strategy. You could take a look at strategies for winning Guess Who online – it’s good preparation for our first machine learning approach which are called Decision Trees.</p>
<h3 id="decision-trees">Decision Trees</h3>
<p>Let’s look at Decision Trees. We can start with a sort of “Hello World” Decision Tree example. I find this classic example, variations of which you can find online (so if my explanation does not work for you search online), to be very useful.</p>
<p>Imagine a situation where we are trying to predict if a person, let’s call them Mary, is going to go for a hike in the woods. Let us suppose Mary has been keeping a diary.  In this diary she has been recording the weather in terms of if it has been sunny/rainy/cloudy and perhaps also if it has been humid and perhaps if it was windy or not. She has also tracked the days she has gone on a hike, perhaps by using an activity tracking-type app. Let us imagine she has pulled that data together for weekend days, i.e. days it would have been possible for her to go on a hike as follows.</p>
<p><img alt="Diagram has a collection of training examples in the format of Day - Temperature -Humidity - Wind - Hike? over a 14 day period. Day temperature humidity wind hike?
Day 1 hot high weak no -red text
Day 2 HOT HIGH strong no - red text
Day 3 warm high weak yes - green text
Day 4 cold high weak yes - green text
Day 5 cold Normal weak yes - green text
Day 6 cold Normal  strong no - red text
Day 7 warm normal strong yes - green text
Day 8 hot high weak no - red text
Day 9 hot normal weak yes - green text
Day 10 cold normal weak yes - green text
Day 11 hot  normal strong yes - green text
 Day 12 warm high strong yes - green text
 Day 13 WARm normal weak yes - green text
 Day 14 cold high strong no - red text" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/c9/74/hero_c9749d6d-0969-42b9-bf5a-6289c6bb60fd.png" srcset="https://ugc.futurelearn.com/uploads/assets/c9/74/small_hero_c9749d6d-0969-42b9-bf5a-6289c6bb60fd.png 320w, https://ugc.futurelearn.com/uploads/assets/c9/74/hero_c9749d6d-0969-42b9-bf5a-6289c6bb60fd.png 648w, https://ugc.futurelearn.com/uploads/assets/c9/74/large_hero_c9749d6d-0969-42b9-bf5a-6289c6bb60fd.png 729w, https://ugc.futurelearn.com/uploads/assets/c9/74/large_hero_c9749d6d-0969-42b9-bf5a-6289c6bb60fd.png 2x"/></p>
<p>So in our sample we have a collection of training examples.</p>
<p>We have 14 days of data. On 9 of those days Mary recorded going for a hike and on 5 of those she did not hike.</p>
<p>Mary is now wondering what her pattern of behaviour has been and decides that maybe she could use this data. She could use these attribute-value pairs to build a machine learning model which would predict her future decisions on hiking, based on these weather-related features.</p>
<p>Mary could then use this machine learning model to make decisions on whether to go hiking or not.</p>
<p>Take the example of the weather on Day 15 which is:</p>
<p><strong>Day 15 Temperature: Cold, Humidity: High, Wind: Weak</strong></p>
<p>A prediction can be made regarding whether or not Mary will go for a hike. However, at this stage the answer is not obvious from looking at the features presented.</p>
<p>We will see, through building a decision tree (DT), we can have a basis for interpreting or understanding when Mary will go or not go for a hike. It may not always be correct, as perhaps there is more to Mary’s decision than the simple features shown. However, hopefully, it will have some predictive capability.</p>
<p>So we take a “Divide and Conquer” approach:</p>
<ul>
<li>Split into subsets based on an attribute</li>
<li>Are they pure? (yes/no?), i.e. is there only one target feature level in the set, e.g. all 
“Yes” or all “No” in this case</li>
<li>If subsets are pure stop</li>
<li>If they are not then repeat the process</li>
<li>See which subset new data falls into in order to make a prediction</li>
</ul>
<h3 id="using-given-datasets">Using given datasets</h3>
<p>Let’s see how it works including exploring what we mean by “pure”.</p>
<p>Let’s take “Temperature” as our first descriptive feature and split on this.</p>
<p><img alt="Diagram has a collection of training examples in the format of Day - Temperature -Humidity - Wind - Hike? over a 14 day period Diagram has a collection of training examples in the format of Day - Temperature -Humidity - Wind - Hike? over a 14 day period. Day temperature humidity wind hike?
Day 1 hot high weak no -red text
Day 2 HOT HIGH strong no - red text
Day 3 warm high weak yes - green text
Day 4 cold high weak yes - green text
Day 5 cold Normal weak yes - green text
Day 6 cold Normal  strong no - red text
Day 7 warm normal strong yes - green text
Day 8 hot high weak no - red text
Day 9 hot normal weak yes - green text
Day 10 cold normal weak yes - green text
Day 11 hot  normal strong yes - green text
 Day 12 warm high strong yes - green text
 Day 13 WARm normal weak yes - green text
 Day 14 cold high strong no - red text" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/c9/74/hero_c9749d6d-0969-42b9-bf5a-6289c6bb60fd.png" srcset="https://ugc.futurelearn.com/uploads/assets/c9/74/small_hero_c9749d6d-0969-42b9-bf5a-6289c6bb60fd.png 320w, https://ugc.futurelearn.com/uploads/assets/c9/74/hero_c9749d6d-0969-42b9-bf5a-6289c6bb60fd.png 648w, https://ugc.futurelearn.com/uploads/assets/c9/74/large_hero_c9749d6d-0969-42b9-bf5a-6289c6bb60fd.png 729w, https://ugc.futurelearn.com/uploads/assets/c9/74/large_hero_c9749d6d-0969-42b9-bf5a-6289c6bb60fd.png 2x"/></p>
<p>So we take the attribute “Temperature” and we set that as a node. We then create branches according to the different levels of “Hot”, “Warm” and “Cold” as follows:</p>
<p><a href="https://ugc.futurelearn.com/uploads/assets/68/f3/68f33239-1108-49c9-907f-02470b0b9fc3.PNG"><img alt="“Temperature” Tree set as a node, showing 3 different branches according to the different levels of “Hot”, “Warm” and “Cold”, subdivided from the original 14 day table" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/e7/db/hero_e7db5fe4-67ba-4fbe-97bc-d5c1f65d200e.png" srcset="https://ugc.futurelearn.com/uploads/assets/e7/db/small_hero_e7db5fe4-67ba-4fbe-97bc-d5c1f65d200e.png 320w, https://ugc.futurelearn.com/uploads/assets/e7/db/hero_e7db5fe4-67ba-4fbe-97bc-d5c1f65d200e.png 648w, https://ugc.futurelearn.com/uploads/assets/e7/db/large_hero_e7db5fe4-67ba-4fbe-97bc-d5c1f65d200e.png 729w, https://ugc.futurelearn.com/uploads/assets/e7/db/large_hero_e7db5fe4-67ba-4fbe-97bc-d5c1f65d200e.png 2x"/></a></p>
<p>There are 3 examples of Mary not going for a hike when it is “hot” and 2 examples where she did not go for a hike when it is “cold”. These are not “pure” datasets and will require splitting, based on the remaining attributes. But, take a look at “Warm”, every time the temperature was “Warm”, Mary went for a hike. This is a “pure” dataset and requires no further splitting. If this was a game of “Guess who”? If we asked the question “Is it warm outside?” then we would know for sure Mary goes for a hike (or at least the data to date demonstrates this).</p>
<p>What’s next? Ok let’s pursue pure datasets for the “Hot” and “Cold” branches in turn.</p>
<p>Let’s choose the ”Hot” subset and split it based on something. Let’s try the “Humidity” feature. We now end up with the following:</p>
<p><a href="https://ugc.futurelearn.com/uploads/assets/ba/68/ba686254-b7c5-4bca-bc69-38d1971ccd88.PNG"><img alt="Dataset Diagram Algorithm for Hot and Cold and warm Temperature Branches. A branch for humidity has been added and below this are further branches stating 'high' and 'normal'. The text beneath the 'high' subset table reads 'pure subset' while the text beneath the 'normal' subset table reads 'pure subset'" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/ba/68/hero_ba686254-b7c5-4bca-bc69-38d1971ccd88.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/ba/68/small_hero_ba686254-b7c5-4bca-bc69-38d1971ccd88.PNG 320w, https://ugc.futurelearn.com/uploads/assets/ba/68/hero_ba686254-b7c5-4bca-bc69-38d1971ccd88.PNG 648w, https://ugc.futurelearn.com/uploads/assets/ba/68/large_hero_ba686254-b7c5-4bca-bc69-38d1971ccd88.PNG 729w, https://ugc.futurelearn.com/uploads/assets/ba/68/large_hero_ba686254-b7c5-4bca-bc69-38d1971ccd88.PNG 2x"/></a></p>
<p>So the algorithm stops on the left-hand side now, as we have pure sets. So, if the Temperature is “Hot” and the Humidity is “Normal”, Mary goes for a hike.</p>
<p>Now let’s look at the “Rain” subset. Let’s split here on something such as “Wind”.</p>
<p><a href="https://ugc.futurelearn.com/uploads/assets/aa/ee/aaeed6a2-00e2-4b71-9ab9-e1957451ae9d.PNG"><img alt="Subset diagram with 3 branches - on the top branch the word' temperature' is pointing with the arrow to the word Warm. Lower down the left branch has the word Hot pointing down with the arrow to the word Humidity from this word an arrow goes to the left to the word High and the other arrow points to the right out of the word Humidity and says Normal  - each branch has subsets with the following - The Warm branch has a pure subset below it with the headings Day - Temperature -Humidity- Wind. The Humidity Branch has 2 two separate subsets with the words Day - Humidity - Wind.  The Wind Branch has two separate subsets with the words Day - Humidity and Wind on them." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/aa/ee/hero_aaeed6a2-00e2-4b71-9ab9-e1957451ae9d.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/aa/ee/small_hero_aaeed6a2-00e2-4b71-9ab9-e1957451ae9d.PNG 320w, https://ugc.futurelearn.com/uploads/assets/aa/ee/hero_aaeed6a2-00e2-4b71-9ab9-e1957451ae9d.PNG 648w, https://ugc.futurelearn.com/uploads/assets/aa/ee/large_hero_aaeed6a2-00e2-4b71-9ab9-e1957451ae9d.PNG 729w, https://ugc.futurelearn.com/uploads/assets/aa/ee/large_hero_aaeed6a2-00e2-4b71-9ab9-e1957451ae9d.PNG 2x"/></a></p>
<p>“Wind” is a good choice here as we don’t have to go deeper. We now have pure subsets all round.  We have now a situation where all branching of the tree leads to a leaf node which allows us to determine a clear classification. If our final subsets were not pure we might decide to take the majority outcome in such a subset. In this case, our final decision tree is as follows:</p>
<p><a href="https://ugc.futurelearn.com/uploads/assets/22/c0/22c0ec2a-5406-4c8f-937e-2913723af14e.PNG"><img alt='3 Branches of the tree - Top branch has the word "temperature with the arrow pointing to the word Warm - under the word warm written in green it says Mary Hikes - The branch lower down to the left says Hot with the word pointing to Humidity from this there is a left arrow pointing to High - under high there written in red says  Mary does not hike and a right arrow pointing to Normal underneath normal written in green 
it says Mary Hikes. The final branch on the right has the word Cold pointing downwards to the word Wind with an arrow pointing on the left to the word Weak under the word Weak is written in green Mary hikes and another arrow pointing to the word Strong - under the word strong written in red it says Mary does not hike' sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/22/c0/hero_22c0ec2a-5406-4c8f-937e-2913723af14e.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/22/c0/small_hero_22c0ec2a-5406-4c8f-937e-2913723af14e.PNG 320w, https://ugc.futurelearn.com/uploads/assets/22/c0/hero_22c0ec2a-5406-4c8f-937e-2913723af14e.PNG 648w, https://ugc.futurelearn.com/uploads/assets/22/c0/large_hero_22c0ec2a-5406-4c8f-937e-2913723af14e.PNG 729w, https://ugc.futurelearn.com/uploads/assets/22/c0/large_hero_22c0ec2a-5406-4c8f-937e-2913723af14e.PNG 2x"/></a></p>
<p>Let’s apply our new data: <strong>Temperature: Cold, Humidity: High, Wind: Weak.</strong></p>
<p>We follow the tree from the root node to the leaf across the attribute values. We have marked this in red in the figure.</p>
<p><a href="https://ugc.futurelearn.com/uploads/assets/38/08/38083e60-544b-47fc-8e4a-3e3d3e0924e7.PNG"><img alt="Decision Temperature Tree - On the Top Branch the word Temperature with the arrow pointing to the word warm under the word written in Green it states Mary Hikes.  To the left there is another branch with states Hot leading from Hot an arrow takes us to the word Humidity From Humidity the left arrow takes us to the word High - under the word High is written Mary does not hike. A right arrow from the word Humidity says Normal under the word Normal written in Green it states Mary hikes - The third branch of the tree which is located on the right hand side has the word Cold written the arrow pointing from Cold leads to the word wind - From wind the left arrow points to the word Weak in GREEN it states Mary Hikes - Another arrow leads out to the right from the word wind and points to the word Strong under the word Strong is written in Red Mary does not hike" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/38/08/hero_38083e60-544b-47fc-8e4a-3e3d3e0924e7.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/38/08/small_hero_38083e60-544b-47fc-8e4a-3e3d3e0924e7.PNG 320w, https://ugc.futurelearn.com/uploads/assets/38/08/hero_38083e60-544b-47fc-8e4a-3e3d3e0924e7.PNG 648w, https://ugc.futurelearn.com/uploads/assets/38/08/large_hero_38083e60-544b-47fc-8e4a-3e3d3e0924e7.PNG 729w, https://ugc.futurelearn.com/uploads/assets/38/08/large_hero_38083e60-544b-47fc-8e4a-3e3d3e0924e7.PNG 2x"/></a></p>
<p>That is the basic idea of a decision tree. In the next step we will look at a specific algorithm for developing this because, as you might have noticed, we selected attributes to split in this example without a lot of thought. There are specific approaches to doing this decision tree construction in a way which yields useful decision trees.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.3&emsp;The ID3 Algorithm</h2><div class="u-typography-bold-intro">
<p>In the last step we ended by stating that we would look at some specific algorithms for constructing decision trees given training data.</p>
<p>The ID3 algorithm <a href="https://en.wikipedia.org/wiki/ID3_algorithm">(Iterative Dichotomiser 3)</a> is one such specific algorithm. It is used to generate a decision tree from a given dataset by employing a top-down greedy search in order to test each attribute at every node of the tree. The resulting tree is used to classify future samples.The ID3 is a classic algorithm to use for an introduction to decision trees. Improved algorithms include the very commonly used <a href="https://en.wikipedia.org/wiki/C4.5_algorithm">C4.5 algorithm</a> which was developed by the same creator of ID3 - <a href="https://en.wikipedia.org/wiki/Ross_Quinlan">Ross Quinlan</a> and CART (Classification and Decision Tree). This is similar to C4.5 but can also support numerical target features, i.e. regression.</p>
<p>The basic idea of ID3 is to first find an attribute which best classifies the examples given in the training data. Next, you make that attribute a decision tree node and recursively repeat this process for the subsets created using the remaining attributes. This is what we did in the previous step, except we never got into details on how the “best” attribute is selected. We will deal with that now. But first, here is the pseudo-code for the ID3 algorithm which you should examine. The most important piece that will stick out for you is the step that specifies choosing the attribute that best classifies the examples.</p>
<p><a href="https://ugc.futurelearn.com/uploads/assets/9d/9d/9d9d6f17-69af-4a69-8443-b425d288d7b1.png"><img alt="ID3 Algorithm - text reads. 'examples, target attribute, attributes, create a root node for the tree. If all examples are positive, return the single node tree root, with label = +. if all examples are negative, return the single node tree root, with label + -. If number of predicting attributes is empty, then Return the single node tree root, with label = most common value of the target attribute in the examples. Otherwise Begin a The attribute that best classifies examples. Decision Tree attribute for Root = A. For each possible value, v 1 of A, Add a new tree branch below Root, corresponding to the test A = V1. Let Examples (v1) be the subset of examples that have the value v1 for A If Examples (v1) is empty then below this new branch add a leaf node with label = most common target value in the examples Else below this new branch add the subtree ID3 (Examples (v1), Target Attribute, Attributes - {A}) End Return Root" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/9d/9d/hero_9d9d6f17-69af-4a69-8443-b425d288d7b1.png" srcset="https://ugc.futurelearn.com/uploads/assets/9d/9d/small_hero_9d9d6f17-69af-4a69-8443-b425d288d7b1.png 320w, https://ugc.futurelearn.com/uploads/assets/9d/9d/hero_9d9d6f17-69af-4a69-8443-b425d288d7b1.png 648w, https://ugc.futurelearn.com/uploads/assets/9d/9d/large_hero_9d9d6f17-69af-4a69-8443-b425d288d7b1.png 729w, https://ugc.futurelearn.com/uploads/assets/9d/9d/large_hero_9d9d6f17-69af-4a69-8443-b425d288d7b1.png 2x"/></a></p>
<p>So how do we decide which attribute is best to split on? The ID3 algorithm uses the statistical measures of entropy and information gain to do this. Before we examine this in detail let us develop our intuition for the idea.</p>
<h3 id="splitting-attributes">Splitting attributes</h3>
<p>An attribute can be the “Best Attribute to split” if it reduces uncertainty the most when we look at the subsets generated under each value of the attribute. Let’s look at our example and examine the difference between splitting on “Temperature”  versus splitting on “Wind”.</p>
<p><a href="https://ugc.futurelearn.com/uploads/assets/2e/3c/2e3c9fb0-7ffa-409f-977b-be7e2b7f9813.png"><img alt="2 Decision Trees one with Temperature and the other with Wind as a heading.  On  the top of the Temperature is written 9 yes/5 no. On the Top of the Wind 9 yes/5 no  is written. Underneath the Temperature 3 arrows point outwards connecting to the words Hot Warm Cold - underneath the word Hot it states 2 yes/3 no Underneath the word warm it states 4 yes/0 no underneath the word Cold it states 3 yes/2 no.  The second tree named Wind has 2 arrows pointing out one with the word stating 'weak' and the second with the word 'strong' under the word weak it says 6 yes/2no under the word strong it states 3 yes/3 no" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/2e/3c/hero_2e3c9fb0-7ffa-409f-977b-be7e2b7f9813.png" srcset="https://ugc.futurelearn.com/uploads/assets/2e/3c/small_hero_2e3c9fb0-7ffa-409f-977b-be7e2b7f9813.png 320w, https://ugc.futurelearn.com/uploads/assets/2e/3c/hero_2e3c9fb0-7ffa-409f-977b-be7e2b7f9813.png 648w, https://ugc.futurelearn.com/uploads/assets/2e/3c/large_hero_2e3c9fb0-7ffa-409f-977b-be7e2b7f9813.png 729w, https://ugc.futurelearn.com/uploads/assets/2e/3c/large_hero_2e3c9fb0-7ffa-409f-977b-be7e2b7f9813.png 2x"/></a></p>
<p>So, while we are not yet defining certainty in any mathematical way, let’s examine which of the two split possibilities yield most certainty for us intuitively.</p>
<p>If we look at the “Temperature” attribute we see we have for the attribute level of “Warm” we have complete certainty of the target. If we look at the attribute level for “Hot” and “Cold” we are quite uncertain again, but overall the split on “Temperature” is not bad.</p>
<p>If we look at “Wind” and the level is “Strong,” we are completely uncertain. If we have “Weak” then we can be more certain that it is time for a hike, but we cannot be completely certain. 
Which split would you prefer based on what you see? Most people would choose “Temperature”.</p>
<p>What we are doing here is looking for attributes to split on which create subsets as close to pure as possible. The closer to pure they are, the more certain we become regarding the prediction. Think about it. Play with scenarios in your head by experimenting with the attribute values above.</p>
<p>Now let us look more formally at the information gain and the uncertainty measures, which are reflected in your intuition, in the next step.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.4&emsp;Entropy and Information Gain</h2><div class="u-typography-bold-intro">
<p>The ID3 algorithm does not have your quick human intuition about attributes which yield good splits.</p>
<p>How should it then choose the best attribute to split on?</p>
<p>Possibilities include:</p>
<ul>
<li><strong>Random:</strong> Just choose any attribute</li>
<li><strong>Minimum Set of Values:</strong> Pick the attribute with the smallest number of possible 
 values</li>
<li><strong>Maximum Set of Values:</strong> Perhaps pick the attribute with the largest number of 
  possible values</li>
<li><strong>Maximising Information Gain:</strong> Choosing attributes that will lead to the smallest 
size 
of subtrees (if this was our <strong>“Guess Who”</strong> game it would be the strategy which on 
average gets you to the answer with the least number of questions)</li>
</ul>
<p>The ID3 algorithm chooses the last approach, based on the use of information theory. In particular, the ID3 algorithms uses a calculation of entropy and Information Gain to calculate the best splits. We’ll now look at these measures in some detail before putting them together.</p>
<h3 id="entropy">Entropy</h3>
<p>Entropy is interpreted in different ways, but in our context, we will consider it a measure of the homogeneity of a set. Homogeneity is a measure of purity of our set – the term we used earlier. Entropy goes up as our certainty and homogeneity decreases. If a given subset has a 50:50 split between our two classes (we have been looking at yes/no classes in our example) then we are very uncertain how to predict the outcome (we might as well just flip a coin for a new data instance that splits to that subset to assign it to one of the two classes). In such a case Entropy is at a maximum. At the other extreme imagine our split leads to a subset which has only one class, e.g. like Temperature level “Warm” in the previous step. In that case, we have a lot more certainty for any incoming data point for which Temperature is “Warm”, i.e. Mary will go for a hike if past data is anything to go by. In this case, Entropy is zero. There is no uncertainty and we have indeed 100% certainty. Given the contrary directions of entropy and impurity, it may be better to call entropy a measure of impurity of our set.</p>
<p>The formula to calculate entropy is:</p>
<script type="math/tex; mode=display">H(x) = - \sum_{i=1}^n P(X=i) \log_2 P(X=i)</script>
<p>Here, <script type="math/tex">X</script> is a random variable under consideration.  <script type="math/tex">n</script> is the number of possible values for <script type="math/tex">X</script> and <script type="math/tex">P(X)</script> is the probability of the event <script type="math/tex">X</script> for this random variable.  By event, we mean the target attribute values, i.e. Mary goes for a hike and Mary does not go for a hike. It is a binary class, so our sum over <script type="math/tex">X</script> is just a sum over two different values. Let’s look at our example again. We have a set <script type="math/tex">S</script> of training data examples so we will measure which we can call sample entropy for this binary-valued random variable.</p>
<script type="math/tex; mode=display">H(s) = -p_+\log_2 p_+ -p_- \log_2 p_-</script>
<p>Let’s say we have a very uncertain situation where a split gives us a set S with 5 instances which are “Yes” (i.e. Mary goes for a hike) and 5 instances which are “No” (i.e. Mary does not go for a hike). In that case:</p>
<script type="math/tex; mode=display">H(s) = \frac{5}{10}\log_2(\frac{5}{10}) -\frac{5}{10}\log_2(\frac{5}{10}) = 1</script>
<p>The unit of information, by the way, is called a bit so we would usually write this as 1 bit.</p>
<p><script type="math/tex">\frac{5}{10}</script> is the probability of both the positive and negative examples in this set <script type="math/tex">S</script>.</p>
<p>Note <script type="math/tex">S</script> is our set (or subset at deeper nodes of tree) of training examples. 
Also, note that <script type="math/tex">p_+</script> and <script type="math/tex">p_-</script> are the % of positive and negative examples in the set S under consideration and these are arrived at by counting.</p>
<p>Let’s take another example where we find a split which yields 10 examples, where the “Goes for a Hike” attribute is “Yes”, and 0 (zero) examples where the ”Goes for a Hike” attribute is “No”.</p>
<p>In this case we have what we call a pure subset and the entropy can be calculated as follows:</p>
<script type="math/tex; mode=display">H(s) = - \frac{10}{10} (\log_2 \frac{10}{10}) - \frac{0}{10} (\log_2 \frac{10}{10}) = 0 \:  bit</script>
<p>In our binary target attribute value system entropy swings between 0 and 1 at the extremes. A plot of entropy versus probability of “Yes” (or example) for such a system is as per the figure.</p>
<p><img alt="Diagram of Binary Target Attribute Value system - Entropy swings between 0 and 1 A plot of entropy versus probability of “Yes” (or example) for such a system" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/81/65/hero_81651cca-e8be-4dc8-9700-d1c53afe87a9.png" srcset="https://ugc.futurelearn.com/uploads/assets/81/65/small_hero_81651cca-e8be-4dc8-9700-d1c53afe87a9.png 320w, https://ugc.futurelearn.com/uploads/assets/81/65/hero_81651cca-e8be-4dc8-9700-d1c53afe87a9.png 648w, https://ugc.futurelearn.com/uploads/assets/81/65/large_hero_81651cca-e8be-4dc8-9700-d1c53afe87a9.png 729w, https://ugc.futurelearn.com/uploads/assets/81/65/large_hero_81651cca-e8be-4dc8-9700-d1c53afe87a9.png 2x"/></p>
<p>We now use that measure of entropy to measure the uncertainty in a set of training examples in terms of the target feature attribute level.  So now we proceed to the next step – conditional entropy.</p>
<p><img alt="Entropy of life represented by light in chaotic patterns_black background" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/c0/31/hero_c03176d3-9c06-4be2-93f4-dd3721284142.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/c0/31/small_hero_c03176d3-9c06-4be2-93f4-dd3721284142.jpg 320w, https://ugc.futurelearn.com/uploads/assets/c0/31/hero_c03176d3-9c06-4be2-93f4-dd3721284142.jpg 648w, https://ugc.futurelearn.com/uploads/assets/c0/31/large_hero_c03176d3-9c06-4be2-93f4-dd3721284142.jpg 729w, https://ugc.futurelearn.com/uploads/assets/c0/31/large_hero_c03176d3-9c06-4be2-93f4-dd3721284142.jpg 2x"/></p>
<h3 id="conditional-entropy">Conditional Entropy</h3>
<p>Here we look at the amount of certainty a particular attribute gives us if we were to split a subset of training examples <script type="math/tex">S</script> on it.  We are really looking for an attribute which, if we split on it, gives us as many items of our set S as possible in pure sets.  We will use our measures of uncertainty (entropy) to do this, by conditioning it on the attribute.</p>
<p>So we can introduce the specific conditional entropy  <script type="math/tex">H(X \mid Y=v)</script></p>
<script type="math/tex; mode=display">H( X \mid Y = v) = -\sum_{i=1} ^n P(X=i \mid Y = v) \log_2 p(X=i \mid Y=v)</script>
<p>This is the amount of impurity present when we choose a specific attribute <script type="math/tex">Y</script> to have the value <script type="math/tex">v</script>.</p>
<p>This means that for a specific attribute <script type="math/tex">Y</script>, if we want to look at the expected impurity over all values of the attribute, we go a step further to use the conditional entropy <script type="math/tex">H(X \mid Y)</script> which is:</p>
<script type="math/tex; mode=display">H(X \mid Y) = \sum_{v \in values(Y)} P(Y=v) H(X \mid Y = v)</script>
<p>You might consider this the weighted sum of the entropies of the resulting subsets caused by the splits on that attribute with the greatest weighting given the largest set.</p>
<p>Again, we are looking at sample conditional entropy, so we might use the notation 
<script type="math/tex">H(S \mid Y)</script>. We need <script type="math/tex">H(S \mid Y)</script> to be as small as possible, i.e. our use of the attribute has tidied up the subsets generated significantly so they are a lot purer than they were.</p>
<p>Now we have a way of calculating the entropy of a given subset <script type="math/tex">S</script> and a way of calculating the entropy associated with splitting on an attribute <script type="math/tex">Y</script> on that set <script type="math/tex">S</script>.</p>
<p>We will see a calculation of this in the next subsection when we put this all together.
This next part is to look at choosing an attribute which reduces uncertainty the most compared to other attributes. To measure this we look at <em>Information Gain</em>.</p>
<h3 id="information-gain-ig">Information Gain (IG)</h3>
<p>The Information Gain is based on the decrease in entropy after a dataset is split on an attribute. Constructing a decision tree is all about selecting each attribute <script type="math/tex">(Y)</script> to calculate Information Gain and finding such an attribute that returns the highest <script type="math/tex">IG</script> (i.e., the most homogeneous branches). This attribute will be the next decision node for the tree.</p>
<p>Let’s look at this more formally. Information Gain is also known as Mutual Information. In this gain, you can consider it the Mutual Information between an attribute <script type="math/tex">Y</script> and the random variable <script type="math/tex">X</script>.</p>
<script type="math/tex; mode=display">I(X,Y) = H(X) - H(X \mid Y)</script>
<p>For our sample Information Gain, we can consider this the Mutual Information between our attribute <script type="math/tex">Y</script> and class labels of our sample of training examples <script type="math/tex">S</script>.</p>
<p>The formula to calculate Information Gain is as follows:</p>
<script type="math/tex; mode=display">Gain(S,Y) = H(S) - \sum_{v\in Values(Y)} \frac{\mid Sv \mid}{ \mid S \mid H(Sv)}</script>
<p>where</p>
<p><script type="math/tex">v</script> are possible values of <script type="math/tex">Y</script><br/>
<script type="math/tex">S</script> is a set of examples (sample of <script type="math/tex">X</script>)  <br/>
<script type="math/tex">S_v</script> is subset where <script type="math/tex">X_Y</script> = <script type="math/tex">v</script></p>
<p>Let’s look at our choice for the first node in our example in the previous step. We had:</p>
<p><img alt="Decision Tree diagram of Temperature versus Wind - Temperature Tab with 3 arrows pointing outwards Hot (2 yes/3no)- Warm(4 yes/0 No Cold (3 yes/2 No) - Cold 3 Ye/2 No. Wind with 2 Arrows pointing Outwards Weak (6 yes/2 no) Strong is 3 yes/3 no" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/a5/cd/hero_a5cdc4bf-4b86-45e8-90ca-e86dcb0563d9.png" srcset="https://ugc.futurelearn.com/uploads/assets/a5/cd/small_hero_a5cdc4bf-4b86-45e8-90ca-e86dcb0563d9.png 320w, https://ugc.futurelearn.com/uploads/assets/a5/cd/hero_a5cdc4bf-4b86-45e8-90ca-e86dcb0563d9.png 648w, https://ugc.futurelearn.com/uploads/assets/a5/cd/large_hero_a5cdc4bf-4b86-45e8-90ca-e86dcb0563d9.png 729w, https://ugc.futurelearn.com/uploads/assets/a5/cd/large_hero_a5cdc4bf-4b86-45e8-90ca-e86dcb0563d9.png 2x"/></p>
<p>And we decided to go with Temperature for this first split. Was this a good decision? Let’s work it out.</p>
<p>For Temperature we have:</p>
<script type="math/tex; mode=display">H(S_{Temp}) = - \frac{9}{14} \log_2 \frac{9}{14} - \frac{5}{14} \log_2 \frac{5}{14} = 0.95</script>
<p>Then</p>
<script type="math/tex; mode=display">H(S_{Hot}) =  -\frac{2}{5} \log_2 \frac {2}{5} - \frac {3}{5} \log_2 \frac{3}{5} = -(0.4)(-1.321)-(0.6)(-0.74) = 0.528 + 0.444 = 0.972</script>
<p>Then</p>
<p><script type="math/tex">H(S_{Warm}) = -\frac{4}{4} \log_2 \frac{4}{4} - \frac{0}{4} \log_2 \frac {0}{4} = 0</script><br/>
And <br/>
<script type="math/tex">H(S_{Cold}) =  -\frac{3}{5} \log_2 \frac {3}{5} -\frac{2}{5} \log_2 \frac {2}{5} = 0.972</script></p>
<p>Information Gain is then</p>
<script type="math/tex; mode=display">0.95 –(5/14)(0.972) – (4/14)(0) – (5/14)(0.972) = 0.95-0.347-0-0.347=0.256 \:bits</script>
<p>Now let’s look at our other candidate, Wind.</p>
<script type="math/tex; mode=display">H(S_{Weak}) = -\frac{6}{8} \log_2 \frac{6}{8} -\frac{2}{8} \log_2 \frac{2}{8} = 0.81</script>
<p>And</p>
<script type="math/tex; mode=display">H(S_{Strong}) = -\frac{3}{6} \log_2 \frac{3}{6} - \frac{3}{6} \log_2 \frac{3}{6} =1</script>
<p>And</p>
<p><script type="math/tex">Gain (S, “Wind”) = H(S) - \frac{8}{14}H(S_{Weak}) - \frac{6}{14} H(S_{Strong})</script>
<script type="math/tex">= 0.95 - \frac{8}{14} 0.81 - \frac{6}{14} (1.0) =0.05 \:bits</script></p>
<p>We gain 0.05 bits by splitting on Wind but a whopping 0.256 bits by splitting on Temperature. Therefore, we chose wisely in the previous step.</p>
<p>We can now see how we choose the best attribute to split on, based on the use of information as specified in the ID3 algorithm.  Each subsequent split decision uses the same approach.</p>
<p>There comes a point where we don’t or can’t split any more. If we don’t have pure sets in these leaf nodes then the target feature level is based on the majority occurrence in that final set.  With this understanding let us look more at what issues arise with decision trees.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.5&emsp;Overfitting</h2><div class="u-typography-bold-intro">
<p>Over-fitting is the phenomenon in which the learning system tightly fits the given training data so much that it would be inaccurate in predicting the outcomes of the untrained data.</p>
<p>In <strong>Decision Trees,</strong> <strong>over-fitting</strong> occurs when the <strong>Tree</strong> is designed so as to perfectly fit all samples in the training data set. If we consider our “Does Mary go for a hike today” example and we imagine it has many more attributes, overfitting might look like:</p>
<blockquote>
<p>“Mary goes for a hike if it is warm,  not humid and there is a light breeze and if it is 4pm on her birthday and she has eaten an ice-cream that day and she is wearing her green shirt.”</p>
</blockquote>
<p>Let’s think about this. We could always classify our training examples perfectly. How do we do this? Well, how about we keep splitting and splitting until we have 1 leaf per training example? These singletons are a pure subset by default. However, we could imagine that this might not work well on new data, as at this point, if this is real world data, we will have fitted noise and idiosyncrasies into the training data. Data we have not seen before, i.e. test data, is unlikely to have the same noise and idiosyncrasies expressed in precisely the same way in their attributes.</p>
<p>The graph below illustrates more generally overfitting as we increase the depth of our tree in pursuit of ever increasing performance on our training data. We can see overfitting occurs when testing data begins to produce inferior results.</p>
<p><img alt="Chart graph with blue arrow pointing upwards as an indicator of 'Accuracy' and blue  arrow pointing to the right stating Sizes of Tree - number of nodes. Green line protruding in a curved manner to the right a 1/3 of the way up the  blue line  saying 'Performance with Training Data' directly underneath green line is a Red jagged line pointing in a curved manner downwards stating 'Performance with Testing Data" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/b3/9a/hero_b39acfff-689c-47f7-b01d-9e51b6fc8823.png" srcset="https://ugc.futurelearn.com/uploads/assets/b3/9a/small_hero_b39acfff-689c-47f7-b01d-9e51b6fc8823.png 320w, https://ugc.futurelearn.com/uploads/assets/b3/9a/hero_b39acfff-689c-47f7-b01d-9e51b6fc8823.png 648w, https://ugc.futurelearn.com/uploads/assets/b3/9a/large_hero_b39acfff-689c-47f7-b01d-9e51b6fc8823.png 729w, https://ugc.futurelearn.com/uploads/assets/b3/9a/large_hero_b39acfff-689c-47f7-b01d-9e51b6fc8823.png 2x"/></p>
<h3 id="avoiding-overfitting">Avoiding Overfitting</h3>
<p>There are several ways to stop overfitting. One method is to stop splitting when the quality of the split is poor. One simple way of doing this is by setting a threshold on the increase in purity you want to see in your splits. Another more robust way is to see if the potential split produces significant differences in the populations. Take a look at this article, <a href="http://erikerlandson.github.io/blog/2016/05/26/measuring-decision-tree-split-quality-with-test-statistic-p-values/">Measuring Decision Tree Split Quality with Test Statistic P-Values</a> for more information on this.</p>
<h3 id="subtree-replacement-pruning">Subtree replacement pruning</h3>
<p>Another idea is to grow the tree quite fully and then post-prune, based on validation set. 
Let’s think about this idea which is called subtree replacement pruning.</p>
<p>For each node, we can see what will happen if we remove that node and all the children from that tree. We could measure performance on the validation set and make a decision on its retention based on the performance change. We could try this out for all nodes and permanently remove nodes to facilitate the greatest improvement. We could keep repeating this until further pruning is harmful.</p>
<p>Another arguably more common approach is to use an ensemble of decision trees in an approach referred to as Random Forests. We will consider this in the next step.</p>
<p><sub><strong>References</strong></sub></p>
<p><sub>Landson, E. (2016) ‘Measuring Decision Tree Split Quality with Test Statistic P-Values’ <em>tool monkey</em>, available: http://erikerlandson.github.io/blog/2016/05/26/measuring-decision-tree-split-quality-with-test-statistic-p-values/ [accessed 3 Dec 2019]</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.6&emsp;More robust Decision Trees through Random Forests</h2><div class="u-typography-bold-intro">
<p>A random forest, as its name implies, consists of a large number of individual decision trees that operate as an <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble</a>.</p>
<p>Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction.</p>
<p>It is an example of an ensemble method and more specifically <a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating">“bagging”</a> which we will examine more formally in a later course. For now it is sufficient that you understand that random forests use a collection of decision trees to reduce overfitting. If you want to get started with random forests ahead of our more formal coverage of ensemble methods, we present the basic algorithm here. This explanation should make sense based on the material covered to date.</p>
<h3 id="the-steps-to-implement-random-forests-algorithm">The steps to implement Random Forests algorithm</h3>
<p><strong>Step 1:</strong> Grow <script type="math/tex">K</script> different decision trees. 
How precisely do we do this? First, we pick a random subset <script type="math/tex">S_r</script>of training examples and grow a full ID3 tree <script type="math/tex">T</script> (without any pruning). When you do the splitting choose from <script type="math/tex">% <![CDATA[
y<<Y %]]></script> random attributes. This is random attribute selection. We then compute our information gain steps based on <script type="math/tex">S_r</script> instead of the full set of training examples we began with. We repeat this process for all <script type="math/tex">K</script> trees. We should have <script type="math/tex">K</script> different trees.</p>
<p>So let’s imagine we were doing our “Does Mary go for hike” example and that we have many more attributes than the original three that we had. These new attributes could be:</p>
<p>Weekday or Weekend? 
Or perhaps Birthday or not? 
Or perhaps “Proximity to nearest mountain”.</p>
<p>The details don’t matter. Let’s just imagine there are several. We specify this last assumption to turn this into an interesting example that might merit a random forest. Let’s choose <script type="math/tex">K=3</script> for this exposition.</p>
<p>So our first tree, Tree 1 uses a random subset of training examples we call <script type="math/tex">S_{r1}</script> and a random subset of features <script type="math/tex">Y_{r1}</script> to yield the following. We show in red the output of the tree for our testing example Test 1. It is not important what the attributes and their values are for this tree, but what is important for this specific fixed test example Test 1 is that we can see the highlighted path through the tree and it predicts that this Test 1 is classified as a “Yes”, i.e. Mary will go for a hike.</p>
<p><img alt='Tree with random subset named Sr1,Yr1 on top of the Tree arrow leading straight down to a white shaped empty oval - underneath the shape it says "Yes" To the left of the top of tree there is a Red line that leads to the downwards arrow pointing to an empty oval shape - leading from this shape is a Red arrow pointing to a blue ova. To the left of the blue Oval is a Red arrow pointing to an empty oval shape under this shape is the word "Yes" to the right of the blue oval there is a blue arrow pointing to another empty oval shape. Under this shape is the word "No" - On top of the tree to the Right there is a blue line with a downwards arrow pointing to an empty oval shape. Leading from this shape the arrow points to a blue shaped oval. Leading out of the Left via a blue arrow it leads to an empty oval shape. Underneath this word it states "Yes"  To the right of the blue oval there is an arrow that points an empty oval shape underneath this shape it states "No"' sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/8a/b9/hero_8ab922e8-fcbf-423b-9429-03c1ae7ed82c.png" srcset="https://ugc.futurelearn.com/uploads/assets/8a/b9/small_hero_8ab922e8-fcbf-423b-9429-03c1ae7ed82c.png 320w, https://ugc.futurelearn.com/uploads/assets/8a/b9/hero_8ab922e8-fcbf-423b-9429-03c1ae7ed82c.png 648w, https://ugc.futurelearn.com/uploads/assets/8a/b9/large_hero_8ab922e8-fcbf-423b-9429-03c1ae7ed82c.png 729w, https://ugc.futurelearn.com/uploads/assets/8a/b9/large_hero_8ab922e8-fcbf-423b-9429-03c1ae7ed82c.png 2x"/></p>
<p>Let’s create our second tree. Tree 2 uses another random subset of training examples we call <script type="math/tex">S_{r2}</script> and a random subset of features <script type="math/tex">Y_{r2}</script>to yield the following. We can see that testing with Test 1 also yields a “Yes”</p>
<p><img alt='Tree with random subset named Sr2,Yr2 on top of the Tree arrow leading straight down to a white shaped empty oval - underneath the shape  there is a blue arrow leading down to a blue oval shape. From the left of the blue oval shape there i a blue arrow leading down to an empty oval shape - underneath this shape it says the word  Yes.  Leading out from the same blue oval shape the arrow on the right points underneath an empty oval shape underneath this word  it states "No" To the left of the top of tree there is a blue line that leads to the downwards arrow pointing to an empty oval shape - leading from this shape is a blue arrow pointing to a blue oval. To the left of the blue Oval is a blue arrow pointing to an empty oval shape in the left under this empty oval shape it says the word "Yes" To the right of the blue oval there is a blue arrow pointing to another empty oval shape underneath. Under this shape is the word "No" - On top of the tree to the Right there is a RED line with a downwards arrow pointing to an empty oval shape. Leading from this shape the arrow points to a blue shaped oval. Leading out of the Left via a RED arrow it leads to an empty oval shape. Underneath this word it states "Yes"  To the right of the blue oval there is an arrow that points to an empty oval shape underneath this shape it states "No' sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/e4/35/hero_e4358658-c57d-41d8-a2ab-eb3c558ed5b8.png" srcset="https://ugc.futurelearn.com/uploads/assets/e4/35/small_hero_e4358658-c57d-41d8-a2ab-eb3c558ed5b8.png 320w, https://ugc.futurelearn.com/uploads/assets/e4/35/hero_e4358658-c57d-41d8-a2ab-eb3c558ed5b8.png 648w, https://ugc.futurelearn.com/uploads/assets/e4/35/large_hero_e4358658-c57d-41d8-a2ab-eb3c558ed5b8.png 729w, https://ugc.futurelearn.com/uploads/assets/e4/35/large_hero_e4358658-c57d-41d8-a2ab-eb3c558ed5b8.png 2x"/></p>
<p>So far so good. Let’s create our third and final tree (we said in this case we would pursue <script type="math/tex">K=3</script>).  Perhaps it looks like the following.</p>
<p><img alt='Tree with random subset named Sr3,Yr3 on top of the Tree arrow leading straight down via red arrow to a white shaped empty oval - underneath the shape there is a Red arrow leading down to a blue oval shape. From the left of the blue oval shape there is a blue arrow leading down to an empty oval shape - underneath this shape it says the word  Yes.  Leading out from the same blue oval shape the arrow on the right points underneath to an empty oval shape underneath this the word states "No" To the left of the top of tree there is a blue line that leads to the downwards arrow pointing to an empty oval shape - leading from this shape is a blue arrow pointing to a blue oval shape underneath. To the left of the blue Oval is a blue arrow pointing to an empty oval shape in the left under this empty oval shape it says the word "Yes" To the right of the blue oval there is a blue arrow pointing to another empty oval shape underneath. Under this shape is the word "No" - On top of the tree to the Right there is a BLUE line with a downwards arrow pointing to an empty oval shape. Leading from this shape the arrow which points to a blue shaped oval. Leading out of the Left via a blue arrow it leads to an empty oval shape. Underneath this word it states "Yes"  To the right of the blue oval there is an arrow that points to an empty oval shape underneath this shape it states "No' sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/6e/42/hero_6e42ce95-96b6-445b-ad2b-8bc65f9c657e.png" srcset="https://ugc.futurelearn.com/uploads/assets/6e/42/small_hero_6e42ce95-96b6-445b-ad2b-8bc65f9c657e.png 320w, https://ugc.futurelearn.com/uploads/assets/6e/42/hero_6e42ce95-96b6-445b-ad2b-8bc65f9c657e.png 648w, https://ugc.futurelearn.com/uploads/assets/6e/42/large_hero_6e42ce95-96b6-445b-ad2b-8bc65f9c657e.png 729w, https://ugc.futurelearn.com/uploads/assets/6e/42/large_hero_6e42ce95-96b6-445b-ad2b-8bc65f9c657e.png 2x"/></p>
<p>This tree like all the previous trees is slightly different in structure. We can test with example Test 1 and we have the classifier output “No”, i.e. Mary does not go for a hike.</p>
<p><strong>Step 2:</strong> So we have built our 3 trees in this case. It is time to consider what happens when we run test data points. What we do is classify Test 1 using each of the trees <script type="math/tex">T_1, ...T_k</script>. In our case we had: <br/>
Test 1, Tree 1 yielding a “Yes”<br/>
Test 1, Tree 2 yielding a “Yes”<br/>
Test 1, Tree 3 yielding a “No”</p>
<p>So what do we do? The trees do not agree. We solve this in the next substep.</p>
<p><strong>Step 3:</strong> To break the impasse we have with the outputs of our tree, we can simply use a majority vote, i.e. we go with the class that was predicted most often. In this case, the output is “Yes”</p>
<p><img alt='Subsets of Attributes and training examples. On the top of diagram is written the wording Dataset S.  There is an arrow pointing from this Heading down to the left - under this arrow is the Diagram Sr3 as noted above.  Leading from the heading Dataset S is an arrow pointing straight down the middle to the diagram Sr2 as noted above. There is an arrow pointing straight down to the Right to the Diagram Sr1 as noted above. From the bottom of subset Sr3 the where the Red arrow pointed to "No" there is an arrow that heading to a blue box stating Majority Voting.  From the middle subset known as Sr2 where the arrow points to yes oval there is an arrow leading staright to the box that says Majority voting.  Moving on to the right hand side diagram known as Sr1 - underneath where the Red arrow points to the word Yes there is a blue arrow that points to Majority Voting.  From the Heading Majority Voting there is one arrow that points to Final Class.' sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/39/97/hero_39971d67-5f56-4090-93c3-79758c7e89c9.png" srcset="https://ugc.futurelearn.com/uploads/assets/39/97/small_hero_39971d67-5f56-4090-93c3-79758c7e89c9.png 320w, https://ugc.futurelearn.com/uploads/assets/39/97/hero_39971d67-5f56-4090-93c3-79758c7e89c9.png 648w, https://ugc.futurelearn.com/uploads/assets/39/97/large_hero_39971d67-5f56-4090-93c3-79758c7e89c9.png 729w, https://ugc.futurelearn.com/uploads/assets/39/97/large_hero_39971d67-5f56-4090-93c3-79758c7e89c9.png 2x"/></p>
<p>And that is how Random forests work in their most basic form. You should know enough now to be able to understand what you are doing, should you choose to use them immediately. Interestingly Random Forest have state of the performance in many domains so you now have a very useful machine learning algorithm in your toolset.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.7&emsp;Interpretability of Trees</h2><div class="u-typography-bold-intro">
<blockquote>
<p>Interpretability is the degree to which a human can understand the cause of a decision. Interpretability is the degree to which a human can consistently predict the model’s result (Miller 2019).</p>
</blockquote>
<p>With a decision, you can trace a classification through reading the rules off the tree and it provides a concise description of what makes a classification such as “Mary goes on a hike”.</p>
<p>The higher the interpretability of a machine learning model, the easier it is for someone to comprehend why certain decisions or predictions have been made. It is not a black box model because we have a clear picture of its internal working. Since decision trees are easily interpretable, they become an important use for many industries and users.</p>
<p><img alt="Decision Tree - On the top line 50% of the line in is in blue (to the left) and 50% of the line is in the red (to the right) In the centre of the top line is an oval blue shape right in the centre with the word Temperature written in white - Under the word Temperature is an arrow pointing to a white Oval with the word warm in it.  Directly beneath this written in green is Mary hikes.  At the end of the top blue line there is an arrow pointing downwards to a white oval shape - inside this word it says Hot - beneath this a blue arrow points to the word Humidity which is in a blue oval. To the left and the right of this blue oval shape are arrows pointing out in opposite directions leading to 2 oval white shapes - the oval shape on the left says High in it and beneath this written in Red it says Mary does not hike - Under the right arrow written in the oval it says Normal. Underneath this written in Green it says Mary Hikes. At the end of the top Red line there is an arrow pointing downwards to an oval white shape, written in this word it states Cold leading from this oval shape downwards you arrive at a blue Oval with the word Wind written inside it. From this there are two arrows pointing outwards from this blue oval shape.  The RED arrow to the left points to the word Weak which is inside an oval shape. Underneath this is written Mary hike in GREEN- to the the right of the blue Oval there is a blue arrow leading to the right - under this arrow there is oval white shape which states strong.  Under this written in RED it says Mary does not hike" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/9e/d0/hero_9ed0a1c4-a7ef-45fb-a541-172e81a78905.png" srcset="https://ugc.futurelearn.com/uploads/assets/9e/d0/small_hero_9ed0a1c4-a7ef-45fb-a541-172e81a78905.png 320w, https://ugc.futurelearn.com/uploads/assets/9e/d0/hero_9ed0a1c4-a7ef-45fb-a541-172e81a78905.png 648w, https://ugc.futurelearn.com/uploads/assets/9e/d0/large_hero_9ed0a1c4-a7ef-45fb-a541-172e81a78905.png 729w, https://ugc.futurelearn.com/uploads/assets/9e/d0/large_hero_9ed0a1c4-a7ef-45fb-a541-172e81a78905.png 2x"/></p>
<p>The rule for “Mary goes for a hike” is (Temperature = Warm) OR (Temperature = Hot AND Humidity = Normal) OR (Temperature = Cold AND Wind = Weak).</p>
<h3 id="interpretability-and-explainability">Interpretability and Explainability</h3>
<p>What is useful about interpretability is it allows us to explain how the algorithm arrived at a decision. This is really important, especially now, given how often machine learning is being used to make critical decisions which affect people. Examples include screening for clinical trials, approval for loans, or even suitability for a job position. Indeed, so important is it that <a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">Explainable Artificial Intelligence (AI)</a> has become a major area of study within artificial intelligence. For an example please look at the <a href="https://www.darpa.mil/program/explainable-artificial-intelligence">US DARPA Explainable AI programme</a> which contains some useful information.</p>
<p>This is not just a technical nicety either. From a legal perspective, EU GDPR law demands that citizens have a “right to explanation”. You can learn more about this idea <a href="https://en.wikipedia.org/wiki/Right_to_explanation">here</a>.</p>
<p>This topic is well beyond the scope of this course but everyone should be aware of such matters and educate themselves accordingly. A good starting point is this fairly recent BBC News feature <a href="https://www.bbc.com/news/technology-50506431">Google tackles the black box problem with Explainable AI</a>.</p>
<p><sub><strong>Reference</strong></sub>
<sub>
Miller, Tim. (2017) ‘Explanation in artificial intelligence: Insights from the social sciences.’ arXiv Preprint arXiv:1706.07269. (2017).</sub></p>
<p><sub>Kelion, Leo. (2019) ‘Google tackles the black box problem with Explainable AI’, <em>BBC News</em>, available: https://www.bbc.com/news/technology-50506431 [accessed 9 Dec 2019]
</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.8&emsp;Extending our Trees</h2><div class="u-typography-bold-intro">
<p>In this step, we look briefly at useful features and enhancements of decision trees that you should find useful.</p>
<p>We also look at handling continuous variables, moving from classification to regression and extension, to the point where we have more than 2 classes to classify.</p>
<h3 id="continuous-attributes">Continuous Attributes</h3>
<p>How do we deal with continuous valued variables? Everything we’ve seen up to now have been categorical attributes. In our hiking example, we saw that we had an attribute called Temperature. We might have expected it to take on numerical values, i.e. <script type="math/tex">16\:C</script> or <script type="math/tex">28\:C</script> etc. Instead, we used the values of “Hot”, “Warm” and “Cold” and mapped (I did not say how) from a continuously valued variable to a categorical one. This is quite a useful way of handling the challenge of continuous attributes although it introduces the problem of how to do the mapping. For example, I think <script type="math/tex">28\:C</script> should be labelled as ”Hot” but perhaps you wouldn’t agree.</p>
<p>More generally, you might want to take as input the numerical value of Temperature and just have your tree deal with it.  However, the problem here is that you will need to split on these attributes. As an example let’s take a 2-feature version of our “Mary goes for a hike” predictor. Let’s say we measure temperature in degrees celsius and wind speed in km/h. We now have two continuous valued features – they are not categorical anymore.</p>
<p>We need to discretise our continuous attributes. How do we choose these? One idea might be to make a random choice initially. For example, in our case, lets split Wind Speed on a single threshold we will call <script type="math/tex">Speed_1</script>. We could try two thresholds for Temperature <script type="math/tex">T_1</script> and <script type="math/tex">T_2</script>. After training with a data set, our decision tree would look like this (to build this tree we would have used specific values for the thresholds).</p>
<p><img alt="Decision tree threshold" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/a0/23/hero_a023dd61-cf04-4a82-97ad-2079ae265e1f.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/a0/23/small_hero_a023dd61-cf04-4a82-97ad-2079ae265e1f.PNG 320w, https://ugc.futurelearn.com/uploads/assets/a0/23/hero_a023dd61-cf04-4a82-97ad-2079ae265e1f.PNG 648w, https://ugc.futurelearn.com/uploads/assets/a0/23/large_hero_a023dd61-cf04-4a82-97ad-2079ae265e1f.PNG 729w, https://ugc.futurelearn.com/uploads/assets/a0/23/large_hero_a023dd61-cf04-4a82-97ad-2079ae265e1f.PNG 2x"/></p>
<p>The decision boundaries described by this tree in the 2-dimensional feature space given by attributes Wind Speed, and Temp can be seen in the diagram below.</p>
<p><img alt="decision tree boundary" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/80/c6/hero_80c63243-fd89-486d-9a40-a23293eb325d.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/80/c6/small_hero_80c63243-fd89-486d-9a40-a23293eb325d.PNG 320w, https://ugc.futurelearn.com/uploads/assets/80/c6/hero_80c63243-fd89-486d-9a40-a23293eb325d.PNG 648w, https://ugc.futurelearn.com/uploads/assets/80/c6/large_hero_80c63243-fd89-486d-9a40-a23293eb325d.PNG 729w, https://ugc.futurelearn.com/uploads/assets/80/c6/large_hero_80c63243-fd89-486d-9a40-a23293eb325d.PNG 2x"/>
You can see how the feature space has been partitioned by the decision tree. 
If we look at the binary classes overlaid on this space we might get something like as follows:</p>
<p><img alt="HikeNoHike" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/37/ac/hero_37ac12e7-3b4d-4bd1-aa0c-d2ab390f5bb7.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/37/ac/small_hero_37ac12e7-3b4d-4bd1-aa0c-d2ab390f5bb7.PNG 320w, https://ugc.futurelearn.com/uploads/assets/37/ac/hero_37ac12e7-3b4d-4bd1-aa0c-d2ab390f5bb7.PNG 648w, https://ugc.futurelearn.com/uploads/assets/37/ac/large_hero_37ac12e7-3b4d-4bd1-aa0c-d2ab390f5bb7.PNG 729w, https://ugc.futurelearn.com/uploads/assets/37/ac/large_hero_37ac12e7-3b4d-4bd1-aa0c-d2ab390f5bb7.PNG 2x"/>
What do you think of that? It might suggest that maybe we could optimise or explore values of <script type="math/tex">Speed_1</script>, <script type="math/tex">T_1</script>and <script type="math/tex">T_2</script> to find the best performance, right?  This is something to explore. We might even have different thresholds in different parts of the tree just to make things extra adaptive? These are all ideas to think about, although it is beyond the scope of this course. If you would like to explore this a little further, try this research paper <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/splits.pdf">‘Efficient Determination of Dynamic Split Points in a Decision Tree’</a>.</p>
<h3 id="multiclass">Multiclass</h3>
<p>Ok, so how else can we extend things? How about if we have more than just two classes for prediction?</p>
<p>The multiclass classification decision trees predict the most frequent class in the subset. 
Consider there are <script type="math/tex">K</script> classes in a dataset <script type="math/tex">(1,2,3,....k)</script>. The goal of a multiclass classification decision tree is to learn to correctly classify <script type="math/tex">K</script> classes. The formula to calculate the entropy of multiclass classification is:<br/>
Entropy: <script type="math/tex">H(S)=-\sum_c(P_c \log_2 P_c)</script>
Where <script type="math/tex">P_c</script>=% of examples of class <script type="math/tex">c</script> in <script type="math/tex">S</script>.</p>
<h3 id="regression">Regression</h3>
<p>If we want to use a decision tree for regression, the predicted output is the average of all the training examples in the subset. The entropy calculation is not the same as in the classification problem as it requires a different definition of a mathematical concept for homogeneity or pureness of sets. We do not cover this topic in the course, but a good starting point can be found in this article, <a href="https://www.saedsayad.com/decision_tree_reg.htm">Decision Tree - Regression</a>.</p>
<p><sub><strong>References</strong></sub></p>
<p><sub>Chickering, D., Meek, C. and Rounthwaite, R. (2001) ‘Efficient determination of dynamic split points in a decision tree’ 
Chickering, D.M., Meek, C. and Rounthwaite, R., (2001) ‘Efficient determination of dynamic split points in a decision tree’. In Proceedings 2001 IEEE international conference on data mining (pp. 91-98). IEEE. </sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.9&emsp;Advantages and Disadvantages of Decision Trees</h2><div class="u-typography-bold-intro">
<p>Listed below are the advantages and disadvantages of Decision Trees.</p>
<h3 id="advantages">Advantages</h3>
<p>Decision trees have a number of advantages for machine learning.</p>
<ol>
<li>
<p>Easy - they are easy to understand and lend themselves to graphical representation.</p>
</li>
<li>
<p>Interpretable - decision trees can more easily be traced in terms of how particular data led to a particular classification.</p>
</li>
<li>
<p>Computationally good - training decision trees even with large amounts of data can be achieved with relatively modest computing power.</p>
</li>
<li>
<p>Good in a group - decision trees can be combined in ensembles or indeed with other machine learning algorithms to suit many problems and to produce high performance.</p>
</li>
<li>
<p>Flexible - decision trees can handle categorical data very well, as we have seen, but also are capable, with care, of working well with numerical data too. These can be combined, which is particularly attractive for real world machine learning problems.</p>
</li>
<li>
<p>Low overhead for data preparation - decision trees work well with data including variables that normally may require some further processing such as one-hot encoding.</p>
</li>
<li>
<p>Intuitive - decision trees approximate human decision making to some degree.</p>
</li>
<li>
<p>Tunable - overfitting and underfitting can be compensated for.</p>
</li>
<li>
<p>Any Boolean function can be approximated including the <a href="https://en.wikipedia.org/wiki/Exclusive_or">XOR</a> which can be challenging for some machine learning approaches.</p>
</li>
</ol>
<h3 id="disadvantages">Disadvantages</h3>
<ol>
<li>
<p>Sensitivity to training data - the final tree is very sensitive to the training data and noise in the data, although this can be dealt with through pruning and ensembling and other methods.</p>
</li>
<li>
<p>We cannot guarantee that a tree we have created is the optimal tree. If you would like proof, please see <a href="https://people.csail.mit.edu/rivest/HyafilRivest-ConstructingOptimalBinaryDecisionTreesIsNPComplete.pdf">Constructing Optimal Binary Decision Trees is NP-Complete</a>.</p>
</li>
<li>
<p>Prone to overfitting.</p>
</li>
<li>
<p>Axis aligned splits of data can have difficulty approximating some decision boundaries.</p>
</li>
</ol>
<p>Regarding this last point. A <a href="https://en.wikipedia.org/wiki/Decision_boundary">decision boundary</a> or decision surface is a hypersurface that partitions the underlying vector space into two sets, one for each class. The classifier will classify all the points on one side of the decision boundary as belonging to one class and all those on the other side as belonging to the other class.</p>
<p>You can visualise this decision boundary problem with decision trees in the animated GIF below. 
<img alt="regression - text states 'our feature space along with the optimal decision boundary. Our first split. DT keeps splitting to approximate the required decision boundary. Axis aligned splits require deep trees. Our feature space ..along with the optimal decision boundary. The GIF shows a series of splits in dotted and continuous lines splitting a white square with blue outline with blue and red dots scattered throughout the square." src="https://www.failteonline.ie/futurelearn/test/ca684/DecisionTree.gif"/></p>
<p><sub><strong>References</strong></sub></p>
<p><sub>
Laurent, H. and Rivest, R.L., 1976. Constructing optimal binary decision trees is NP-complete. <em>Information processing letters</em>, 5(1), pp.15-17.
<sub></sub></sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.11&emsp;Review of Topic 1</h2><div class="u-typography-bold-intro">
<p><img alt="Forest trees with full green foliage and hint of sunlight_- shutterstock_ image ID_Reference number 98506802.jpg" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/ff/39/hero_ff396104-70e7-4d04-9530-b2fdad7852c4.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/ff/39/small_hero_ff396104-70e7-4d04-9530-b2fdad7852c4.jpg 320w, https://ugc.futurelearn.com/uploads/assets/ff/39/hero_ff396104-70e7-4d04-9530-b2fdad7852c4.jpg 648w, https://ugc.futurelearn.com/uploads/assets/ff/39/large_hero_ff396104-70e7-4d04-9530-b2fdad7852c4.jpg 729w, https://ugc.futurelearn.com/uploads/assets/ff/39/large_hero_ff396104-70e7-4d04-9530-b2fdad7852c4.jpg 2x"/></p>
<p><strong>Congratulations on completing Topic 1</strong></p>
<p>We covered a lot of information. However,  it all centred around the idea of a decision tree. You should now know what a decision tree is. You should know how to take training data with a target feature and illustrate how a decision tree might be used to make predictions.</p>
<p>We focussed on decision trees for classification. However, these trees can also be used for regression (although we do not explore that in this course).</p>
<p>We also focussed on binary classification as this lent itself to the easiest pedagogical journey.  However, decision trees can work with more than binary target classes and you should be able to explore that topic further if you wish.</p>
<p>We chose the ID3 algorithm in particular as a method for creating decision trees. It is not the most powerful technique but it represented a milestone in the development of the decision tree as a machine learning algorithm. It also allowed us to explore ideas around the choice of attributes for splitting and an opportunity to get reacquainted with information theory. Who doesn’t love information theory?</p>
<p>An important point I hope you will remember is the problem of overfitting. We saw how we can understand how overfitting occurs in the context of decision trees. Decision trees allow us to very easily picture how overfitting can occur.  We will see later that overfitting occurs for all machine learning algorithms so exposure to this issue now should help you later in the programme.</p>
<p>Furthermore, we saw some ideas for handling overfitting and used this as an opportunity to learn a little about the Random Forest classifier. This is a useful classifier which you will learn more about later in the context of ensemble approaches.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p style="page-break-before: always"><h2>2.1&emsp;Welcome to Topic 2</h2><div class="u-typography-bold-intro">
<p>In this topic, we are going to take a look at the Naïve Bayes Classifier.</p>
<p>This is a great classifier to examine, as it directly applies a number of concepts from statistics. In particular, it relies heavily on, you guessed it, Bayes Theorem, one of the most useful results in statistical science.</p>
<p>The Naive Bayes Classifier has been extended and enhanced in many ways. However, an understanding of its basic principles as we will learn about this week will position you well for self-learning in this area in the future.</p>
</div><p><h2>2.2&emsp;Introduction to Probabilistic Classifiers </h2><div class="u-typography-bold-intro">
<p>As mentioned in the previous step, we are going to examine the Naive Bayes Classifier.</p>
<p>We will examine the various components of the algorithm and look at some of the statistical properties assumed, i.e independence. We will present examples of the classifier in action for both continuous and discrete attributes, before concluding with a weighing up of pros and cons for this sort of classifier. We start however with the basic principle behind the classifier which is Bayesian classification.</p>
<h3 id="probabilistic-classification">Probabilistic Classification</h3>
<p>A Naive Bayes Classifier is an example of a Bayesian Classifier which is a probabilistic classifier. The main goal of such a classifier is to determine the probability of features occurring in each class and to return the most likely class.</p>
<p>Our goal is to learn the function  <script type="math/tex">f(x) \rightarrow  y</script> where <script type="math/tex">y</script> is one of the <script type="math/tex">k</script> classes (e.g. goes for a hike/does not go for a hike, or cats versus dog, or whatever). Our set of attribute values, i.e. our feature vector <script type="math/tex">x = x_1, x_2, ...x_d</script>- values of attributes can be categorical and numerical (including a mix of predictor types so long as you calculate a conditional probability of the predictor value given the class).</p>
<p>We are talking about classification and therefore about learning a predictor function. We can build up this predictor function based on past data, which will take a set of attributes x and produce a class prediction <script type="math/tex">y</script>. It is probabilistic classification. Therefore, we are seeking to calculate the most probable class given observation of feature vector <script type="math/tex">x</script> :</p>
<script type="math/tex; mode=display">\widehat{y}= arg max_y P(y \mid x)</script>
<p>Naïve Bayes is a subtype of a general type of probabilistic classifier called a Bayes Classifier. Its main purpose is to assign classes based on the computed probability of the class. Probabilistic classifiers, unlike other machine learning classifiers, find the probability of each class first, and then choose the class with the highest probability.</p>
<p>They compute the quantity <script type="math/tex">P</script> of <script type="math/tex">y</script> given <script type="math/tex">x</script> for all classes. Therefore, a binary classifier will produce two numbers, one for each class. For example, consider the classification of email as either spam or genuine. Two numbers are produced by our probabilistic classifier. One is the probability of a given email being spam and the other is the probability that the email is genuine (ham). The classifier produces a single output by selecting the biggest number, i.e. the most probable class.</p>
<p>Our essential problem then is to calculate the probabilities of each class given an observation <script type="math/tex">x</script> (a feature vector). All Bayesian classifiers do this in one way or another through the application of Bayes Rule.</p>
<p>We will examine Bayes Rule next.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.3&emsp;Bayesian Classification</h2><div class="u-typography-bold-intro">
<p>We begin with Bayes rule.</p>
<script type="math/tex; mode=display">P(y \mid x) = \frac{P(x \mid y)P(y)}{P(x)}</script>
<p>We have structured it here to reflect our challenge of calculating probability of a class <script type="math/tex">y</script> given a feature vector <script type="math/tex">x</script>. If you need a refresher on your statistics and Bayes rule, I thoroughly recommend Andrew Moore’s notes which are still available on the Carnegie Mellon University website <a href="http://www.cs.cmu.edu/~awm/15781/slides/prob18.pdf">here</a>.</p>
<p>So, <script type="math/tex">P(y \mid x)</script> is equal to <script type="math/tex">P(x \mid y)=P(y)</script> scaled by <script type="math/tex">\frac{1}{P(x)}</script></p>
<p>Now we are going to replace <script type="math/tex">P(x)</script> with the denominator in Bayes Rule calculated as in the following equation.</p>
<script type="math/tex; mode=display">P(y \mid x) = \frac{P(x \mid y)P(y))}{\sum_{y}'P(x \mid {y}')P({y}')}</script>
<p>We are writing <script type="math/tex">P(x)</script> out in a very particular way here. We are summing up over all possible classes <script type="math/tex">y</script> and we will elaborate upon why this is useful later. Remember <script type="math/tex">P(x)</script> is the probability of the feature vector.</p>
<script type="math/tex; mode=display">P(y \mid x) = \frac{\overbrace{P(x \mid y)}^{class-model}\overbrace{P(y)}^{prior}}{\underbrace{\sum_{y}'P(x \mid {y}')P({y}')}_{normalizer}}</script>
<p>Let’s now elaborate on the various components of Bayes Rule according to the components we have named in the equation. First, we have the prior probability <script type="math/tex">P(y)</script>. This is the probability of a class independent of any knowledge about a specific <script type="math/tex">x</script>. If we were looking at a spam detector application, <script type="math/tex">P(y)</script> would be the likelihood of spam emails. If half of all emails were spam we would have <script type="math/tex">P(y)=0.5</script>.</p>
<p>Next, we have the class model, which is also called the likelihood. Given that an email is spam, how likely am I to see a particular set of words <script type="math/tex">x</script>? Similarly given that an email is genuine, how likely is that set of words <script type="math/tex">x</script>? Now let us consider the digit classification problem.  Given that the class is a “9”, how likely are we to see a pixel in the top right-hand corner and one in the bottom left-hand corner? Or if we assume the class is for the digit “5”, how likely to see a dark pixel in the centre and a light grey pixel in the bottom left-hand corner.</p>
<p>Finally the <script type="math/tex">P(y \mid x)</script> is the posterior probability.</p>
<p>Next, we look at the denominator, the expanded form of <script type="math/tex">P(x)</script>. We will deal with this in the next step.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.4&emsp;Examining the typical components of a simple Bayesian Classifier</h2><div class="u-typography-bold-intro">
<p>Let’s consider the example below to understand the components of the Bayesian Classifier.</p>
<p>Suppose you are running a hospital and you have a set of patients. A patient presents with a set of symptoms that <em>may</em> be influenza (flu). You use a Bayes classifier to determine if they have influenza or not.</p>
<h3 id="bayesian-classification-components">Bayesian classification: components</h3>
<script type="math/tex; mode=display">P(x) = \sum_{y'}P(x \mid y') P(y')</script>
<p>Where <script type="math/tex">y</script> is influenza and <script type="math/tex">x</script> is the observed symptoms of influenza.</p>
<p><script type="math/tex">y</script> is binary - it has either the value “Patient has Influenza” or “Patient does not have Influenza”. <script type="math/tex">X</script> is a set of symptoms, for example having:</p>
<ul>
<li>a headache</li>
<li>a sore throat</li>
<li>unable to move without aid</li>
<li>a cough</li>
</ul>
<p>We have three components.</p>
<p>The first of these is <script type="math/tex">P(y)</script>. A priori ,without seeing the patient, is the patient likely to have the flu or not? This is important. Let’s say it is winter. Even if you have flu-type symptoms it is unlikely you have the flu, as the common cold can have similar symptoms. The common cold is also, as the name suggests, pretty common. Relative to the common cold, the flu is relatively rare. So the prior for flu would be a fairly low number here.</p>
<p><script type="math/tex">P(x \mid y)</script> is a class conditional model which describes the likelihood of observing <script type="math/tex">x</script> for class <script type="math/tex">y</script>. For example, assuming that the person has the flu, are the symptoms exhibited by this patient plausible?</p>
<p>Now we have <script type="math/tex">P(y \mid x)</script>. This is the “flipped-around” case. Given the symptoms that we see in a patient, how likely is that they have the flu. You can intuitively perceive how this might vary depending on the variation in features of <script type="math/tex">x</script>. For example:</p>
<ul>
<li>
<p>If they only have a headache, how likely is it they have flu?</p>
</li>
<li>
<p>If they have a headache and a sore throat only, how likely is it they have a flu?</p>
</li>
<li>
<p>If they have a sore throat, a cough and a temperature but no headache, how likely is it they have a flu?</p>
</li>
</ul>
<p>Most people will have some experience of this sort of process when self-diagnosing via <a href="https://www.webmd.com/">WebMD</a>.</p>
<p><script type="math/tex">P(x)</script> is a component which normalizes probabilities across observations. It does not affect which class is most likely, because we are looking for the argument which maximises the expression which is the most probable class with a given observation <script type="math/tex">x</script>. Think about that. Given a specific set of symptoms for a specific patient, <script type="math/tex">P(x)</script> is fixed when we are looking at calculating the posterior probability <script type="math/tex">P(y \mid x)</script> for the two classes in <script type="math/tex">y</script> for that patient. This part is sometimes completely left out of Bayesian classifiers as all it does is scale the outputs for each class. In classification, because we are looking for the largest value, the absolute scale is not important. We just want to know which class in <script type="math/tex">y</script> has the largest posterior probability.</p>
<p>In this example <script type="math/tex">P(x)</script> is calculated on the set of patients you see in your hospital; e.g what proportion of your patients only have a headache (independent of whether they have a flu or anything else). <script type="math/tex">P(x)</script> can be written as follows:
<script type="math/tex">P(x) = \sum_{y'}P(x \mid y') P(y')</script></p>
<p>We will retain this form for our Naïve Bayes classifier going forward.</p>
<p>One final point to note. We could dispense with <script type="math/tex">P(x)</script> for classification, as we are only looking for the largest posterior probability in relative terms. However, if we were seeking to rank our patients for treatment then we would retain <script type="math/tex">P(x)</script>. Why? Because now the actual values of the posterior probabilities are what is required if we wish to compare patients in terms of probability of having a flu. As the patients will all likely have different <script type="math/tex">x</script> vectors, then of course <script type="math/tex">P(x)</script> likely varies across patients.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.5&emsp;Decision boundaries </h2><div class="u-typography-bold-intro">
<p>Machine learning decision boundaries are critical for classification problems, as they reflect where the algorithm switches its prediction across classes.</p>
<p>In Course 1: <strong>Introduction, Data Representation and Feature Engineering</strong>  we discussed the concept of generative versus discriminative machine learning models. If you recall our decision trees you will have noted that decision boundaries are discriminative - they are determined by the training data.</p>
<p>If you have forgotten the difference recall that:</p>
<ul>
<li>Discriminative models: These models <strong>learn the boundary</strong> between classes directly from the data.</li>
<li>Generative models: These models, on the other hand, <strong>learn the statistical distribution</strong> of the classes.</li>
</ul>
<p>The Naïve Bayes Classifier is a generative model. It produces a complete probability distribution for each class. There is a definite likelihood for any point <script type="math/tex">x</script> and this will impact how decision boundaries emerge.</p>
<p>Let’s take an example where we have two classes and a single attribute in our feature vector.</p>
<p><img alt="Two classes and a single attribute in feature vector.  Image of a graph, base line is blue with a curved grey short mountain shaped curve that goes through an adjacent shaped orange mountain shaped image. Second curve that is in orange starts at the bottom of the blue line in the centre of the grey shaped curve. The Orange shaped mountain is a lot taller and not as robust in shape as the grey shape.  A third of the way up the orange shape there is a staggered blue line that begins at the base and as soon as it reaches a point that it touches the orange it is marked with a blue dot.  As soon as the blue staggered line hits the grey curve  not too far above the base line there is a RED DOT marking this spot. Underneath the blue line at this spot is written X1 and at the end of the Base blue line on the right is written X. The Grey mountain shaped image is referred to as P(x/A) and the orange shaped image is referred to as P(x/B) - in the diagram written on the left where there is a blue dot it states 'This is the probability of a specific value of x lets called it x1 if the class was B' Where there is a red dot is written 'This is the probability of x1 if the class was A." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/88/f7/hero_88f75911-3d7a-4099-b1cc-e1a92036d5f8.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/88/f7/small_hero_88f75911-3d7a-4099-b1cc-e1a92036d5f8.PNG 320w, https://ugc.futurelearn.com/uploads/assets/88/f7/hero_88f75911-3d7a-4099-b1cc-e1a92036d5f8.PNG 648w, https://ugc.futurelearn.com/uploads/assets/88/f7/large_hero_88f75911-3d7a-4099-b1cc-e1a92036d5f8.PNG 729w, https://ugc.futurelearn.com/uploads/assets/88/f7/large_hero_88f75911-3d7a-4099-b1cc-e1a92036d5f8.PNG 2x"/></p>
<p>We have a distribution <script type="math/tex">P(x \mid A)</script> called a likelihood, which is the conditional probability of <script type="math/tex">x</script> given <script type="math/tex">A</script> which exists over all of <script type="math/tex">x</script>. We also have this likelihood for <script type="math/tex">B</script>. These overlap. This is not what you encountered with the decision tree, where there is a crisp unambiguous demarcation between classes. That demarcation line between classes is what we call a decision boundary.</p>
<p>Let us make this even clearer. We infer <script type="math/tex">P(class)</script> via <script type="math/tex">P(observation)</script> as follows:</p>
<script type="math/tex; mode=display">P(y \mid x) \propto P(x \mid y ) P(y)</script>
<p>If we assume that the prior probabilities are equal for our two classes <script type="math/tex">A</script> and <script type="math/tex">B</script> in the example, then we can say that our decision boundary would arise as follows:</p>
<p><img alt="Decision boundary vector.  Image of a graph, base line is blue with a curved grey short mountain shaped curve that goes through an adjacent shaped orange mountain shaped image. Second curve that is in orange starts at the bottom of the blue line in the centre of the grey shaped curve. The Orange shaped mountain is a lot taller and not as robust in shape as the grey shape.  A third of the way up the orange shape there is a staggered blue line that begins at the base and as soon as it reaches a point that it touches the orange it is marked with a blue dot.  As soon as the blue staggered line hits the grey curve not too far above the base line there is a RED DOT marking this spot.  There is a grey line that starts at the base of the blue that is on the left of the staggered blue line - when the grey line reaches the orange lower side of the shaped mountain there is a green dot marking the spot. Underneath the base blue line at this spot is written Xd which marks the point of the green dot. Under the same blue line adjacent to Xd is written X1  which markes the spot of the staggered blue line reaching the 2nd point of the orange shaped curved which is marked with a blue dot.  At the end of the Base blue line on the right is written X. The Grey mountain shaped image is referred to as P(x/A) and the orange shaped image is referred to as P(x/B) - in the diagram written on the left where there is a blue dot it states 'This is the probability of a specific value of x lets called it x1 if the class was B' Where there is a red dot is written 'This is the probability of x1 if the class was A. Where there is a Green dot is written 'Point of equal probability which occurs at X=Xd" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/1c/1c/hero_1c1c2c7b-4d83-4537-9a05-a37b98038ee8.png" srcset="https://ugc.futurelearn.com/uploads/assets/1c/1c/small_hero_1c1c2c7b-4d83-4537-9a05-a37b98038ee8.png 320w, https://ugc.futurelearn.com/uploads/assets/1c/1c/hero_1c1c2c7b-4d83-4537-9a05-a37b98038ee8.png 648w, https://ugc.futurelearn.com/uploads/assets/1c/1c/large_hero_1c1c2c7b-4d83-4537-9a05-a37b98038ee8.png 729w, https://ugc.futurelearn.com/uploads/assets/1c/1c/large_hero_1c1c2c7b-4d83-4537-9a05-a37b98038ee8.png 2x"/></p>
<p>For values of the attribute greater than <script type="math/tex">x_d</script> we have <script type="math/tex">P(x \mid B)>P(x \mid A)</script> and therefore the class assigned is <script type="math/tex">B</script>.</p>
<p>If this was a decision tree we would have seen a decision boundary as per the next figure.</p>
<p><img alt="Decision Tree example of Class A and Class B.  Base line is blue. Above the base line on the Left area is written Class A above this is a grey line that goes 50% along the top line.  Above the base blue line on the Right is written Class B.  Above the same line on under the Class B in the far right is written X. Above the Class B wording there is an Orange line that leads to the top right. There is a grey line that goes straight down the centre point where the grey and orange line meet at the Top. At the bottom of this line at the centre point is written Xd. Slightly to the right of the centre grey line is a red dot marked as X1 on the base Blue line." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/f3/83/hero_f3833c04-f019-4d46-a387-9d806117a84f.png" srcset="https://ugc.futurelearn.com/uploads/assets/f3/83/small_hero_f3833c04-f019-4d46-a387-9d806117a84f.png 320w, https://ugc.futurelearn.com/uploads/assets/f3/83/hero_f3833c04-f019-4d46-a387-9d806117a84f.png 648w, https://ugc.futurelearn.com/uploads/assets/f3/83/large_hero_f3833c04-f019-4d46-a387-9d806117a84f.png 729w, https://ugc.futurelearn.com/uploads/assets/f3/83/large_hero_f3833c04-f019-4d46-a387-9d806117a84f.png 2x"/></p>
<p>If we take a bird’s eye view of a 2-dimensional feature vector space, we might visualise it as below, which I hope highlights the difference between the generative and discriminative nature of the models and the resultant decision (illustrative) boundaries.</p>
<p><img alt="2-dimensional feature vector space left diagram has 11 triangles with 3 thick green lines and a very small green square going down the right hand side of the triangles separating them from 14 red oblong shaped boxes - underneath the images it states 'Discriminative'  to the right of the diagram are 11 triangles in a circular format with quite thick green lines going through them creating a circular format. To the right is a second image of the 14 rectangular shapes with blue thick lines going through forming a circular shape. Underneath this word is written Generative." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/52/20/hero_5220c3f1-38a3-448a-aafb-0bbb11e142f7.png" srcset="https://ugc.futurelearn.com/uploads/assets/52/20/small_hero_5220c3f1-38a3-448a-aafb-0bbb11e142f7.png 320w, https://ugc.futurelearn.com/uploads/assets/52/20/hero_5220c3f1-38a3-448a-aafb-0bbb11e142f7.png 648w, https://ugc.futurelearn.com/uploads/assets/52/20/large_hero_5220c3f1-38a3-448a-aafb-0bbb11e142f7.png 729w, https://ugc.futurelearn.com/uploads/assets/52/20/large_hero_5220c3f1-38a3-448a-aafb-0bbb11e142f7.png 2x"/></p>
<p>Let’s recap that again just so that we are clear, and reinforce the contrast with the decision tree model we have seen previously.</p>
<p>With our decision trees, we have discriminative models. The training data is used to construct a decision boundary which separates our classes. Classification is accomplished by taking a new observation and determining on which side of the decision boundary it resides. It is as simple as that.</p>
<p>With Naïve Bayes we have what we are calling a generative model. It is not boundary oriented from the outset. What it tries to do is compute a posterior probability distribution. Consequently, predictions are computed by modelling each class according to the data. When a new observation comes in a Naïve Bayes classifier will ask which class is more likely to have produced a feature vector which looks like that.</p>
<h3 id="decision-boundary-geometry">Decision Boundary Geometry</h3>
<p>So the decision boundaries with a NB are generally parabolic. However in the case where we have the same variances, but obviously different means our decision boundaries are hyperplanes. If the variances differ, we have elliptical decision boundaries. The figure below again contrasts this situation with boundaries that would arise with a decision tree for the same data.</p>
<p><img alt="Boundaries diagram. In the first diagram we have a horizontal and vertical line in blue. The Vertical line points upwards and is named Feature 1 the Horizontal line is named Feature 2.  Between both lines there are 12 black dots placed.  Above the outer most Black dot there is a smaller Green Horizontal and vertical diagram with 4 red dots placed inside.  The wording decision tree  appears between bottom vertical lines. To the Right of this is a second diagram with a Blue vertical and horizontal lines. The vertical line pointing upwards is called Feature 1 and the Horizontal line pointing to the right is called Feature 2.  In the diagram there are 12 black dots sporadically positioned with large grey circular lines covering them.  This merges with Red Circular lines which are covering the area with 4 red dots in.  The Red circles and Grey circles interlink at a stage whereby 1 red dot and 2 black dots both appear in the grey and red circles. Between the two black dots and the red dot in these merged circles is a blue curved line. Between the left blue Horizontal line and the blue curved line is states Naive Bayes" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/de/52/hero_de520097-dcdf-4458-b230-f735f79d0f37.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/de/52/small_hero_de520097-dcdf-4458-b230-f735f79d0f37.PNG 320w, https://ugc.futurelearn.com/uploads/assets/de/52/hero_de520097-dcdf-4458-b230-f735f79d0f37.PNG 648w, https://ugc.futurelearn.com/uploads/assets/de/52/large_hero_de520097-dcdf-4458-b230-f735f79d0f37.PNG 729w, https://ugc.futurelearn.com/uploads/assets/de/52/large_hero_de520097-dcdf-4458-b230-f735f79d0f37.PNG 2x"/></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.6&emsp;The Independence Assumption</h2><div class="u-typography-bold-intro">
<p>By now you should be comfortable with the basic idea that Bayes rule could potentially be useful in building a classifier.</p>
<p>In other words, we can infer <script type="math/tex">P(class)</script> via <script type="math/tex">P(observation)</script> through</p>
<script type="math/tex; mode=display">P(class \mid observation) \propto P(observation \mid class ) P(class)</script>
<p>However, calculating <script type="math/tex">P(observation \mid class)</script> can be challenging, as we rarely have sufficient data to estimate such a distribution for real-world machine learning problems. 
Let’s explore this issue. To repeat, a key component of our Bayes rule application is the calculation of the likelihood, i.e. <script type="math/tex">P(x|y)</script>, i.e. we must compute 
Compute  <script type="math/tex">P(x_1, x_2...x_d {\left | y \right )}</script> for every observation <script type="math/tex">x_1,...x_d</script></p>
<p>These are class-conditional ”counts” based on training data. The problem here lies in how we calculate these probabilities. We do this by counting the number of times each possible <script type="math/tex">x</script> comes up for each class <script type="math/tex">y</script>. Let’s examine this with a classic classification problem which is our handwritten digit recognition using the MNIST dataset. You can read a little about that problem here - <a href="http://yann.lecun.com/exdb/mnist/">MNIST database of handwritten digits</a>.</p>
<p>Below is a sample digit from MNIST. For our digit recognition task, these bitmaps represent our <script type="math/tex">x</script>. In this example, our bitmaps are 20 pixels by 20 pixels. Each pixel is in a grayscale byte image representation in which each pixel value is in the range 0-255, where 0 represents black and 255 represents white.</p>
<p><img alt="small squared blue graph with the figure 8 written in black" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/e3/b8/hero_e3b8b0a2-0d7d-4aa6-a681-71b5d357dd3b.png" srcset="https://ugc.futurelearn.com/uploads/assets/e3/b8/small_hero_e3b8b0a2-0d7d-4aa6-a681-71b5d357dd3b.png 320w, https://ugc.futurelearn.com/uploads/assets/e3/b8/hero_e3b8b0a2-0d7d-4aa6-a681-71b5d357dd3b.png 648w, https://ugc.futurelearn.com/uploads/assets/e3/b8/large_hero_e3b8b0a2-0d7d-4aa6-a681-71b5d357dd3b.png 729w, https://ugc.futurelearn.com/uploads/assets/e3/b8/large_hero_e3b8b0a2-0d7d-4aa6-a681-71b5d357dd3b.png 2x"/></p>
<p>For this 20 x 20 bitmap, we have 400 variables, each of which can take on a value between 0 and 255. In order to calculate the probability of <script type="math/tex">x</script> given <script type="math/tex">y</script> we need to do this across all the permutations of the components of <script type="math/tex">x</script>.</p>
<p>That’s right. All 400 variables, each of which can take on 256 different values! For all the different classes!</p>
<p>We need to estimate this for every permutation of <script type="math/tex">x</script>, given that the class of interest is 8 or the class is 5 and so on. The obvious problem here is that we are unlikely to see every <script type="math/tex">x_1,...x_d</script> for every <script type="math/tex">y</script>.
For our digits, we might have <script type="math/tex">256^{400}</script> possible patterns. Even if we simplified our pixels values to binary, i.e. black or white pixels, we still have <script type="math/tex">2^{400}</script> possible patterns.</p>
<p>As we have to estimate these distributions through instance counting over our training set we are highly unlikely to see any repetitions of many pixel configurations. So you will never get the data. Therefore, you can never possibly arrive at these likelihood estimates by counting them.</p>
<p>The solution to this problem is to invoke independence of the feature component random variables. This is where the “naïve” in the Naïve Bayes Classifier comes from – it is naïve because it does not consider any dependence which is likely to exist between the attributes.  This sounds like a bad idea, given that surely this can’t be true, i.e. surely knowing the value of one attribute for a given class tells you something about some other attribute for that class.</p>
<p>Suppose, for example, we develop a fruit classifier based on images and we use a “bag of features” representation based on attributes such as colour, shape and size. For a fruit such as a banana we don’t expect attributes such as colour and shape to be uncorrelated, i.e “yellow” and “round” are no more surprising than “yellow” and “elongated”.</p>
<p>However, the benefit of this invoking of independence is we now only need to look at the likelihood of each attribute in isolation for each class. Let’s see why this is so.</p>
<p>We will assume <script type="math/tex">x_1, ...x_d</script>is conditionally independent given <script type="math/tex">y</script>. By conditional independent, we mean independent given that we are examining a specific class <script type="math/tex">y</script>.</p>
<script type="math/tex; mode=display">P(x_1, ...x_d \mid y) = \underbrace{\prod_{i=1}^ { d} P(x_i \mid x_1 ...x_{i-1}, y)}_{chain \:rule}</script>
<p>That is the impossible part for our MNIST digit dataset. Let’s consider this.  We have expressed the required likelihood in terms of its factors of marginal probabilities via the chain rule. What are these marginal probabilities?</p>
<p>For each pixel, beginning with pixel #1 we are asking what are the chances of this pixel:</p>
<ul>
<li>Having grayscale value 128 for the class 8</li>
<li>Given that pixel #2 has the grayscale value 23</li>
<li>While pixel #3 has the grayscale value 145 etc, etc</li>
</ul>
<p>An impossible practical task!</p>
<p>However, once we embrace the assumption of independence then we can say:</p>
<script type="math/tex; mode=display">P(x_1, ...x_d \mid y) = \underbrace{\prod_{i=1}^ { d} P(x_i \mid x_1 ...x_{i-1}, y)}_{chain \: rule} = \underbrace{\prod _{i=1}^ d P(x_i \mid y)}_{independence}</script>
<p>This last term is a lot less onerous to calculate. 
We will now assume that pixel <script type="math/tex">(i)</script> is independent of all the other pixels for that class.</p>
<p>This is a much better situation as we can now simply look at pixel 1, for example, and ask how many times was it black and how many times was it white for class “8”. I can do it again for class “3” and so on.</p>
<p>Using such an approach we have a practical calculation which will enable us to apply Bayes rule to develop an actual algorithm. This is the Naïve Bayes classifier and we will look at two examples over the next few steps although not before taking a closer look at conditional independence.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.7&emsp;Conditional Independence</h2><div class="u-typography-bold-intro">
<p>Naïve Bayes uses the idea of conditional independence which allows us to do a very convenient factorization of the likelihood.</p>
<p>Conditional independence in this context means that given a class, the attributes of the feature vector are considered independent.</p>
<p>Let’s look at a basic example of this idea. Consider the probability of catching a cold <script type="math/tex">P(C)</script> and the probability of the occurrence of cold weather <script type="math/tex">P(CW)</script>. The probability of cold weather and catching a cold are not independent, i.e. <script type="math/tex">P(CW,C)>P(CW)P(C)</script>. In other words, the probability of it being cold and you catching a cold is greater than the likelihood of each happening just by coincidence.</p>
<p>However, these may be independent if we know that the person is spending more time indoors. i.e. <script type="math/tex">P(CW,C\mid I)=P(CW\mid I)P(C\mid I)</script>. Spending more time indoors ”explains” the dependence between cold weather and catching a cold. In other words, knowing that a person is spending a lot of time indoors gives us information that perhaps it is cold outside and that chance of catching a virus increases (e.g. less air circulation and closer proximity to other people etc).</p>
<p>Conditional independence states that maybe there is an external factor that is influencing both cold weather and catching a cold. It’s not C or CW but some other factor behind the scene. i.e. its presence increases the probability that there is cold weather and catching a cold. If we condition on this factor, then perhaps the events could be independent. This factor could be “spending more time indoors”.</p>
<p>By conditioning with this factor, we realise that the weather being cold does not cause a person to catch a cold. It is spending more time inside which explains it. Similarly, it is not catching a cold that explains cold weather! It is the “spending more time indoors” that explains both.</p>
<p>By themselves the cold weather and catching a cold are not related – we can catch a cold even when there is no cold weather. However, people don’t generally catch a cold unless they are spending more time indoors, usually in close proximity with other people. When you spend more time indoors there is more to be cold weather and you are more likely to catch a cold.</p>
<p>It is this hidden factor (“spending more time indoors”) that affects you catching a cold and the weather being cold. This is what correlates them. This is what is behind conditional independence. It is saying that, behind the scenes, there is this factor which explains the attribute relationships. Within this  “spending more time indoors” condition, the events are more independent.</p>
<p><img alt="Feature vector.  Circular/Oval blue rimmed shape with the wording 'Spending more time indoors' inside the shape. 3 arrows pointing out of the shape to 3 separate oval shapes.  The 1st oval shape has the wording 'Cold Weather' written inside the 2nd oval shape has the wording 'catching cold' written inside the shape and the final shape has 'Drop in Fitness level' written inside." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/83/60/hero_8360a7a3-24d1-44ba-85de-b8e4f6994a7f.png" srcset="https://ugc.futurelearn.com/uploads/assets/83/60/small_hero_8360a7a3-24d1-44ba-85de-b8e4f6994a7f.png 320w, https://ugc.futurelearn.com/uploads/assets/83/60/hero_8360a7a3-24d1-44ba-85de-b8e4f6994a7f.png 648w, https://ugc.futurelearn.com/uploads/assets/83/60/large_hero_8360a7a3-24d1-44ba-85de-b8e4f6994a7f.png 729w, https://ugc.futurelearn.com/uploads/assets/83/60/large_hero_8360a7a3-24d1-44ba-85de-b8e4f6994a7f.png 2x"/></p>
<p>In classification, Class value explains all the dependence – that is our assumption. So we are saying that any kind of independence between the attributes is explained by the class. The class is the equivalent of our “spending more time indoors”.</p>
<p><img alt="Blue small squared graph with with figure 8 in black writing inside. To the right of this image is a 2nd image of an Oval shape with the wording Digit is &quot;8&quot; inside the shape.  Leading from the shape there are 3 arrows pointing to 3 separate Oval shapes to the right.  In each oval there is black writing separately.  The first oval states 'Pixel x1 is black, the second oval shape states 'Pixel xi is black' and the 3rd oval shape states 'pixel xd is black'" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/35/6f/hero_356f9c83-4bd5-4441-9f75-d248b8d6f416.png" srcset="https://ugc.futurelearn.com/uploads/assets/35/6f/small_hero_356f9c83-4bd5-4441-9f75-d248b8d6f416.png 320w, https://ugc.futurelearn.com/uploads/assets/35/6f/hero_356f9c83-4bd5-4441-9f75-d248b8d6f416.png 648w, https://ugc.futurelearn.com/uploads/assets/35/6f/large_hero_356f9c83-4bd5-4441-9f75-d248b8d6f416.png 729w, https://ugc.futurelearn.com/uploads/assets/35/6f/large_hero_356f9c83-4bd5-4441-9f75-d248b8d6f416.png 2x"/></p>
<p>Here, the digit “8” explains the correlations between the pixels of the image and therefore we are left with conditional independence. If you know this is digit “8” then you can say (or at least get away with saying) that the pixels are uncorrelated because it is the digit “8” which explains the dependencies within the bitmap and puts pixels in certain places.</p>
<p>This is important in Naïve Bayes, as we have this idea of conditional independence related to the class, which we use to estimate likelihood made easier through counting occurrences. Armed with a better understanding of that assumption, we can move on to look at some real examples.</p>
<p>If this step has left you with some questions, the Wikipedia article on this topic is useful - <a href="https://en.wikipedia.org/wiki/Conditional_independence">Conditional Independence</a>. You may also enjoy the material in the following video, which is excellent.</p>
<p></p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<sub>Source: <a href="https://www.youtube.com/user/MIT">MIT OpenCourseWare</a></sub>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.8&emsp;Continuous Example</h2><div class="u-typography-bold-intro">
<p>Let’s consider the following example:</p>
<p>We are going to use a Naïve Bayes Classifier to distinguish cats from dogs based on the two image-based features we used in MOOC 1 when looking at clustering.</p>
<p>We have our fictional features <script type="math/tex">f_1</script> and <script type="math/tex">f_2</script> which picked out ear morphology and facial geometry for example. So we have two classes as follows:</p>
<ul>
<li>
<p>Classes: <script type="math/tex">{d, c}</script>, attributes: <script type="math/tex">f_1</script>, <script type="math/tex">f_2</script></p>
</li>
<li>
<p>Training examples: <script type="math/tex">{f_1^i, f_2^i, y^i}</script>, 4 dogs, 12 cats</p>
</li>
</ul>
<p>The first task to estimate is the prior Class probabilities: <script type="math/tex">P(d)=4/(4+12)=0.25;P(c)=0.75</script><br/>
Let’s assume that we have only dogs. What is the model for the distribution of <script type="math/tex">f_1</script> and <script type="math/tex">f_2</script> given we have dogs? Let us go with <script type="math/tex">f_1</script> and <script type="math/tex">f_2</script> as real numbers and they are continuous numerical variables.</p>
<p>We could then assume a continuous distribution and therefore <script type="math/tex">f_1</script> and <script type="math/tex">f_2</script> could be taken as arising from a Gaussian distribution. This means if we have the mean and variance then we have completely described the Gaussian distribution and can get the probability for any <script type="math/tex">f_1</script> and <script type="math/tex">f_2</script>.</p>
<h3 id="model-for-dogs">Model for dogs</h3>
<p><script type="math/tex">f_1</script> is a Gaussian variable with mean and variance estimated as:</p>
<p>Mean :<script type="math/tex">\mu_{f_1,d}= \frac{1}{4}\sum_{i:y_i = d}f_1^i</script></p>
<p>Variance : <script type="math/tex">\mu_{f_1,d}= \frac{1}{4}\sum_{i:y_i = a}(f_1^i-\mu_{f_1,d})^2</script></p>
<p><script type="math/tex">f_2</script>  is also a Gaussian variable with (<script type="math/tex">\mu_{f_2,d} , \sigma^2_{f_2,d}</script>)</p>
<p>Let’s assume that the features <script type="math/tex">f_1</script> and <script type="math/tex">f_2</script> are independent.</p>
<h3 id="model-for-cats">Model for cats</h3>
<p>The <script type="math/tex">f_1</script> and <script type="math/tex">f_2</script> variables are the same but are labelled as (<script type="math/tex">\mu_{f_1,c} , \sigma^2_{f_1,c}</script>) and (<script type="math/tex">\mu_{f_2,c} , \sigma^2_{f_2,c}</script>)</p>
<p>The graph below shows the distribution of the model attributes (<script type="math/tex">f_1</script>, <script type="math/tex">f_2</script>) for dogs and cats.</p>
<p><img alt="Graph showing the distribution of the model attributes ($$f_1$$, $$f_2$$) for dogs and cats - Blue arrow pointing straight up with a sequence of black dots on the line in the format one black dot, two black dots side by side a space then 2 black dots side by side then 3 black dots side by side then  a space then 2 black dots side by side then 1 black dot and underneath a further one back dot on the straight blue line.  To the right of this is a  Vertical blue line with an arrow pointing upwards labelled $$f_1$$ and an arrow to the right pointing Horizontally labelled $$f_2$$. Inside this area placed sporadically are 12 black dots and 4 red dots. The red dots appear farthest away from the meeting point of the horizontal and vertical meeting point. Underneath  the horizontal line is a blue straight line on the blue line black dots appear in the following manner: One black dot space one black dot space one black dot space. 2 black dots on top of each other 2 spaces  one black dot space. then a final black dot. Underneath the blue line is an equation known as (uf2,c102f2,C)" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/2c/bc/hero_2cbcc604-c477-4734-a352-7aa62b03e2b8.png" srcset="https://ugc.futurelearn.com/uploads/assets/2c/bc/small_hero_2cbcc604-c477-4734-a352-7aa62b03e2b8.png 320w, https://ugc.futurelearn.com/uploads/assets/2c/bc/hero_2cbcc604-c477-4734-a352-7aa62b03e2b8.png 648w, https://ugc.futurelearn.com/uploads/assets/2c/bc/large_hero_2cbcc604-c477-4734-a352-7aa62b03e2b8.png 729w, https://ugc.futurelearn.com/uploads/assets/2c/bc/large_hero_2cbcc604-c477-4734-a352-7aa62b03e2b8.png 2x"/></p>
<p>Here we are just looking at the cats. The black dots and projecting these onto the axes.</p>
<p>Those are the histograms. So now once we calculate the mean and variance we have our distributions as follows:</p>
<p><img alt="Graph showing the distribution of the model attributes ($$f_1$$, $$f_2$$) for dogs and cats - Blue arrow pointing straight up with a sequence of black dots on the line. Behind these black dots is a raised blue mountain shape with the peak appearing on the right hand side. Each of the black dots appear in the blue raised mountain shape. The equation is referred to as u,F1,d,02F1,d. The format appears as one black dot, two black dots side by side a space then 2 black dots side by side. Underneath this set of dots there is a staggered blue line that starts slightly before the Vertical blue line and goes right across into the centre of the adjacent graph that I will go into further detail farther on. Under this staggered line side by side are 3 black dots then 2 black dots side by side then 1 black dot and underneath a further one back dot on the straight blue line.  To the right of this is a graph with a Vertical blue line that has an arrow pointing upwards labelled $$f_1$$ and an arrow to the right pointing horizontally labelled $$f_2$$. Inside this area placed sporadically are 12 black dots and 4 red dots. The red dots appear farthest away from the meeting point of the horizontal and vertical meeting points. Underneath  the horizontal line is a second blue straight line . Behind this line is a blue mountain shape. On the blue line black dots appear in the following manner: One black dot space one black dot space one black dot space 2 spaces 2 black dots on top of each other 2 spaces 3 black dots on top of each other. Immediately before the 3 black dots there is a staggered line that starts beneath the base line and goes straight up into the middle of the main graph until it reaches the staggered meeting line point that was created by the equation known as u,F1,d,02F1,d. After the aforementioned 3 black dots there is a  space the 2 black dots on top of each other, then 2 two spaces before another single black dot another space and one final last black dot on the line . Underneath the blue line is an equation known as (uf2,c102f2,C)" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/d2/f4/hero_d2f4cf3e-c11b-4eb7-a6ed-afe789f2c069.png" srcset="https://ugc.futurelearn.com/uploads/assets/d2/f4/small_hero_d2f4cf3e-c11b-4eb7-a6ed-afe789f2c069.png 320w, https://ugc.futurelearn.com/uploads/assets/d2/f4/hero_d2f4cf3e-c11b-4eb7-a6ed-afe789f2c069.png 648w, https://ugc.futurelearn.com/uploads/assets/d2/f4/large_hero_d2f4cf3e-c11b-4eb7-a6ed-afe789f2c069.png 729w, https://ugc.futurelearn.com/uploads/assets/d2/f4/large_hero_d2f4cf3e-c11b-4eb7-a6ed-afe789f2c069.png 2x"/></p>
<p>These are independent, so we can multiply them together to yield a big bump on our plane as follows:</p>
<p><img alt="Graph showing the distribution of the model attributes ($$f_1$$, $$f_2$$) for dogs and cats - Blue arrow pointing straight up with a sequence of black dots on the line. Behind these black dots is a raised blue mountain shape with the peak appearing on the right hand side. Each of the black dots appear in the blue raised mountain shape. The equation is referred to as u,F1,d,02F1,d. The format appears as one black dot, two black dots side by side a space then 2 black dots side by side. Underneath this set of dots there is a staggered blue line that starts slightly before the Vertical blue line and goes right across into the centre of the adjacent graph that I will go into further detail farther on. Under this staggered line side by side are 3 black dots then 2 black dots side by side then 1 black dot and underneath a further one back dot on the straight blue line.  To the right of this is a graph with a Vertical blue line that has an arrow pointing upwards labelled $$f_1$$ and an arrow to the right pointing horizontally labelled $$f_2$$. Inside this area placed sporadically are 12 black dots and 4 red dots. The red dots appear farthest away from the meeting point of the horizontal and vertical meeting points. In this diagram there are large grey circles which go around 11 of the black dots and 3 of the red dots. Underneath  the horizontal line is a second blue straight line . Behind this line is a blue mountain shape. On the blue line black dots appear in the following manner: One black dot space one black dot space one black dot space 2 spaces 2 black dots on top of each other 2 spaces 3 black dots on top of each other. Immediately before the 3 black dots there is a staggered line that starts beneath the base line and goes straight up into the middle of the main graph until it reaches the staggered meeting line point that was created by the equation known as u,F1,d,02F1,d. After the aforementioned 3 black dots there is a space the 2 black dots on top of each other, then 2 two spaces before another single black dot then another space before one final last black dot on the line . Underneath the blue line is an equation known as (uf2,c102f2,C)" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/4c/67/hero_4c67b3f1-3609-477c-a01a-77744cdd1fa9.png" srcset="https://ugc.futurelearn.com/uploads/assets/4c/67/small_hero_4c67b3f1-3609-477c-a01a-77744cdd1fa9.png 320w, https://ugc.futurelearn.com/uploads/assets/4c/67/hero_4c67b3f1-3609-477c-a01a-77744cdd1fa9.png 648w, https://ugc.futurelearn.com/uploads/assets/4c/67/large_hero_4c67b3f1-3609-477c-a01a-77744cdd1fa9.png 729w, https://ugc.futurelearn.com/uploads/assets/4c/67/large_hero_4c67b3f1-3609-477c-a01a-77744cdd1fa9.png 2x"/></p>
<p>We do the same for the dogs to get:</p>
<p><img alt="Graph showing the distribution of the model attributes ($$f_1$$, $$f_2$$) for dogs and cats - Blue arrow pointing straight up with a sequence of black dots on the line. Behind these black dots is a raised blue mountain shape with the peak appearing on the right hand side. Each of the black dots appear in the blue raised mountain shape. The equation is referred to as u,F1,d,02F1,d. The format appears as one black dot, two black dots side by side a space then 2 black dots side by side. Underneath this set of dots there is a staggered blue line that starts slightly before the Vertical blue line and goes right across into the centre of the adjacent graph that I will go into further detail farther on. Under this staggered line side by side are 3 black dots then 2 black dots side by side then 1 black dot and underneath a further one back dot on the straight blue line.  To the right of this is a graph with a vertical blue line that has an arrow pointing upwards labelled $$f_1$$ and an arrow to the right pointing horizontally labelled $$f_2$$. Inside this area placed sporadically are 12 black dots and 4 red dots. The red dots appear farthest away from the meeting point of the horizontal and vertical meeting points. In this diagram there are 6 large grey circles which go around 11 of the black dots and 3 of the red dots.  Between the inner grey circles of 2 and 3 six large red circles are also formed. Two black dots appear in both grey and the red circles and one red dot appears in both the grey and red circles.  4 Red dots appear in the Red circles in total.  Underneath the horizontal line is a second blue straight line . Behind this line is a blue mountain shape. On the blue line black dots appear in the following manner: One black dot space one black dot space one black dot space 2 spaces 2 black dots on top of each other 2 spaces 3 black dots on top of each other. Immediately before the 3 black dots there is a staggered line that starts beneath the base line and goes straight up into the middle of the main graph until it reaches the staggered meeting line point that was created by the equation known as u,F1,d,02F1,d. After the aforementioned 3 black dots there is a space the 2 black dots on top of each other, then 2 two spaces before another single black dot then another space before one final last black dot on the line.  Underneath the blue line is an equation known as " sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/7e/11/hero_7e112ed4-f693-4308-a327-2550d8b68b3c.png" srcset="https://ugc.futurelearn.com/uploads/assets/7e/11/small_hero_7e112ed4-f693-4308-a327-2550d8b68b3c.png 320w, https://ugc.futurelearn.com/uploads/assets/7e/11/hero_7e112ed4-f693-4308-a327-2550d8b68b3c.png 648w, https://ugc.futurelearn.com/uploads/assets/7e/11/large_hero_7e112ed4-f693-4308-a327-2550d8b68b3c.png 729w, https://ugc.futurelearn.com/uploads/assets/7e/11/large_hero_7e112ed4-f693-4308-a327-2550d8b68b3c.png 2x"/></p>
<p>Now we can see the distributions and the likelihood of the classes captured in a statistical distribution. This is the model.</p>
<p>If we get a new observation, for example, the x as shown in the figure below, which class is this best suited to? Where is it more likely to have come from? 
Is it more likely to come from the model of dogs or the model of cats?
We want to predict which, based on these two models.</p>
<script type="math/tex; mode=display">p(f_1^x \mid c) = \frac{1}{{\sqrt{2\pi\sigma^2_{ f_1,c}}}}exp(\frac{-1}{2})(\frac{( f_1^x-\mu_{ f_1,c})^2}{\sigma^2_{ f_1,c}})</script>
<script type="math/tex; mode=display">p(f_2^x \mid c) = \frac{1}{{\sqrt{2\pi \sigma^2_{ f_2,c}}}}exp(-\frac{1}{2})(\frac{( f_2^x-\mu_{ f_2,c})^2}{\sigma^2_{ f_2,c}})</script>
<script type="math/tex; mode=display">p(f_1^x \mid d) = \frac{1}{{\sqrt{2\pi \sigma^2_{f_1,d}}}}exp(-\frac{1}{2})(\frac{(f_1^x-\mu_{f_1,d})^2}{\sigma^2_{f_1,d}})</script>
<script type="math/tex; mode=display">p(f_2^x \mid d) = \frac{1}{{\sqrt{2\pi \sigma^2_{ f_2,d}}}}exp(-\frac{1}{2})(\frac{( f_2^x-\mu_{ f_2,d})^2}{\sigma^2_{ f_2,d}})</script>
<script type="math/tex; mode=display">P(x \mid d)=p(f_1^x \mid d)p(f_2^x \mid d)</script>
<p>And</p>
<script type="math/tex; mode=display">P(x \mid c)=p(f_1^x \mid c)p(f_2^x \mid c)</script>
<p>For this new <script type="math/tex">x</script> we just plug in the features <script type="math/tex">f_1</script> and <script type="math/tex">f_2</script> in the equations above and use these components to calculate the posterior probabilities. Note the probability of these observations being multiplied together for <script type="math/tex">P(x \mid d)</script> and <script type="math/tex">P(x \mid c)</script>. This is the Naïve part of the classifier. 
Now we combine everything to yield:</p>
<script type="math/tex; mode=display">P(d \mid x) = \frac{P(x \mid d)(P(d)}{P(x \mid d)(P(d)) + P(x \mid c) P(c)}</script>
<p>And similarly for <script type="math/tex">P(c \mid x)</script>. 
We then simply look for the largest value.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.9&emsp;Spam example</h2><div class="u-typography-bold-intro">
<p>Having looked at a continuous example, let us see how Naïve Bayes works with discrete variables.</p>
<p>We consider the example of a spam detector for email. Below is our training data which is labelled – so this is supervised learning.</p>
<h3 id="separate-spam-from-valid-email-attributes--words">Separate spam from valid email, attributes = words</h3>
<table>
<tbody>
<tr>
<td>D1</td>
<td>“send us your password”</td>
<td>spam</td>
</tr>
<tr>
<td>D2</td>
<td>“send us your review”</td>
<td>ham</td>
</tr>
<tr>
<td>D3</td>
<td>“review your password”</td>
<td>ham</td>
</tr>
<tr>
<td>D4</td>
<td>“review us”</td>
<td>spam</td>
</tr>
<tr>
<td>D5</td>
<td>“send us your password”</td>
<td>spam</td>
</tr>
<tr>
<td>D6</td>
<td>“send us your account”</td>
<td>spam</td>
</tr>
</tbody>
</table>
<p>So we want to know if an email is spam or not. 
The first thing we do is calculate the priors.</p>
<p>P(spam) = 4/6  P(ham) = 2/6</p>
<p>The next thing you do is a vocabulary. You list all the words and count every time they are in spam or ham.</p>
<p>So that’s all the estimation you need for NB.</p>
<p><img alt="Table with 3 colums with the Headings Spam - Ham -  and no heading in the 3rd column. Under the Column Spam the following appears from top to bottom: 2/4, 1/4,  3/4,  3/4, 3/4, 1/4 - Under the column Ham the following appears from top to bottom: 1/2, 2/2,1/2, 1/2, 1/2, 0/2 - Under the 3rd Column the following appears : Password, Review, Send, Us, Your, and Account" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/70/cf/hero_70cf80dc-ca07-4228-a07e-4e8e8b3459e0.png" srcset="https://ugc.futurelearn.com/uploads/assets/70/cf/small_hero_70cf80dc-ca07-4228-a07e-4e8e8b3459e0.png 320w, https://ugc.futurelearn.com/uploads/assets/70/cf/hero_70cf80dc-ca07-4228-a07e-4e8e8b3459e0.png 648w, https://ugc.futurelearn.com/uploads/assets/70/cf/large_hero_70cf80dc-ca07-4228-a07e-4e8e8b3459e0.png 729w, https://ugc.futurelearn.com/uploads/assets/70/cf/large_hero_70cf80dc-ca07-4228-a07e-4e8e8b3459e0.png 2x"/></p>
<p>These are the estimations we require for Naive Bayes implementation. Let’s try classification.</p>
<p>We consider a new email. This new email is “review us <strong>now</strong>”</p>
<p>Now we have a new email we want to know if it is spam or not. It also has a new word. We have not seen that word before so what we do is throw it away as we have never seen it before.  So that email gets concatenated to just “review us”.</p>
<p>Now we calculate.</p>
<p><script type="math/tex">P(review-us) \mid spam) = P(0,1,0,1,0,0, \mid spam) = 1-\frac{2}{4}(\frac{1}{4})(1-\frac{3}{4})(\frac{3}{4})(1-\frac{3}{4})(1-\frac{1}{4}) = 0.0044</script><br/>
<br/>
<script type="math/tex">P(review-us) \mid ham) = P(0,1,0,1,0,0, \mid ham) = 1-\frac{1}{2}(\frac{2}{2})(1-\frac{1}{2})(\frac{1}{2})(1-\frac{1}{2})(1-\frac{0}{2}) = 0.0625</script><br/>
<br/>
<script type="math/tex">P(ham \mid review-us)=\frac{0.0625 * \frac{2}{6}}{0.0625 *\frac{2}{6}+ 0.0044 * \frac{4}{6}} = 0.87</script><br/>
<br/>
Ta-da! We have predicted that this email is a genuine email. And this is how Naïve Bayes operates in the discrete case.</p>
<p>If you would like to look at some more detailed examples, take a look at <a href="https://www.machinelearningplus.com/predictive-modeling/how-naive-bayes-algorithm-works-with-example-and-full-code/">How Naive Bayes Algorithm Works?</a>
(with example and full code).</p>
<p><sub><strong>References</strong></sub></p>
<p><sub>Machine Learning Plus (2019), <em>How Naive Bayes Algorithm Works? (with example and full code)</em>, available: https://www.machinelearningplus.com/predictive-modeling/how-naive-bayes-algorithm-works-with-example-and-full-code/ [accessed 16 Dec 2019].</sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.10&emsp;Naive Bayes: Pros and Cons</h2><div class="u-typography-bold-intro">
<p>Now we know what a Naive Bayes Classifier is, should we use it for everything?</p>
<ul>
<li>What are the downsides?</li>
<li>What are the upsides?</li>
</ul>
<p>Let’s take a quick look.</p>
<h3 id="advantages">Advantages</h3>
<p>The Naive Bayes Classifier is:</p>
<ul>
<li>Quick to train.</li>
<li>Quick to predict.</li>
<li>The prediction is probabilistic, so this gives a measure of confidence in the output.</li>
<li>Pretty interpretable as you can see how the posterior is compiled.</li>
<li>Minimal in terms of parameters requiring tuning.</li>
</ul>
<h3 id="disadvantages">Disadvantages</h3>
<p>The Naive Bayes makes some very restrictive claims about our data. Consequently, they will generally not perform as well as a more complicated model.</p>
<h3 id="summary">Summary</h3>
<p>A Naive Bayesian classifier is always a good decision for a first approach to a machine learning problem and can provide a baseline for subsequent comparison with later approaches that you adopt. If it does happen to perform well, then good for you. Fast, interpretable and robust to missing data it is a good choice in that case. Generally, they work well for very high dimensional data, such as with text.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.12&emsp;Review of Topic 2</h2><div class="u-typography-bold-intro">
<p>In this topic, you learnt about Bayes rule.</p>
<p>You also learnt how such an important statistical theorem could be harnessed and applied to feature vectors to produce a classifier which in many cases is capable of great performance, despite the very severe assumptions it relies upon in terms of statistical independence.</p>
<p>You also learned about decision trees which were our first introduction to a machine learning algorithm. You will, I hope, have been surprised by how intuitive yet powerful the decision tree algorithm is and how it leads to an interpretable, user-friendly algorithm.</p>
<p>You might have been surprised to see statistics emerge again in the form of information gain as an element of a particular algorithm for the development of decision trees from data.</p>
<p>Finally, in that section we began to look at ideas, such as ensembling, which we will develop deeper in a later course. This approach turned our humble decision tree into the mightier random forest which has been one of the best performing machine learning algorithms for many tasks.</p>
<p>At this point, it is time to put the ideas you have learned into practice so we embark on that journey next.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p style="page-break-before: always"><h2>3.1&emsp;Welcome to Topic 3</h2><div class="u-typography-bold-intro">
<p>Welcome to Topic 3. We hope you enjoyed the previous topic.</p>
<p>It is practical skills time! We have been accumulating quite a bit of material at this stage and you have probably not had a lot of time to put any of this into action.</p>
<p>Many of you may not even have a lot of experience or confidence yet in turning the sort of ideas we have seen into code. Fear not, as this week we are going to introduce some software tools based around the Python language which will allow you to very quickly put these ideas into action.</p>
<p>If you don’t already know Python don’t worry as it is pretty easy to get going with the language although as with any language mastery takes the accumulation of a lot of experience.</p>
<p>We are going to build up skills that will allow you to implement both the Decision Tree (and its ensembled version, the Random Forest Classifier) and the Naïve Bayes Classifier.</p>
<p>We will build up to these through drawing attention to component technologies that are universally useful to Machine Learning implementation in Python in a structured step by step way.</p>
<h3 id="python-data-science-handbook">Python Data Science Handbook</h3>
<p>We are going to follow an excellent textbook which I recommend for this course and which is available <a href="https://jakevdp.github.io/PythonDataScienceHandbook/">online</a> for free. This book, written by Jake VanderPlas, is a great guide for those wishing to harness Python for basic machine learning and data science.</p>
<p><a href="https://jakevdp.github.io/PythonDataScienceHandbook/"><img alt="Book entitled 'Python Data Science Handbook' showing grey Iquana on white and red background" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/f3/75/hero_f375723d-78a1-4f51-9924-66ae846b2922.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/f3/75/small_hero_f375723d-78a1-4f51-9924-66ae846b2922.PNG 320w, https://ugc.futurelearn.com/uploads/assets/f3/75/hero_f375723d-78a1-4f51-9924-66ae846b2922.PNG 648w, https://ugc.futurelearn.com/uploads/assets/f3/75/large_hero_f375723d-78a1-4f51-9924-66ae846b2922.PNG 729w, https://ugc.futurelearn.com/uploads/assets/f3/75/large_hero_f375723d-78a1-4f51-9924-66ae846b2922.PNG 2x"/></a>
<sub>Source: O’Reilly Media</sub></p>
<p>We will spend less time talking and more time doing this week compared to other weeks. Before we go further I strongly urge you to refresh what you learned in the previous course regarding the use of Google Colab.</p>
<p>To be more explicit, please review the items highlighted in the “<a href="https://colab.research.google.com/notebooks/basic_features_overview.ipynb">Overview of Colaboratory Features</a>” notebook.</p>
<p><img alt="overview of colaboratory features showing a table of contents, including code cells, text cells, adding and removing cells, working with Python, system aliases, magics" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/ec/ad/hero_ecada20a-4171-4b2f-9f62-560a52df523d.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/ec/ad/small_hero_ecada20a-4171-4b2f-9f62-560a52df523d.PNG 320w, https://ugc.futurelearn.com/uploads/assets/ec/ad/hero_ecada20a-4171-4b2f-9f62-560a52df523d.PNG 648w, https://ugc.futurelearn.com/uploads/assets/ec/ad/large_hero_ecada20a-4171-4b2f-9f62-560a52df523d.PNG 729w, https://ugc.futurelearn.com/uploads/assets/ec/ad/large_hero_ecada20a-4171-4b2f-9f62-560a52df523d.PNG 2x"/></p>
<p>I know you are all impatient to get started, so without further delay, let’s do that.</p>
<p><sub><strong>References</strong></sub></p>
<p><sub>VanderPlas, Jake. (2016) <em>Python Data Science Handbook: Essential tools for working with data</em> Sebastopol, CA: O’Reilly Media</sub></p>
</div><p><h2>3.2&emsp;Markdown</h2><div class="u-typography-bold-intro">
<p>Before you delve into your practicals, you should take a look at a number of technologies which are worth investing some time on.</p>
<p>Our Google Colab documents cells comprise either Text or Code and while the code part (generally Python) is fairly obvious, the text part and the rich formatting it supports requires a basic understanding of Markdown.</p>
<p>In this step, we look at Markdown. This is a sort of writing technology. It was invented to make writing for the web easier.</p>
<p>Take a look at some of the originating ideas for Markdown <a href="https://daringfireball.net/projects/markdown/">here</a>.</p>
<p>Markdown is increasingly used for easy creation of text for the web. The very document you are reading is written in Markdown! A great and short introduction to Markdown can be seen in the video below.
</p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<sub>Source: <a href="https://www.youtube.com/channel/UCYspUZGexLdDLjHRkuERQlg">Nicholas Cifuentes-Goodbody</a></sub>
<p>In this YouTube video, the presenter ends the introduction by describing how references can be managed in Markdown. The presenter used Pandocs and a reference manager such as <a href="https://www.zotero.org/">Zotero</a>. For those interested in the use of Markdown more generally for their work outside its use in Colab, I would recommend the following blog posts on both Markdown and citation management within Markdown:
<a href="http://historytothepublic.org/referencing-and-working-with-bibliographies-in-markdown-the-recommended-method/">Referencing and working with bibliographies in Markdown: the recommended method</a>.</p>
<p>Now that you have a basic understanding of Markdown, it is time to consider the specifics of how Markdown is used in Google Colab. The best source for that material is the Google Colab site, so please take a look through the following link - 
<a href="https://colab.research.google.com/notebooks/markdown_guide.ipynb">Formatting text in Colaboratory: A guide to Colaboratory markdown</a>.</p>
<p>A great advantage of the Markdown support in Colab is the ease of integration of equations and other mathematical expressions. This is achieved through the use of MathJax. This is a Javascript library which allows easy conversion between equations expressed using LaTeX syntax and a form suitable for rendering in a web browser.  All you need to do is to place your mathematical statement within a pair of $ signs. The trickier part though, if you are not familiar with it, is expressing your equations in LaTeX, but there are many guides for that online, for example: <a href="https://en.wikibooks.org/wiki/LaTeX/Mathematics">LaTeX/Mathematics</a>.</p>
<p>There are also WYSIWYG (what you see is what you get) editors for equation editing which work best for you? If so please share them in the comments section.</p>
<p>Finally, as easy to use as Markdown is, sometimes you may forget the syntax details. It is best to keep a cheat sheet handy, like this <a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet">Markdown Cheatsheet</a> on Github.</p>
<p>If you don’t know what Git is, we need to rectify that. It is not essential for this course, as you are using Google Colab, and even if sharing notebooks you are likely to do so via Google Drive. That said, everyone should know how to use Git. Let’s force ourselves to look at Git in the next step.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.3&emsp;Git and Github</h2><div class="u-typography-bold-intro">
<p>When writing code, version control is vital.</p>
<p>Version control refers to a software system which records changes to a set of files over time so that you can retrieve specific versions later. While useful, and in this case relevant to source code, version control is applicable to any type of file.  Originally version control was nothing more than making copies of a file or adding versioning information to a document. Although not very sophisticated, it was better than nothing. Such approaches gave way to database-driven solutions where versions of files were tracked and archived. The current best practice is now to use a distributed version control system such as Git.  To learn more about the evolution of version control systems and how <a href="https://git-scm.com/">Git</a> relates to these, please read <a href="https://git-scm.com/book/en/v2/Getting-Started-About-Version-Control">Getting started - About version control</a>.</p>
<p>Armed with this background information, and for the impatient, among you, I really, really, recommend the following short Youtube videos, created by <a href="https://www.youtube.com/channel/UCvjgXvBlbQiydffZU7m1_aw">The Coding Train</a>. They are entertaining and provide a great introduction to many of the concepts in Git through the use of Github.</p>
<p>[1] <a href="https://www.youtube.com/watch?v=BCQHnlnPusY">Introduction - Git and GitHub for Poets</a></p>
<p>[2] <a href="https://www.youtube.com/watch?v=oPpnCh7InLY">Branches - Git and GitHub for Poets</a></p>
<p>[3] <a href="https://www.youtube.com/watch?v=_NrSWLQsDL4">Forks and Pull requests - Git and GitHub for Poets</a></p>
<p>[4] <a href="https://www.youtube.com/watch?v=WMykv2ZMyEQ">GitHub Issues - Git and GitHub for Poets</a></p>
<p>For those of you who have embraced Git and know it well already, many of you will use Git from the command line. Like Markdown, it can be easy to forget some of the less commonly used commands when you need them, so always keep a cheat sheet at your fingertips such as the <a href="https://github.github.com/training-kit/downloads/github-git-cheat-sheet.pdf">Git Cheat Sheet</a>.</p>
<p>Finally, on the subject of Git, if you really want to know everything there is to know about Git, see the <a href="https://git-scm.com/book/en/v2/Getting-Started-About-Version-Control">Git online book</a>.</p>
<h3 id="github-in-colab">Github in Colab</h3>
<p>For the final step, you should now take a quick read of the <a href="https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb">Google Colab Github</a> integration, which is pretty straightforward.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.4&emsp;NumPy and Pandas</h2><div class="u-typography-bold-intro">
<p>In this step, we are going to get some practice with Python libraries, which are important for efficient and effective manipulation of data.</p>
<p>We are not talking about machine learning here. We are simply talking about how to get data into our Python program in a way that allows easy manipulation of our feature vectors, training instances and testing examples across a wide range of data types.  Two packages, <strong>NumPy</strong> and <strong>Pandas</strong>, are very popular and powerful for such tasks. At the end of this step, you should know what NumPy is, and how to use it in a basic way. You will also have a little experience with Pandas. We start with NumPy.</p>
<h3 id="introduction-to-numpy">Introduction to NumPy</h3>
<p>We begin with the excellent introduction to NumPy detailed in our recommended textbook which you can follow and execute as a Google Colab notebook at <a href="https://drive.google.com/open?id=1ClfwwjdCE5raRlwDfxHg8hB-LcJMInQX">Introduction to NumPy</a>.</p>
<p>The next step in that chapter is an introduction to data types in NumPy (Numerical Python) which also has the nice property of helping you understand data types generally in Python. See <a href="https://drive.google.com/open?id=1UJ3UHdv_OfiTIzZM9CciPh1avbTo4yzm">Understanding Data Types in Python</a>. You can follow along by executing the code in the notebook but generally, you must execute the cells in order, or it is likely to fail.</p>
<p>The last step we really need to look at is the NumPy Array type. This is important, as Pandas is based on this data type, so understanding it is very useful.  The link to follow for this is <a href="https://drive.google.com/open?id=1i4DLAtE0xC-0sN8tdqXEqJTlqa6lPq2z">The Basics of NumPy Arrays</a>.</p>
<p>You may wish to finish reading Chapter 2 content of Python Data Science Handbook at the following link - although if you have followed the above steps you are now ready to move on to Pandas.</p>
<p>If you have time, I recommend that you complete <a href="https://drive.google.com/open?id=1GnSajSiSz7_eHdLgzorb3e141ZpFI0gA">Chapter 2</a>.
Now for Pandas.</p>
<h3 id="pandas">Pandas</h3>
<p>Pandas is built for data munging, aka <a href="https://en.wikipedia.org/wiki/Data_wrangling">data wrangling</a>, which is the activity of transforming data from one format to another, restructuring it, reshaping it and generally making it more convenient for subsequent processing. The Pandas project and the Python data analysis library can be found <a href="https://pandas.pydata.org/">here</a>, but for now you don’t need to go quite that deep.</p>
<p>Actually, given that you will also need to think about plotting and visualisation in order to see your outputs in non-numerical formats, e.g. plots, charts, etc., we will take a crash course in Pandas, beginning with a well put together 20 minute Youtube clip. This video takes you through Pandas, while also bringing in important packages like Matplotlib. </p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<sub>Source: <a href="https://www.youtube.com/channel/UCxX9wt5FWQUAAz4UrysqK9A/about">CS Dojo</a></sub>
<h3 id="deeper-into-pandas">Deeper into Pandas</h3>
<p>At this point, it is time for our go-to textbook and we will now dive into Chapter 3 of Python Data Science Handbook, specifically looking at <a href="https://drive.google.com/open?id=1EXHYD6yCWOcKKSVq9ubvwAZSfax6NlM7">Data Manipulation with Pandas</a>.</p>
<p>Next, you really should understand the <strong>Series</strong> and <strong>DataFrame</strong> data structures which are very well introduced in <a href="https://drive.google.com/open?id=1hdaafRPulNi5U7rykIGs1RGbSNgjvcUk">Introducing Pandas Objects</a>.</p>
<p>Having acquired this knowledge, it’s time to look at indexing. The <a href="https://drive.google.com/open?id=16ut9T8ndI31fVAqnHXzitjz4B4p7KOKY">Data Indexing and Selection</a> Colab notebook is well explained and gives you ample opportunity to experiment.</p>
<p>Finally, take a quick look at handling missing data in the <a href="https://drive.google.com/open?id=10kCYOS1aZ5zSWgoGRgGutmY7rME5ww9o">Missing Values</a> Colab notebook.</p>
<h3 id="google-colab-pandas-exercises-please-try-it">Google CoLab Pandas Exercises (Please try it)</h3>
<p>I recommend a complete read of all the notebooks associated with Chapter 3 in the <strong>Python Data Science Handbook</strong>. However, even at this point, you are ready to join in with the Google Colab, <a href="https://drive.google.com/open?id=1OD2QGsgSdcnnyJA9S0LOYMxFWnevgfcp">Intro to Pandas</a> tutorial. This is the final piece of this step and gives you some opportunity to have fun with Python and Pandas!</p>
<p>Now, and only now can we tackle our Decision Trees and Naïve Bayes examples.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.5&emsp;Feature Engineering</h2><div class="u-typography-bold-intro">
<p>This is a short introduction step which we will take just prior to learning about a very important machine learning package in Python called Scikit-Learn.</p>
<p>We want to show you some of our Feature Engineering in action with Python. We have not introduced SciKit-Learn just yet and you will see in the following notebook that this package will be the source of our Feature Engineering magic.</p>
<h3 id="feature-engineering-notebook">Feature Engineering notebook</h3>
<p>I encourage you to delve straight into the <a href="https://drive.google.com/open?id=11EYnM5H4wS6shU5g5JgIbRbuMBMFcv6X">Feature Engineering</a> notebook. You won’t fully understand every example in the notebook yet, so just focus on the categorical, text and image features. The piece on missing data is also great.</p>
<p>You will have noticed a nice reference to a notebook on Feature Engineering for Images. It is a really nice, useful resource, but can be left until you are ready to do your assignment. If you are curious or simply enjoying this, take a look <a href="https://drive.google.com/open?id=1U363adTKeD_6EaNfIDfwYgg7ZxWV7suI">here</a>.</p>
<p>At this point, it is time to look at Scikit-Learn.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.6&emsp;Introduction to Scikit-Learn</h2><div class="u-typography-bold-intro">
<p>We are now going to proceed to Machine Learning practical implementation.</p>
<p>The Python package, which will be your best friend now and in your assignment, is <strong>Scikit-Learn</strong>. We encourage you to become familiar with this package and all its algorithms, from decision trees to support vector machines, over a number of courses. However, let’s first address the basics.</p>
<p>We start with a basic introduction to the Scikit-Learn package in the notebook link below. Be warned, there is a lot in it, and it is tempting to jump to some of the links to the other examples mentioned in the notebook. It is not necessary for you to do this and indeed, you don’t need to master every element in the notebook. Just try your best to become familiar with it. Remember too that you can experiment wildly. You can’t break it and it’s not even your computer if you are coding in Google Colab! 
<a href="https://drive.google.com/open?id=128-sBcoWijrWfRXZuN6uSY71efqChab5">Introducing Scikit Learn</a>.</p>
<p>For data visualisation in the above step, you will see <strong>Seaborn</strong> was used rather than <strong>Matplotlib</strong> – if you did not click on the link to <a href="https://drive.google.com/open?id=1YQVSeLDGKhaeesqDYUYa1sO0dYIo5ByJ">Visualization with Seaborn</a> in the step above, I suggest you do so now.</p>
<p>So now it is time at last to follow the examples covered in this online course on our machine learning algorithms. Next up is the Naïve Bayes Classifier.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.7&emsp;Naive Bayes Practical</h2><div class="u-typography-bold-intro">
<p>You will recall that we considered Naïve Bayes and how they work in Topic 2 of this course.</p>
<p>If you want to review how Naïve Bayes work, Jake VandePlas’s <a href="https://drive.google.com/open?id=1jeWaKiwIWzDWT9pHtG10qUn3FAvRJ8oK">Naïve Bayes notebook</a> provides an excellent recap. If you have been following along with all the practicals so far, you are already familiar with all the packages and functionalities used.</p>
<p>You should also notice how easy it is to:</p>
<ul>
<li>Generate data,</li>
<li>Manipulate data,</li>
<li>and fit statistical distributions with Python and NumPy.</li>
</ul>
<p>Look too at the dynamic visualisation – you can immediately visualise your data and 
 results at the click of a cell.</p>
<h3 id="please-comment">Please comment!</h3>
<ul>
<li>Did you actually experiment with the <a href="https://drive.google.com/open?id=1jeWaKiwIWzDWT9pHtG10qUn3FAvRJ8oK">Naïve Bayes notebook?</a></li>
<li>Did you click every cell in sequence?</li>
<li>Did you experiment with different data?</li>
</ul>
<p>At the very least, I hope you had some fun entering testing phrases into the Newsgroup subject classifier? If not, go back and play.</p>
<p>Next up is our Decision Trees algorithm.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.8&emsp;Decision Trees and Random Forests</h2><div class="u-typography-bold-intro">
<p>In the previous step, you worked through Jake VandePlas’s <a href="https://drive.google.com/open?id=1fpqptRX_prfLMoMBonxHgfkyMn0BhN5O">Naïve Bayes notebook</a>.</p>
<p>We are now going to go further and explore another of Jake VandePlas’s excellent introductions, <strong>Decision Trees and Random Forests notebook</strong>. You really only need to go as far as the Random Forest example <a href="https://drive.google.com/open?id=1CGjVFYdFdwY2DZOzdH60e8bzPRC9uFPA">here</a>.</p>
<p>Ideas such as <strong>Bagging used in Ensembles</strong> will be reserved for another course later.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.10&emsp;Review of Topic 3</h2><div class="u-typography-bold-intro">
<p>Congratulations on completing Topic 3, which has been very hands-on.</p>
<p>There was a lot to take in but it has all been very practical, and hopefully interactive if you got involved with working through your Colab notebooks.</p>
<p>While we have used Google Colab for the hands-on practical sessions, you could just as easily have installed Jupyter yourself via Anaconda. Alternatively, you could have dispensed with the notebooks in the first place, and have done everything in plain vanilla Python scripts.</p>
<p>Whatever path you chose we hope you have learned how powerful Python and packages like Scikit-Learn are in helping you accelerate your machine learning journey and for putting data and detail onto what are otherwise sometimes abstract concepts.</p>
<p>At this point, you should be ready to learn about your practical assignment. We will deal with this in Topic 4.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p style="page-break-before: always"><h2>4.1&emsp;Welcome to Topic 4</h2><div class="u-typography-bold-intro">
<p>In the video above Professor Tomas Ward explains what will be covered in Topic 4 of Bayesian and Information Based Learning.</p>
<p>Topic 4 introduces and describes your assignment for this entire program. This is a fun assignment and is based on a research challenge which this masters class has been involved with since 2018.</p>
<table>
<thead>
<tr>
<th>Assignment</th>
<th>Release date</th>
<th>Submission deadline</th>
</tr>
</thead>
<tbody>
<tr>
<td>Media Memorability</td>
<td>10 February 2020</td>
<td>27 April 2020</td>
</tr>
</tbody>
</table>
<p>Please refer to <a href="https://www.futurelearn.com/courses/data-representation-and-feature-engineering/1/steps/656288">Course 1 - Assessment Details</a> for more information about how to complete the practical and how to submit your work for grading.</p>
<h3 id="your-task">Your Task</h3>
<p>You are going to look at a prediction task. This is a media analytics task in which you are going to design a machine learning algorithm that will be used to predict the memorability of short video clips.</p>
<p>“How on earth am I going to do that” you might be asking yourself? Well, the set up is straightforward enough.</p>
<p>We asked test subjects to watch 10,000 seven-second video clips. These test subjects were subsequently asked about their recall of these videos.</p>
<p>As a result, we were able to annotate each video clip with a memorability score, based on how many people were able to successfully recollect the video. So we have the videos, and target features - in this case, the memorability score.</p>
<p>Your task is to design a machine learning algorithm which predicts these memorability scores from the videos.  Easy right? Let’s take a look.</p>
</div><p><h2>4.2&emsp;Memorability</h2><div class="u-typography-bold-intro">
<p>We can all name a particular film that we loved and enjoyed watching because it was entertaining, had a great plotline, or a fantastic score.</p>
<p>But what <em>makes</em> that film memorable? What makes it stick in our minds when so many others are quickly forgotten? Your assignment deals with memorability and the ability to remember video content after a certain period of time.</p>
<p>Watch the following one-minute videos, all dealing with a different subject matter, and then answer the question posed in the comments section below.</p>
<p><strong>The Fall [1-Minute Short Film]</strong>
</p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<p><strong>The most boring video in the world. The snail.</strong>
</p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<p><strong>A Story (1-Minute Film)</strong>
</p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<h3 id="comment-tell-us-what-you-think">Comment: Tell us what you think!</h3>
<p>We’d like you to tell us what <em>you</em> think makes a film or video memorable.</p>
<p>In your response, please comment on the following:</p>
<ul>
<li>Short term memorability</li>
<li>Long term memorability</li>
<li>Designing for memorability</li>
<li>Video memorability prediction using Machine Learning</li>
</ul>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.3&emsp;Media Memorability Assignment </h2><div class="u-typography-bold-intro">
<p>For this assignment we want you to predict the short term and long term memorability scores for a set of videos, using their pre-computed features and the video captions.</p>
<p>In this step, we outline the main components of your assignment. These include:</p>
<ol>
<li>An introduction to the assignment</li>
<li>Marks allocated</li>
<li>The information you need to complete your assignment, and where to find it</li>
<li>The tool you will use to perform this assignment</li>
<li>The assignment deliverables and how to submit them</li>
<li>The submission deadline</li>
</ol>
<h3 id="introduction-to-the-assignment">1. Introduction to the assignment</h3>
<p>This assignment is part of the <a href="http://ceur-ws.org/Vol-2283/MediaEval_18_paper_40.pdf">MediaEval Predicting Media Memorability task</a> in which people were shown a set of 7-second video clips and tested on their ability to remember them.</p>
<p>The goal of this task is to automatically predict a memorability score for a video, reflecting its probability to be remembered.</p>
<p>Subjects who took part in the <strong>MediaEval Predicting Media Memorability task</strong> watched a sequence of videos and were then tested on their recall of these videos after several hours and also after several days.</p>
<p><em>Your task</em> is to perform a media analytics task in which you are going to design a machine learning algorithm that will be used to predict the memorability of short video clips.</p>
<h3 id="marks-allocated">2. Marks allocated</h3>
<p>This assignment is worth <strong>25%</strong> of the overall module marks.</p>
<h3 id="google-drive-assignment-folder">3. Google Drive Assignment Folder</h3>
<p>We have created an assignment folder on Google Drive, called <a href="https://drive.google.com/open?id=1qqy-qvvHH6NKfZgE6d2Dc755a7FhiP7N"><strong>CA684 _Assignment</strong></a>. This contains all the folders and documents you will need to complete this assignment. We advise you to bookmark this link.</p>
<h3 id="google-colaboratory">4. Google Colaboratory</h3>
<p>We will be using <a href="https://colab.research.google.com/notebooks/welcome.ipynb#recent=true"><strong>Google Colab</strong></a> to perform this assignment. Google Colab is a free cloud platform similar to Jupyter Notebook on a local machine. We recommend Colab as a workspace environment because it supports GPU, which makes executing code easier and faster than trying to execute code in the local machine.</p>
<h3 id="deliverables">5. Deliverables:</h3>
<p>You are expected to upload the completed assignment to <strong><a href="https://loop.dcu.ie/theme/dcu/layout/altlogin.php">Loop</a></strong>. Your submission should contain the following 2 items:</p>
<ol>
<li>A detailed report explaining your assignment in IEEE double-column format.</li>
<li>A zip file consisting of all your code files.</li>
</ol>
<p>Do not use the exact method provided in <strong>Predicting memorability using video captions</strong> in your submission, as this will be viewed as plagiarism. You may, of course, use the features with a different model.</p>
<h3 id="submission-deadline">6. Submission deadline</h3>
<p>We are releasing the relevant information you need to complete the assignment now. This means you can begin working on how you will go about completing it.</p>
<p>The deadline for your assignment submission is <strong>27 April 2020</strong>.</p>
<h3 id="comment">Comment!</h3>
<p>This step is designed to be a guide to getting started with your assignment. Please read through this information carefully and be sure to comment below if you have any questions or anything is unclear.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.4&emsp;Assignment overview</h2><div class="u-typography-bold-intro">
<p>The Assignment Overview folder contains 3 documents that will give you an overview of the MediaEval Predicting Media Memorability task.</p>
<p>We advise you to read through each of these documents carefully before beginning the assignment.</p>
<h3 id="assignment-overview-folderhttpsdrivegooglecomdriveu0folders1svbkambekoy67sjadxljp6cf1gua81m"><a href="https://drive.google.com/drive/u/0/folders/1Sv_BkAMBekoy67sJAdXljP6Cf1GUA81M"><strong>Assignment overview folder</strong></a></h3>
<p>The 3 files in this folder provide a comprehensive introduction to the problem which you are being asked to solve.</p>
<ol>
<li><strong>MediaEval 2018: Predicting Media Memorability</strong>:
This research paper was presented at the MediEval memorability challenge. This paper gives you a brief overview of the dataset considered for their experiments, the methodologies implemented, and the evaluation metrics used.</li>
<li><strong>MediaEval_Problem_Slides_Comments</strong>: This presentation, given by the authors of <strong>MediaEval 2018: Predicting Media Memorability</strong>, provides a detailed description of the assignment and the dataset, as well as the results and methodologies used by them (please note the comments on this document).</li>
<li>An edited presentation of DCU’s 2019 entry for this competition, entitled <strong>Insight@DCU in the Memorability Challenge at MediaEval2019 - EB_Edit</strong>.</li>
</ol>
<p>Take a look at DCUs memorability results! Their entry achieved the best performing results, through ensembling models with different modalities, such as captions and visual pre-computed features.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.5&emsp;Your Assignment Dataset</h2><div class="u-typography-bold-intro">
<p>Your assignment dataset contains everything you will need to complete your assignment.</p>
<p>The <strong>README</strong> file provides information on all the features in the Dataset folder. It also gives information on the ground truth and sources folders. You must read this document before you begin this assignment.</p>
<p>The dataset (dev-set) consists of captions for these videos and their pre-computed features. The pre-computed features are video-dedicated features and frame-based features. You don’t need to have in-depth knowledge about these features but the numbers used are useful for providing a solution to the problem. There is also a Ground-Truth file for the dataset which has the memorability scores for 6000 of the videos.</p>
<p>There are pre-computed features available for each of the 8000 videos and these include video captions.</p>
<p>The <a href="https://drive.google.com/drive/folders/17SE5iKTVQI1qMgecF4It7bk7q6y0AEcU"><strong>Dev-set</strong></a> folder contains the dataset you will use in this assignment, including pre-computed features:</p>
<ul>
<li>C3D</li>
<li>HMP</li>
<li>Color Histograms</li>
<li>LBP</li>
<li>ORB</li>
<li>InceptionV3</li>
<li>HOG</li>
<li>Video Captions</li>
<li>Aesthetic Features</li>
</ul>
<p>Here you will also find the <strong>Ground-truth</strong> folder containing the ground-truth scores, which must be considered during training.</p>
<p><em>Please note</em>: We do not recommend that you zip and download files, as this is time-consuming. If you need to download the dev-set files, you can mount your drive to your local machine. You can load files directly from Google Drive into a GPU-enabled Jupyter notebook on Google Colaboratory which is the recommended workspace environment for this assignment.</p>
<p>The <strong>Sources</strong> folder contains all the video files that were used to compute the features. This folder is for reference purposes only and is not necessary in order to complete this assignment.</p>
<p><em>Note: it may take a considerable amount of time to unzip the dev-set folder.</em></p>
<h3 id="please-comment">Please comment</h3>
<p>If you have questions about anything you have read so far, please let us know in the comments below.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.6&emsp;Predicting Memorability Tutorial</h2><div class="u-typography-bold-intro">
<p>In this step, you are presented with a Google Colab notebook that provides detailed instructions on the main elements used in Python for carrying out your assignment.</p>
<p>We encourage you to begin by working through the <strong>Predicting Memorability</strong> tutorial.</p>
<p>We first recommend that you add the shared folder <strong>CA684_Assignment</strong> to your Drive. Right-click on the folder name and click ‘Add to My Drive’, (see Figure 1 below for further details). This will create a read-only folder in your Drive, which will allow you to read in the datasets.</p>
<p><img alt="Google drive webpage, shared with me and opened at CA684 assignment. Add to My drive is highlighted" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/f8/00/hero_f8005dc1-72ec-4df1-80ea-1b42edac90aa.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/f8/00/small_hero_f8005dc1-72ec-4df1-80ea-1b42edac90aa.PNG 320w, https://ugc.futurelearn.com/uploads/assets/f8/00/hero_f8005dc1-72ec-4df1-80ea-1b42edac90aa.PNG 648w, https://ugc.futurelearn.com/uploads/assets/f8/00/large_hero_f8005dc1-72ec-4df1-80ea-1b42edac90aa.PNG 729w, https://ugc.futurelearn.com/uploads/assets/f8/00/large_hero_f8005dc1-72ec-4df1-80ea-1b42edac90aa.PNG 2x"/>
<sub><em>Figure 1: Adding a shared folder to your Drive</em></sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.7&emsp;Predicting Memorability using Video Captions Tutorial</h2><div class="u-typography-bold-intro">
<p>You should now have completed the ‘Predicting Memorability’ tutorial.</p>
<p>Next, you should work through the <strong>Predicting Memorability using Video Captions</strong> tutorial.</p>
<p>This tutorial takes you through the following processes:</p>
<ul>
<li>Loading the captions as features</li>
<li>The ground truths as targets</li>
<li>Building and training your model</li>
<li>Predicting the memorability score</li>
</ul>
<h3 id="choose-a-feature-dataset">Choose a feature dataset</h3>
<p>In your assignment, you must be able to load the features and train your model with the feature(s). Choose one of the feature datasets and work through this tutorial to familiarise yourself with the assignment objective.</p>
<h3 id="create-a-copy-of-the-colab-notebooks">Create a copy of the Colab notebooks</h3>
<p>To interactively follow the tutorials, you will need to create a copy of the Colab notebooks in your own Drive, as the files added in the previous step are in read-only mode. You can do this by clicking on the ‘File’ tab, followed by ‘Save a copy in Drive’. See Figure 1 for more detail. This will create a local copy in the ‘My Drive’ folder that you can then run and edit.</p>
<p><img alt="Google drive screen. File tab open" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/b8/50/hero_b8505746-ef9d-42c3-8606-bffc81a14409.PNG" srcset="https://ugc.futurelearn.com/uploads/assets/b8/50/small_hero_b8505746-ef9d-42c3-8606-bffc81a14409.PNG 320w, https://ugc.futurelearn.com/uploads/assets/b8/50/hero_b8505746-ef9d-42c3-8606-bffc81a14409.PNG 648w, https://ugc.futurelearn.com/uploads/assets/b8/50/large_hero_b8505746-ef9d-42c3-8606-bffc81a14409.PNG 729w, https://ugc.futurelearn.com/uploads/assets/b8/50/large_hero_b8505746-ef9d-42c3-8606-bffc81a14409.PNG 2x"/>
<sub><em>Figure 1: Creating a copy of the Notebooks</em></sub></p>
<h3 id="loading-features">Loading features</h3>
<p>We have created a basic Colab Notebook called ‘Loading features’. This contains function definitions which will help you load some of the provided features.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.8&emsp;Review of Topic 4</h2><div class="u-typography-bold-intro">
<p>Congratulations on completing Topic 4 and Course 2 of the CA684: Machine Learning.</p>
<p>You should now know what is expected of you from your assignment. The material covered in Topic 3 in terms of Python, Scikit-Learn and Pandas should help you get started.</p>
<p>In Course 3: <strong>Error Based Learning and Ensemble Approaches</strong>, we introduce further Machine Learning methods.</p>
<p>Let us know your thoughts on the course in the comments section below.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p style="page-break-before: always"><h2>1.1&emsp;Welcome to the course</h2><div class="u-typography-bold-intro">
<p>Hello everybody and welcome to CA 684 Machine Learning, ‘Error Based Learning and Ensemble Approaches’. This course is the third in a series of five courses under the Dublin City University Machine Learning series.</p>
<p>In this course, in terms of individual machine learning algorithms, we will examine regression methods which utilise error-driven model parameter updates.</p>
<p>We will see how the ideas involved lend themselves to methods useful for both regression and classification in the context of machine learning tasks.</p>
<p>We will also introduce the idea of ensembles, which will equip you with an understanding of how best to combine different machine learning models for achieving improved performance.</p>
<p>Finally, as we do every course, there is an opportunity to put your skills to work with hands on exercises.</p>
<p>The first topic we will tackle in this course is linear regression.</p>
<p>You might recall from our earlier courses that regression, in the context of machine learning, refers to the task of predicting a continuous target variable.</p>
<p>We are now going to examine how we can perform this task using linear regression approaches.</p>
<p>We will explore a new class of performance measures which we describe as loss functions,
and examine the circumstances under which we can use these to find good models for fitting data in a regression task.</p>
<p>We will introduce a specific approach to finding good model parameters, using an iterative algorithm called gradient descent, which you will see used in other areas of machine learning.</p>
<p>Finally, we will examine some ideas for making linear regression model fitting more robust to noise in our datasets.</p>
<p><img alt="Statement of funding from Skillnet Ireland stating that this course has been grant aided by Skillnet Ireland" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/14/0b/hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/14/0b/small_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 320w, https://ugc.futurelearn.com/uploads/assets/14/0b/hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 648w, https://ugc.futurelearn.com/uploads/assets/14/0b/large_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 729w, https://ugc.futurelearn.com/uploads/assets/14/0b/large_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 2x"/></p>
<div class="video_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.2&emsp;Introduction to Linear Regression</h2><div class="u-typography-bold-intro">
<p>In this step, we will get an introduction to Linear Regression.</p>
<p>The basic idea in Linear Regression is to assume a prediction model (a function) of a certain form. In this case, a linear form, and adjust its parameters such that when this model takes the training data as input, it produces outputs which are as close as possible to those associated with each training instance. These parameters we will learn to call “weights”.</p>
<p>More specifically, the model takes the attribute-value pairs (our feature vector) as input and a target feature as output.  It is a supervised learning task T.
Outperformance measure P is an error function which is used to measure how well a particular set of model parameters produces outputs which match the provided target features. The “closer” the outputs are the lower the error and therefore the better the model.</p>
<p>Our algorithms will be based on approaches which start with an initial guess for the set of parameters, calculate errors based on the training data, and then adjust the parameters in such a way as to reduce the error on the next iteration. As iterations proceed the error should reduce to a minimum which produces acceptable performance.</p>
<p>Let’s build up the idea with an example. We will use the classic house price example which is the basis for all sorts of online machine learning competitions. A great starting place for machine learning data and competitions is Kaggle  - an online community of data scientists and machine learning enthusiasts. Check it out <a href="https://www.kaggle.com/.">here</a> On the Kaggle website, you can find a good <a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques">house prices dataset</a>.</p>
<p>I will use this for our example.</p>
<p>This dataset is from Ames in Iowa, and it has almost 3000 properties, with prices and 79 features per property. You can learn more about this great dataset - developed by Dean de Cock from Truman State University - in Ames, Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project <a href="http://jse.amstat.org/v19n3/decock.pdf">here</a>.</p>
<p>A sample of the data is shown in Figure 1 below.</p>
<p><a href="https://ugc.futurelearn.com/uploads/assets/3e/46/3e4616a7-6870-4f9c-a0b6-70de8056f6cb.png"><img alt="Dataset from Ames in Iowa, with almost 3000 properties, with prices and 79 features per property" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/09/3b/hero_093b4760-b6fb-4115-b761-5c98645d93e3.png" srcset="https://ugc.futurelearn.com/uploads/assets/09/3b/small_hero_093b4760-b6fb-4115-b761-5c98645d93e3.png 320w, https://ugc.futurelearn.com/uploads/assets/09/3b/hero_093b4760-b6fb-4115-b761-5c98645d93e3.png 648w, https://ugc.futurelearn.com/uploads/assets/09/3b/large_hero_093b4760-b6fb-4115-b761-5c98645d93e3.png 729w, https://ugc.futurelearn.com/uploads/assets/09/3b/large_hero_093b4760-b6fb-4115-b761-5c98645d93e3.png 2x"/></a></p>
<p><strong>Figure 1</strong>: Ames dataset showing Sales Price and a sample of features including size, year built and the number of bedrooms.
Each row is a unique property and each column is a feature.  The set of variables which span the columns is our set of features.</p>
<p>For this regression challenge, we will set aside SalesPrice as theTarget feature which we are trying to predict. This is our <script type="math/tex">y</script>. We will call it <script type="math/tex">y^j</script> where we use the superscript <script type="math/tex">j</script> to count through all the training examples (almost 3000 in this case). I will remind you again about this notation later. We note that  <script type="math/tex">y^j \in \mathbb{R}</script> as we are dealing with a regression task.</p>
<p>It should also be noted that <script type="math/tex">x^j \in \mathbb{R}^n</script> where <script type="math/tex">n</script> is the dimension of the input feature space.</p>
<p>Let’s focus in on Lot Area versus Sales Price. We will take an example of 10 of these.
A plot of these might reveal something like Figure 2 below.</p>
<p><a href="https://ugc.futurelearn.com/uploads/assets/52/f6/52f6a510-eb68-4011-8838-997b6f598fa7.png"><img alt="Graph with Vertical axis X from 0 to 70,000 and Y axis from 1600 to 2800 - 10 sale prices." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/52/f6/hero_52f6a510-eb68-4011-8838-997b6f598fa7.png" srcset="https://ugc.futurelearn.com/uploads/assets/52/f6/small_hero_52f6a510-eb68-4011-8838-997b6f598fa7.png 320w, https://ugc.futurelearn.com/uploads/assets/52/f6/hero_52f6a510-eb68-4011-8838-997b6f598fa7.png 648w, https://ugc.futurelearn.com/uploads/assets/52/f6/large_hero_52f6a510-eb68-4011-8838-997b6f598fa7.png 729w, https://ugc.futurelearn.com/uploads/assets/52/f6/large_hero_52f6a510-eb68-4011-8838-997b6f598fa7.png 2x"/></a></p>
<p>Figure 2: Sample of 10 properties.</p>
<p>Looking at Figure 2 we can see that we might be able to express the relationship between floor area and sales price in a linear fashion, i.e. we could fit a straight line through the data and it would be a good match.</p>
<p>Let’s fit a line through this data, which we show now in Figure 3.</p>
<p><a href="https://ugc.futurelearn.com/uploads/assets/ee/04/ee04dbd1-5431-45a8-ac73-201b72d85577.png"><img alt="Graph with Vertical axis X from 0 to 70,000 and Y-axis from 1600 to 2800 - 10 sale prices - red line going diagonally through graph starting at 37 on the X-axis climbing to 58 then on the Y-axis 27000" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/b5/ff/hero_b5ff6783-c782-40f3-9ae1-e9054bf5670b.png" srcset="https://ugc.futurelearn.com/uploads/assets/b5/ff/small_hero_b5ff6783-c782-40f3-9ae1-e9054bf5670b.png 320w, https://ugc.futurelearn.com/uploads/assets/b5/ff/hero_b5ff6783-c782-40f3-9ae1-e9054bf5670b.png 648w, https://ugc.futurelearn.com/uploads/assets/b5/ff/large_hero_b5ff6783-c782-40f3-9ae1-e9054bf5670b.png 729w, https://ugc.futurelearn.com/uploads/assets/b5/ff/large_hero_b5ff6783-c782-40f3-9ae1-e9054bf5670b.png 2x"/></a></p>
<p>Figure 3: An example linear model used to fit the data.</p>
<p>This model might be something like
<script type="math/tex">Sales Price = 192 . Floor Area + 62812</script></p>
<p>This is obviously not a perfect model and clearly has problems at the edges (what is the predicted sales price for a vanishingly small area?)</p>
<p>However, for the range we have fitted this with data it is not a bad fit and it allows us to perform reasonable regression, i.e. we can predict some continuous value with possibly acceptable accuracy.  As an example for a floor area of 2200 (square feet), we can predict a Sales Price of $485212=192(2200)+62812.  This looks like a plausible price.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.3&emsp;Simple Linear Models</h2><div class="u-typography-bold-intro">
<p>Let us now look at simple linear models for this regression machine learning task.</p>
<p>This means we will have the output <script type="math/tex">y</script> as a linear function of <script type="math/tex">x</script>.  This predictor function is often called a hypothesis in the machine learning community.  Our hypothesis then which maps <script type="math/tex">x</script> to <script type="math/tex">y</script> is <script type="math/tex">h_\Theta(x)</script>.</p>
<p>In the previous step and in this case SalesPrice example we have <script type="math/tex">h_\Theta(x) = \Theta_0 + \Theta_1x</script> where <script type="math/tex">x</script>  is our <script type="math/tex">FloorArea</script> feature and <script type="math/tex">\Theta_0</script> is our intercept value of <script type="math/tex">62812. h_\Theta(x)</script> takes our <script type="math/tex">x</script> value and produces our prediction for SalesPrice. <script type="math/tex">h_\Theta(x)</script> can be considered our SalesPrice.</p>
<p>The notation we use for our hypothesis <script type="math/tex">h_\Theta(x)</script> reflects the fact that it takes our space of inputs and maps these to output through a parameterised space of functions. Note that <script type="math/tex">\Theta \in \mathbb{R}^n</script> and that <script type="math/tex">h_\Theta(x)</script> : <script type="math/tex">\mathbb{R}^n \rightarrow  \mathbb{R}</script> . The parameters are <script type="math/tex">\Theta</script>’s in this representation.</p>
<p>It should be noted this is independent of the fact that we are looking at a regression challenge here. This idea of the hypothesis in machine learning is widely adopted including in classification. We have introduced it here as it is useful when developing the links between linear regression and other machine learning tasks.</p>
<p>When we have only a small discrete set of <script type="math/tex">y</script>, i.e <script type="math/tex">h_\Theta(x)</script> then, we consider the hypothesis as representing a classification problem. Here, however, we have a continuous variable to predict. Therefore, our hypothesis reflects a regression problem.</p>
<p>The parameters <script type="math/tex">\Theta_i</script> we call weights, parameterise our function which has as a domain the input features <script type="math/tex">x</script> and maps these to predictions, the range of the function <script type="math/tex">y</script>.</p>
<p>Deciding and developing the form of the hypothesis is at the heart of machine learning and we will experience some of the challenges involved throughout the course.</p>
<p>In the case of linear regression, we make the assumption that we can approximate our targets as a linear combination of the feature variables <script type="math/tex">x</script>. We adopt the general form:</p>
<script type="math/tex; mode=display">h_\Theta(x) = \Theta_0 + \Theta_1x_1 + \Theta_2x_2 + …..+\Theta_jx_j</script>
<p>which is more compactly expressed as:</p>
<script type="math/tex; mode=display">h_\Theta(x) = \Theta_0 + \sum_{j=1} ^N \Theta_j x_j</script>
<p>or even more compactly, if we augment our feature vector:</p>
<script type="math/tex; mode=display">x = \begin{bmatrix}
x_1 \\
x_2 \\
...  \\
x_N
 
\end{bmatrix}</script>
<p>as:</p>
<script type="math/tex; mode=display">x = \begin{bmatrix}
1   \\
x_1 \\
x_2 \\
...  \\
x_N
 
\end{bmatrix}</script>
<p>where <script type="math/tex">x_0 = 1</script></p>
<p>then we can write:</p>
<p><script type="math/tex">h_\Theta(x) = \sum_{j=0} ^N \Theta_j x_j</script> = <script type="math/tex">\Theta^Tx</script></p>
<p><strong>Note:</strong> <script type="math/tex">N</script> here is the number of features in the original feature vector, i.e. we do not count <script type="math/tex">x_0</script>.</p>
<p>Returning now to our example, we have <script type="math/tex">N=1</script> for our SalesPrice prediction challenge and can see:</p>
<script type="math/tex; mode=display">x = \begin{bmatrix} 
1   \\

FloorArea:
 
\end{bmatrix} 
and  \:     \Theta =  \begin{bmatrix} 
62812  \\

192
 
\end{bmatrix}</script>
</div><p><h2>1.4&emsp;Loss Functions</h2><div class="u-typography-bold-intro">
<p>We now introduce the concept of a <strong>Loss Function</strong>. This is our performance measure P, remember that concept?</p>
<p>We begin by considering the concept of error in our model. The figure below shows three different linear models for the data. The red line is our original model. The green line has the same slope but a difference intercept, i.e. a different value for <script type="math/tex">\Theta_0</script>. The blue line is a model with both a smaller value for <script type="math/tex">\Theta_0</script>  and a larger <script type="math/tex">\Theta_1</script>. How do we determine which is the best model?</p>
<p><a href="https://ugc.futurelearn.com/uploads/assets/d2/a6/d2a6e394-2e8b-478b-a1e4-6dc82510b9ec.png"><img alt="In the figure there are three different linear models for the data. The red line being the original model, The green line has the same slope but a difference intercept, i.e. a different value for  Θ0. The blue line is a model with both a smaller value for  Θ0  and a larger  Θ1." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/47/e7/hero_47e70626-6dca-4708-a802-6ad4870dccaf.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/47/e7/small_hero_47e70626-6dca-4708-a802-6ad4870dccaf.jpg 320w, https://ugc.futurelearn.com/uploads/assets/47/e7/hero_47e70626-6dca-4708-a802-6ad4870dccaf.jpg 648w, https://ugc.futurelearn.com/uploads/assets/47/e7/large_hero_47e70626-6dca-4708-a802-6ad4870dccaf.jpg 729w, https://ugc.futurelearn.com/uploads/assets/47/e7/large_hero_47e70626-6dca-4708-a802-6ad4870dccaf.jpg 2x"/></a></p>
<p><sub><strong>Figure 1: The effect of different parameters on model fit.</strong><sub></sub></sub></p>
<p>One sensible sounding idea for measuring error is to try to have the model output, <script type="math/tex">h_θ (x)</script> match the true training values <script type="math/tex">y</script> as closely as possible. A simple way to formalise this is to look at the model prediction for each training example and compare it with the true value <script type="math/tex">y</script> and do this over all the <script type="math/tex">M</script> training examples we have. We can measure the error by looking at the differences between the predictions and the true values and sum this up over all our training examples. The larger this sum, is the worse our model fit is. Consequently, we can consider this measure as something which could be produced using a loss function.  An example of such a loss function is as follows:</p>
<script type="math/tex; mode=display">J(h_\Theta,x)=\frac{1}{2} \sum_{i=1}^M(h_\Theta(x^{i})-y^{i} )^2</script>
<p>This is a least-squares cost function. <script type="math/tex">M</script> is the total number of training examples we have. Note how the superscript <script type="math/tex">i</script> here is not exponentiation but instead is just indexing through the different examples we have. So we are looking at the errors for all predictions and aggregating a measure of this error. Given our linear predictor and squared loss function, we have a situation where finding the best parameters <script type="math/tex">\Theta</script> which minimise this loss function is a convex optimization problem which is amenable to many methods. We will only examine the most common approach.</p>
<p><strong>Aside:</strong> While we chose a squared loss function which lends itself to explicit analytical solutions, we could have chosen other models which maintain their convex optimization problem properties and therefore can be solved easily using numerical methods.</p>
<p>One good loss function to consider in your experimentation is the <strong>absolute loss function</strong>.</p>
<script type="math/tex; mode=display">J(h_\Theta,x)= \sum_{i=1}^M\mid h_\Theta(x^{i})-y^{i} \mid</script>
<p>This loss function is a robust loss function which is less susceptible to outliers.</p>
<p>Another well known form is the <strong>Deadband loss function</strong> which uses:</p>
<script type="math/tex; mode=display">max\left \{ 0,\mid h_\Theta(x^i) - (y^i) \mid - \epsilon\right \} , \epsilon \in \mathbb{R}_+</script>
<p>These are shown together for the context in Figure 2.</p>
<p><img alt="This loss function diagram is the basis for Support Vector Regression. If the model for the data is good, one finds that the choice of loss function has little impact on the final model produced" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/49/58/hero_49580b77-8a2f-4c87-9028-047869977ca4.png" srcset="https://ugc.futurelearn.com/uploads/assets/49/58/small_hero_49580b77-8a2f-4c87-9028-047869977ca4.png 320w, https://ugc.futurelearn.com/uploads/assets/49/58/hero_49580b77-8a2f-4c87-9028-047869977ca4.png 648w, https://ugc.futurelearn.com/uploads/assets/49/58/large_hero_49580b77-8a2f-4c87-9028-047869977ca4.png 729w, https://ugc.futurelearn.com/uploads/assets/49/58/large_hero_49580b77-8a2f-4c87-9028-047869977ca4.png 2x"/>
<sub><strong>Figure 2: Illustrative examples of loss functions</strong></sub></p>
<p>This loss function is the basis for Support Vector Regression, which you may have come across in your machine learning adventures. If our model for the data is good, one generally finds that the choice of loss function has little impact on the final model produced. We return now to our plain-vanilla loss function, i.e. the equation below.</p>
<script type="math/tex; mode=display">J(h_\Theta,x)=\frac{1}{2} \sum_{i=1}^M(h_\Theta(x^{i})-y^{i} )^2</script>
<p>Imagine we go through all parameter permutations <script type="math/tex">\Theta_i</script> and calculate the associated loss with respect to the data, e.g. repeating the process we see in Figure 1 but for every value of parameters <script type="math/tex">\Theta_0</script> and <script type="math/tex">\Theta_1</script>. If we plot this loss total versus the points in <script type="math/tex">\Theta_i</script> space, we will find an error surface. In the example highlighted of 2-d parameter space we might see something like Figure 3 below.</p>
<p><img alt="Illustration of an error surface for a 2-dimensional case. If we go through all parameter permutations  Θi and calculate the associated loss with respect to the data. For example, repeating the process we see in Figure 1 but for every value of parameters  Θ0  and  Θ1. If we plot this loss total versus the points in Θi space, we will find an error surface. In the example highlighted of 2-d parameter space we might see something like Figure 3 below." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/e2/15/hero_e215a017-2831-421b-9bf5-15c2aaaafcfb.png" srcset="https://ugc.futurelearn.com/uploads/assets/e2/15/small_hero_e215a017-2831-421b-9bf5-15c2aaaafcfb.png 320w, https://ugc.futurelearn.com/uploads/assets/e2/15/hero_e215a017-2831-421b-9bf5-15c2aaaafcfb.png 648w, https://ugc.futurelearn.com/uploads/assets/e2/15/large_hero_e215a017-2831-421b-9bf5-15c2aaaafcfb.png 729w, https://ugc.futurelearn.com/uploads/assets/e2/15/large_hero_e215a017-2831-421b-9bf5-15c2aaaafcfb.png 2x"/> <sub><strong>Figure 3: Illustration of an error surface for a 2-dimensional case.</strong><sub></sub></sub></p>
<p>The model that fits our data best should correspond to the set of parameters which represent the lowest point in this convex bowl as illustrated in Figure 4.</p>
<p><img alt="Image of parameters minimising error on an error surface." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/e7/a8/hero_e7a8da09-8c56-4899-80b7-a2f00184e927.png" srcset="https://ugc.futurelearn.com/uploads/assets/e7/a8/small_hero_e7a8da09-8c56-4899-80b7-a2f00184e927.png 320w, https://ugc.futurelearn.com/uploads/assets/e7/a8/hero_e7a8da09-8c56-4899-80b7-a2f00184e927.png 648w, https://ugc.futurelearn.com/uploads/assets/e7/a8/large_hero_e7a8da09-8c56-4899-80b7-a2f00184e927.png 729w, https://ugc.futurelearn.com/uploads/assets/e7/a8/large_hero_e7a8da09-8c56-4899-80b7-a2f00184e927.png 2x"/>
<sub><strong>Figure 4: Illustration of parameters minimising error on an error surface.</strong><sub></sub></sub></p>
<p>Given our example earlier for SalesPrice prediction, we could consider <script type="math/tex">\Theta_0</script> = 62812 and <script type="math/tex">\Theta_1</script> = 192. Figure 4 is exaggerated for illustrative purposes and therefore the relative scaling of the parameters is distorted so don’t worry about it.</p>
<h3 id="finding-optimal-theta">Finding Optimal <script type="math/tex">\Theta</script></h3>
<p>So one way to find this point on an error surface for our example is to find the points where:</p>
<script type="math/tex; mode=display">\frac{\partial}{\partial \Theta_0}\frac{1}{2}\sum_{i=1}^M(h_\Theta(x^i) - y^i)^2=0</script>
<p>and</p>
<script type="math/tex; mode=display">\frac{\partial}{\partial \Theta_1}\frac{1}{2}\sum_{i=1}^M(h_\Theta(x^i) - y^i)^2=0</script>
<p>How do we perform this calculation with a large <script type="math/tex">M</script>? It is doable but not very feasible. We would normally solve analytically using linear algebra and gradients as follows:</p>
<p>Let us create the following matrices.</p>
<p><script type="math/tex">X \in \mathbb{R}^{M \times N}</script> and <script type="math/tex">y \in \mathbb{R}^{M }</script></p>
<script type="math/tex; mode=display">X = \begin{bmatrix} 
(x^1)^T  \\

(x^2)^T  \\
...           \\
(x^M)^T
 
\end{bmatrix}</script>
<p>and</p>
<script type="math/tex; mode=display">y = \begin{bmatrix} 
y^1  \\

y^2 \\
...           \\
y^M
 
\end{bmatrix}</script>
<p>then our loss function becomes:</p>
<script type="math/tex; mode=display">J(h_\Theta, x) = \frac{1}{2} \sum_{i=1}^M(h_\Theta(x^i) - y^i)^2
 = \frac{1}{2} \sum_{i=1}^M(\Theta^Tx^i - y^i )^2 
= \frac{1}{2} \mid \mid X\Theta - y \mid \mid ^2 _2</script>
<p>Where is the Euclidean norm? See <a href="https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm">here</a>.</p>
<p>Our minimization challenge is then:</p>
<script type="math/tex; mode=display">\min_\Theta \mid \mid X\Theta - y \mid\mid ^2_2</script>
<p>We can do this by taking the gradient as above.</p>
<script type="math/tex; mode=display">\nabla_\Theta \mid \mid X\Theta - y \mid\mid ^2_2 = 2 X^T (X\Theta - y)</script>
<p>And setting these equal to zero.</p>
<script type="math/tex; mode=display">X^T (X\Theta^* - y) = 0 \Rightarrow \Theta^* = (X^T X)^{-1} X^Ty</script>
<p>This will work, however, as feature sets become large then we end up with some very large matrices to invert and that can really slow things down.  We have <script type="math/tex">N \times M</script> matrix by <script type="math/tex">M \times N</script>  yielding an <script type="math/tex">N \times N</script> matrix.</p>
<p>An alternative is an iterative approach using gradient descent which we examine in the next step.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.5&emsp;The Least Means Squares (LMS Algorithm)</h2><div class="u-typography-bold-intro">
<p>In order to find the set of weights that minimize our error function in an iterative manner, we are going to use an algorithm that evolves the error until it finds the minimum.</p>
<p>The method used in the previous step was analytical in that we explicitly solved for the minimum, this method is iterative.</p>
<p>We will use the <strong>gradient descent algorithm</strong> for this.</p>
<p>Using this method we will pick random weights initially and then use mathematical analysis to figure out which way is <strong>downhill</strong> from that starting point, and <strong>step</strong> out from there to arrive at another point – a set of weights which have lower error than what was seen in the previous step.</p>
<p>We repeat this process over and over until we cannot improve the error any further. Visually it looks like this:</p>
<p><img alt="Visual of gradient descent algorithm." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/0b/50/hero_0b5088d7-12f6-46a3-a363-b90b336218f5.png" srcset="https://ugc.futurelearn.com/uploads/assets/0b/50/small_hero_0b5088d7-12f6-46a3-a363-b90b336218f5.png 320w, https://ugc.futurelearn.com/uploads/assets/0b/50/hero_0b5088d7-12f6-46a3-a363-b90b336218f5.png 648w, https://ugc.futurelearn.com/uploads/assets/0b/50/large_hero_0b5088d7-12f6-46a3-a363-b90b336218f5.png 729w, https://ugc.futurelearn.com/uploads/assets/0b/50/large_hero_0b5088d7-12f6-46a3-a363-b90b336218f5.png 2x"/>
<sub><strong>Figure 1: Illustration of gradient descent showing initial condition and trajectory across iterations towards the minimum.</strong><sub></sub></sub></p>
<p><strong>How do we do this?</strong></p>
<p>What we need to do is find an adjustment to the weights which keep us going downhill. Let’s take a simpler error function with a single parameter to develop an intuition of how to do this as per the figures below.</p>
<p><img alt="Image of gradient descent showing initial condition and trajectory across iterations towards the minimum" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/a7/ad/hero_a7ad9453-077f-4d44-a36e-f31e8fcb663e.png" srcset="https://ugc.futurelearn.com/uploads/assets/a7/ad/small_hero_a7ad9453-077f-4d44-a36e-f31e8fcb663e.png 320w, https://ugc.futurelearn.com/uploads/assets/a7/ad/hero_a7ad9453-077f-4d44-a36e-f31e8fcb663e.png 648w, https://ugc.futurelearn.com/uploads/assets/a7/ad/large_hero_a7ad9453-077f-4d44-a36e-f31e8fcb663e.png 729w, https://ugc.futurelearn.com/uploads/assets/a7/ad/large_hero_a7ad9453-077f-4d44-a36e-f31e8fcb663e.png 2x"/></p>
<p>Let’s say we are starting at a random point marked in the figure above. How do we change <script type="math/tex">\Theta</script> such that J(<script type="math/tex">\Theta</script>) becomes smaller? Let’s focus simply on getting the direction right first.</p>
<p>One way might be to focus on the direction first and ignoring the magnitude of correction (i.e. ignore any interpretation of the length of the arrow).</p>
<p><img alt="Another image of gradient descent showing initial condition and trajectory across iterations towards the minimum focussing on the direction" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/df/71/hero_df712991-445e-4e61-b48c-c0eb9c531cf9.png" srcset="https://ugc.futurelearn.com/uploads/assets/df/71/small_hero_df712991-445e-4e61-b48c-c0eb9c531cf9.png 320w, https://ugc.futurelearn.com/uploads/assets/df/71/hero_df712991-445e-4e61-b48c-c0eb9c531cf9.png 648w, https://ugc.futurelearn.com/uploads/assets/df/71/large_hero_df712991-445e-4e61-b48c-c0eb9c531cf9.png 729w, https://ugc.futurelearn.com/uploads/assets/df/71/large_hero_df712991-445e-4e61-b48c-c0eb9c531cf9.png 2x"/></p>
<p>How about if we started on the left-hand side as per the figure below.</p>
<p><img alt="Another image of gradient descent showing initial condition and trajectory across iterations towards the minimum starting on the left-hand side this time" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/8f/c8/hero_8fc8d0e8-617e-424c-b0ed-a2f48bbf1728.png" srcset="https://ugc.futurelearn.com/uploads/assets/8f/c8/small_hero_8fc8d0e8-617e-424c-b0ed-a2f48bbf1728.png 320w, https://ugc.futurelearn.com/uploads/assets/8f/c8/hero_8fc8d0e8-617e-424c-b0ed-a2f48bbf1728.png 648w, https://ugc.futurelearn.com/uploads/assets/8f/c8/large_hero_8fc8d0e8-617e-424c-b0ed-a2f48bbf1728.png 729w, https://ugc.futurelearn.com/uploads/assets/8f/c8/large_hero_8fc8d0e8-617e-424c-b0ed-a2f48bbf1728.png 2x"/></p>
<p>Then you would hope to go in the direction shown below.</p>
<p><img alt="A further image of gradient descent showing initial condition and trajectory across iterations towards the minimum" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/62/a4/hero_62a4eadf-ea5c-4cf1-8f26-9a584a13e68e.png" srcset="https://ugc.futurelearn.com/uploads/assets/62/a4/small_hero_62a4eadf-ea5c-4cf1-8f26-9a584a13e68e.png 320w, https://ugc.futurelearn.com/uploads/assets/62/a4/hero_62a4eadf-ea5c-4cf1-8f26-9a584a13e68e.png 648w, https://ugc.futurelearn.com/uploads/assets/62/a4/large_hero_62a4eadf-ea5c-4cf1-8f26-9a584a13e68e.png 729w, https://ugc.futurelearn.com/uploads/assets/62/a4/large_hero_62a4eadf-ea5c-4cf1-8f26-9a584a13e68e.png 2x"/></p>
<p>Clearly, in both cases, we are going <strong>downhill</strong>.</p>
<p><strong>Note:</strong> If we were at the bottom of the hill we would not wish to go in either direction.</p>
<p><strong>What aspect of the function reflects these direction requirements?</strong></p>
<p>These directions could be captured by the slope at the two points shown which we can calculate as:</p>
<script type="math/tex; mode=display">\frac{\partial J(\Theta)}{\partial \Theta_0}</script>
<p>This is negative in location (a) and positive in location (b) as shown in the figure below, i.e. the slope is positive at (b) and negative at (a).</p>
<p>Given that at (a) we want to add a positive number to the existing <script type="math/tex">\Theta</script>  and at (b) we want to subtract a positive number from existing then we could use (-1) times <script type="math/tex">\frac{\partial J(\Theta)}{\partial \Theta_0}</script> to get this part right.</p>
<p>When we are at the bottom of the hill at point (c) what is the value of the slope? See! It all works out. In short, we should move in the opposite direction of the derivative</p>
<p><img alt="Another image of gradient descent showing initial condition and trajectory across iterations towards the minimum. There is negative in location and positive in location." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/0f/35/hero_0f35d897-f04b-4e86-b927-060b9ad0affc.png" srcset="https://ugc.futurelearn.com/uploads/assets/0f/35/small_hero_0f35d897-f04b-4e86-b927-060b9ad0affc.png 320w, https://ugc.futurelearn.com/uploads/assets/0f/35/hero_0f35d897-f04b-4e86-b927-060b9ad0affc.png 648w, https://ugc.futurelearn.com/uploads/assets/0f/35/large_hero_0f35d897-f04b-4e86-b927-060b9ad0affc.png 729w, https://ugc.futurelearn.com/uploads/assets/0f/35/large_hero_0f35d897-f04b-4e86-b927-060b9ad0affc.png 2x"/></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.6&emsp;Gradient descent in more than one dimension</h2><div class="u-typography-bold-intro">
<p>We will now consider gradient descent in more than one dimension.</p>
<p>If we consider more than one dimension we must think about the idea of a gradient vector as per Figure 1 below.</p>
<p><img alt="Image of a Gradient Descent in more than 1 dimension diagram" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/6b/89/hero_6b893281-e201-47f7-8262-2bbc6f2eb764.png" srcset="https://ugc.futurelearn.com/uploads/assets/6b/89/small_hero_6b893281-e201-47f7-8262-2bbc6f2eb764.png 320w, https://ugc.futurelearn.com/uploads/assets/6b/89/hero_6b893281-e201-47f7-8262-2bbc6f2eb764.png 648w, https://ugc.futurelearn.com/uploads/assets/6b/89/large_hero_6b893281-e201-47f7-8262-2bbc6f2eb764.png 729w, https://ugc.futurelearn.com/uploads/assets/6b/89/large_hero_6b893281-e201-47f7-8262-2bbc6f2eb764.png 2x"/>
<sub><strong>Figure 1: Gradient Descent in more than 1 dimension.</strong><sub></sub></sub></p>
<p>The gradient vector can be considered as:</p>
<script type="math/tex; mode=display">\nabla J(\Theta) = \begin{bmatrix} 
\frac{\partial J(\Theta)}{\partial \Theta_0}  \\

\frac{\partial J(\Theta)}{\partial \Theta_1} \\
...   \\
\frac{\partial J(\Theta)}{\partial \Theta_N}
 
\end{bmatrix}</script>
<p>This gives the vector the direction of the steepest descent for the function. Its entries are partial derivatives of <script type="math/tex">J(\Theta)</script> with respect to each weight.</p>
<p>From each point, we take the gradient (which is a vector) and go in the opposite direction.</p>
<p>We repeat this on each iteration as shown in Figure 2 until we reach the minimum.</p>
<p><img alt="Alt text" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/e4/00/hero_e40016c1-4a33-44dd-bab8-e573f302b85e.png" srcset="https://ugc.futurelearn.com/uploads/assets/e4/00/small_hero_e40016c1-4a33-44dd-bab8-e573f302b85e.png 320w, https://ugc.futurelearn.com/uploads/assets/e4/00/hero_e40016c1-4a33-44dd-bab8-e573f302b85e.png 648w, https://ugc.futurelearn.com/uploads/assets/e4/00/large_hero_e40016c1-4a33-44dd-bab8-e573f302b85e.png 729w, https://ugc.futurelearn.com/uploads/assets/e4/00/large_hero_e40016c1-4a33-44dd-bab8-e573f302b85e.png 2x"/>
<sub><strong>Figure 2: Three iterations of the gradient descent algorithm.</strong><sub></sub></sub></p>
<p>What this means in terms of adjusting the weight vector is as follows:</p>
<p>We take our starting weight vector <script type="math/tex">% <![CDATA[
\Theta_{old}=< \Theta_0, \Theta_1 > %]]></script> and update it.</p>
<script type="math/tex; mode=display">\Theta_{new} = \Theta_{old} + \alpha(-\nabla J(\Theta))</script>
<p>We step along some proportion of the vector pointing downhill as illustrated in Figure 3 below: ( <script type="math/tex">\alpha=1</script>).</p>
<p><img alt="Alt text" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/a4/71/hero_a4710098-5e90-46d5-9a0c-51581ebe9b04.png" srcset="https://ugc.futurelearn.com/uploads/assets/a4/71/small_hero_a4710098-5e90-46d5-9a0c-51581ebe9b04.png 320w, https://ugc.futurelearn.com/uploads/assets/a4/71/hero_a4710098-5e90-46d5-9a0c-51581ebe9b04.png 648w, https://ugc.futurelearn.com/uploads/assets/a4/71/large_hero_a4710098-5e90-46d5-9a0c-51581ebe9b04.png 729w, https://ugc.futurelearn.com/uploads/assets/a4/71/large_hero_a4710098-5e90-46d5-9a0c-51581ebe9b04.png 2x"/>
<sub><strong>Figure 3: Updating the weight vector according to the gradient vector.</strong><sub></sub></sub></p>
<p>At this point, the intuition of how this works should be clear. Let us get specific with the algorithm.</p>
<p>We update for every component of the weight vector as follows:</p>
<p><script type="math/tex">\Theta_j \leftarrow \Theta_j- \alpha \frac{\partial J(\Theta)}{\partial \Theta_j}</script>
i.e. we do this for <script type="math/tex">j=0,….,N</script></p>
<p>Now the missing piece is the partial derivative term. We calculate this as follows:</p>
<script type="math/tex; mode=display">\frac{\partial J(\Theta)} {\partial \Theta_j} 
= \frac{\partial}{\partial \Theta_j} \frac{1}{2} (h_\Theta (x) - y)^2
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;= 2.\frac{1}{2}(h_\Theta(x)-y).\frac{\partial}{\partial\Theta_j}(h_\Theta(x)-y)
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;=(h_\Theta(x)-y).\frac{\partial}{\partial\Theta_j}(\sum_{i=0}^n\Theta_ix_i - y)



=(h_\Theta(x)-y)x_j</script>
<p>This is called the Widrow-Hoff learning rule or the LMS update rule, and it implements gradient descent for us. There are two ways we can integrate this update procedure into an algorithm based on how we use the information from each training example. In <strong>batch gradient descent</strong> we go through all the training examples before updating the weight vector. In <strong>stochastic gradient descent</strong> we update the weight vector after every training example.</p>
<p>The <strong>batch descent algorithm</strong> is as follows:</p>
<p>Repeat until convergence {</p>
<p><script type="math/tex">\Theta_j :</script>= <script type="math/tex">\Theta_j + \alpha \sum_{i=1} ^{m} (y^i - h_\Theta (x^i)) x_j^i</script> 
(for every <script type="math/tex">j</script>)</p>
<p>}</p>
<p>While the <strong>stochastic gradient descent</strong> algorithm is as follows:</p>
<p>Loop {</p>
<p>for <script type="math/tex">i = 1</script> to <script type="math/tex">m</script> , {</p>
<p><script type="math/tex">\Theta_j</script> := <script type="math/tex">\Theta_j + \alpha (y^i - h_\Theta (x^i)) x_j^i</script> (for every <script type="math/tex">j</script>).</p>
<p><script type="math/tex">\;\;\;\;\;\;\;\;</script>}</p>
<p>}</p>
<p><strong>Note:</strong> This means we make progress towards the minimum with every training example. If <script type="math/tex">M</script> is large, i.e. we have many training examples. This is a good approach, as we can get close to optimal weights much more quickly than with batch descent.</p>
<p>At this point, you should have a firm idea regarding how gradient descent can allow you to choose a well-fitting model for linear regression.</p>
<p>In future weeks you will have an opportunity to experiment with these methods. For the impatient among you why not jump into Kaggle and explore notebooks which already exist on the platform demonstrating the use of linear regression for the Ames dataset or indeed any other dataset that interests you.</p>
<p>We now proceed to some extensions.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.7&emsp;Modelling Non Linear Relationships</h2><div class="u-typography-bold-intro">
<p>Let’s look again at our SalesPrice versus floor area data.</p>
<p>We had fitted it with a straight line but scrutinising it you might think something like a polynomial might be a better fit as shown in Figure 1.</p>
<p><img alt="Graph with Vertical axis X from 0 to 70,000 and Y-axis from 1600 to 2800 - 10 sale prices - green curved line going starting at 10000 and ending 2700" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/dd/7a/hero_dd7a3ada-4ddf-4df1-b78d-d505bdb7aba2.png" srcset="https://ugc.futurelearn.com/uploads/assets/dd/7a/small_hero_dd7a3ada-4ddf-4df1-b78d-d505bdb7aba2.png 320w, https://ugc.futurelearn.com/uploads/assets/dd/7a/hero_dd7a3ada-4ddf-4df1-b78d-d505bdb7aba2.png 648w, https://ugc.futurelearn.com/uploads/assets/dd/7a/large_hero_dd7a3ada-4ddf-4df1-b78d-d505bdb7aba2.png 729w, https://ugc.futurelearn.com/uploads/assets/dd/7a/large_hero_dd7a3ada-4ddf-4df1-b78d-d505bdb7aba2.png 2x"/>
<sub><strong>Figure 1: A better non-linear model fit to our data.</strong><sub></sub></sub></p>
<p>But wait! We are talking about linear regression, so how could we adopt such a model fit? The answer is to transform the data to yield new features. The nonlinearity is captured in the feature transformation preserving our linear relationship which now operates on the new features. In other words, for our example above we might go with:</p>
<script type="math/tex; mode=display">h_{\Theta}(x) = \Theta_0 + \Theta_1 x + \Theta_2 x^2</script>
<p>In the equation above the “2” exponentiates the variable x. It is not an indexing term.
Note our hypothesis is still linear, i.e. it is of the form:</p>
<script type="math/tex; mode=display">h_{\Theta}(z) = \sum_{j=0}^{K} \Theta_j z_j = \Theta^T z</script>
<p>Where <script type="math/tex">z</script> = <script type="math/tex">\begin{bmatrix}
    1 \\
    x \\   
    x^2
\end{bmatrix}</script>  where <script type="math/tex">x</script> is our <script type="math/tex">FloorArea</script>.</p>
<p>So now our hypothesis is linear in new features but non-linear in the raw data features. However, we still have a convex optimization problem and all the ideas we have seen can be applied here to find the optimal parameters.</p>
<p><strong>Regularization</strong></p>
<p>It is tempting, given the value we saw in deriving new non-linear features, to create a better fit with our training data to do so. However, when do we stop? How about if we add further new non-linear transformations of the original feature vector to yield Figure 2?</p>
<p><img alt="Graph with Vertical axis X from 0 to 700,000 and Y-axis from 1600 to 2800 - 10 sale prices - green line climbing upwards and peaking at 62000 through graph starting at 0 on the X-axis climbing to 70000 than on the Y-axis 27000" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/bb/29/hero_bb29b3db-11ac-4edb-bdc4-53d368a769ae.png" srcset="https://ugc.futurelearn.com/uploads/assets/bb/29/small_hero_bb29b3db-11ac-4edb-bdc4-53d368a769ae.png 320w, https://ugc.futurelearn.com/uploads/assets/bb/29/hero_bb29b3db-11ac-4edb-bdc4-53d368a769ae.png 648w, https://ugc.futurelearn.com/uploads/assets/bb/29/large_hero_bb29b3db-11ac-4edb-bdc4-53d368a769ae.png 729w, https://ugc.futurelearn.com/uploads/assets/bb/29/large_hero_bb29b3db-11ac-4edb-bdc4-53d368a769ae.png 2x"/>
<sub><strong>Figure 2: A model fit with several additional non linear features.</strong><sub></sub></sub></p>
<p>This might be a good fit, but it might not be. It might be overfitting the data. We will look at this in detail later in this course but for the moment consider it possible that we could fit our data too well, such that our model does not perform on future data, i.e. data it has not seen before. For this reason, some training data is always withheld as validation data so that an estimate of performance on unseen data can be made.<br/>
To avoid overfitting it is clearly a good idea to go with a smaller number of features so long as acceptable performance is obtained.</p>
<p>Another commonly used approach is regularization in which we keep the magnitude of the parameters small – the intuition behind this is not so obvious but in short smaller parameters reduce the magnitude of swings in the model fit.  We can explicitly prevent large values of the parameters through inclusion of a penalisation for <script type="math/tex">\mid \mid \Theta \mid \mid ^2 _2</script> in our optimization algorithm. In the case of least squares this would look like the following:</p>
<script type="math/tex; mode=display">\min_\Theta\lambda \left \| \Theta \right \|_2 ^2 + \left \| X \Theta - y  \right \|_2^2</script>
<script type="math/tex; mode=display">\Rightarrow \nabla _\Theta (\left \| \Theta \right \|_2^2  + \left \| X \Theta - y  \right \|^2_2) = 2\Theta + 2X^T(X \Theta - y)</script>
<script type="math/tex; mode=display">\Rightarrow \Theta^* = (X^TX + \lambda I)^{-1} X^T y</script>
<p>We will look at this in terms of our gradient descent algorithm for regression during our practical week when we will look at both Ridge regression and Lasso regression.  Until then we will move on to classification using Logistic Regression.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>1.8&emsp;Review of Topic 1</h2><div class="u-typography-bold-intro">
<p>Congratulations on completing Topic 1.</p>
<p>In this topic, you have learned some useful ideas with respect to the use of linear models for regression purposes.</p>
<p>The idea of a loss function is a key aspect of what you should have learned. Building on this, you should have learned the importance of optimization of the model based on minimizing loss. This optimization is achieved through finding the optimal set of weights which locate the minimum of our loss functions.  This culminated in an introduction to a very useful approach in machine learning for optimization called gradient descent.</p>
<p>We looked at a few variations on the gradient descent approach. We closed off the topic by examining an extension of linear regression to non-linear cases. We took a brief look at regularization which can help prevent something called overfitting which we will examine in later courses.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p style="page-break-before: always"><h2>2.1&emsp;Welcome to Topic 2</h2><div class="u-typography-bold-intro">
<p>Hello everybody and welcome to Topic 2, Logistic Regression.</p>
<p>In this topic we will extend the thinking we did around linear regression and extend it to classification.</p>
<p>In particular, we will examine an approach called logistic regression which, despite its name, is a classification method.</p>
<p>We will think more deeply than previously about the hypothesis concept and how this influences the decision boundaries which emerge when used in the context of classification.</p>
<p>We extend the idea of a cost function to embrace the nonlinear nature of the prediction task and examine in detail how gradient descent can again be used to provide a solution to the model fitting challenge.</p>
<p>This topic concludes with an introduction to multi-class classification and further exposure to the idea of regularization for more robust model development.</p>
<p><img alt="Statement of funding from Skillnet Ireland stating that this course has been grant-aided by Skillnet Ireland" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/14/0b/hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/14/0b/small_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 320w, https://ugc.futurelearn.com/uploads/assets/14/0b/hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 648w, https://ugc.futurelearn.com/uploads/assets/14/0b/large_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 729w, https://ugc.futurelearn.com/uploads/assets/14/0b/large_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 2x"/></p>
<div class="video_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.2&emsp;Progression from Linear Regression</h2><div class="u-typography-bold-intro">
<p>In the previous topic, we learned about Linear Regression.</p>
<p>We now introduce Logistic Regression by examining how we can adapt the error-based learning approach of Linear Regression to sort the classification problems which we have dealt with previously as shown below.</p>
<p><strong>Spam/ham</strong><br/>
<strong>Online transactions - Fradulent/Genuine</strong><br/>
<strong>Tumour : Malignant/Benign?</strong></p>
<p>Starting off, we are going to look at binary classification i.e. our output has only two values  <script type="math/tex">y \in { 0,1 }</script>, where 0 might be spam and 1 might be ham for our problem.</p>
<p><strong>So how do we develop a classification algorithm from what we have seen?</strong></p>
<p>Let us take our single feature linear regression example and convert it into a classification problem which can be seen below.</p>
<p><img alt="scatter plot of the SIZE and RENTAL PRICE features from the office rentals dataset" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/db/bd/hero_dbbdf5a1-bf8a-469e-8020-8b2f46b0e7e5.png" srcset="https://ugc.futurelearn.com/uploads/assets/db/bd/small_hero_dbbdf5a1-bf8a-469e-8020-8b2f46b0e7e5.png 320w, https://ugc.futurelearn.com/uploads/assets/db/bd/hero_dbbdf5a1-bf8a-469e-8020-8b2f46b0e7e5.png 648w, https://ugc.futurelearn.com/uploads/assets/db/bd/large_hero_dbbdf5a1-bf8a-469e-8020-8b2f46b0e7e5.png 729w, https://ugc.futurelearn.com/uploads/assets/db/bd/large_hero_dbbdf5a1-bf8a-469e-8020-8b2f46b0e7e5.png 2x"/>
<sub><strong>A scatter plot of the Size and Rental Price features from the office rentals data set</strong></sub></p>
<p>So instead of predicting “Rental Price” we are classifying the transactions as saying, “short term lease” vs “long term lease”.</p>
<p>So the plot becomes:</p>
<p><img alt='Linear Regression diagram classifying the transactions as say short term lease vs "long term lease"' sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/0b/0b/hero_0b0bbe61-f8a4-4284-8878-9570f3631e2d.png" srcset="https://ugc.futurelearn.com/uploads/assets/0b/0b/small_hero_0b0bbe61-f8a4-4284-8878-9570f3631e2d.png 320w, https://ugc.futurelearn.com/uploads/assets/0b/0b/hero_0b0bbe61-f8a4-4284-8878-9570f3631e2d.png 648w, https://ugc.futurelearn.com/uploads/assets/0b/0b/large_hero_0b0bbe61-f8a4-4284-8878-9570f3631e2d.png 729w, https://ugc.futurelearn.com/uploads/assets/0b/0b/large_hero_0b0bbe61-f8a4-4284-8878-9570f3631e2d.png 2x"/></p>
<p>Let’s apply Linear Regression to this.  We fit a straight line to this.</p>
<script type="math/tex; mode=display">h_\Theta(x) = \Theta^T x</script>
<p>For historical reasons, h is often called a hypothesis. Our hypothesis was that we had a linear relationship when we were doing linear regression.</p>
<p><img alt="A second linear regression diagram featuring long term lease and size" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/02/85/hero_02850a32-12d8-4642-b89a-a76c97bc8a87.png" srcset="https://ugc.futurelearn.com/uploads/assets/02/85/small_hero_02850a32-12d8-4642-b89a-a76c97bc8a87.png 320w, https://ugc.futurelearn.com/uploads/assets/02/85/hero_02850a32-12d8-4642-b89a-a76c97bc8a87.png 648w, https://ugc.futurelearn.com/uploads/assets/02/85/large_hero_02850a32-12d8-4642-b89a-a76c97bc8a87.png 729w, https://ugc.futurelearn.com/uploads/assets/02/85/large_hero_02850a32-12d8-4642-b89a-a76c97bc8a87.png 2x"/></p>
<p>So we have our linear regression model above, how is that a prediction since it produces continuous numbers from -infinity to + infinity?</p>
<p>We want our output <script type="math/tex">y \in</script> { <script type="math/tex">0,1</script>}. i.e. only two possibilities - not infinitely many.</p>
<p>One idea is that we can threshold the output. So we might say:</p>
<p>If <script type="math/tex">h_\Theta(x) \geq 0.5</script> predict that <script type="math/tex">y=1</script></p>
<p>and if <script type="math/tex">h_\Theta(x) \leq 0.5</script> predict that <script type="math/tex">y=0</script></p>
<p><img alt="A third linear diagram featuring Yes and No results" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/bb/cc/hero_bbcc5f8d-477f-481b-ab66-2e8f1692860d.png" srcset="https://ugc.futurelearn.com/uploads/assets/bb/cc/small_hero_bbcc5f8d-477f-481b-ab66-2e8f1692860d.png 320w, https://ugc.futurelearn.com/uploads/assets/bb/cc/hero_bbcc5f8d-477f-481b-ab66-2e8f1692860d.png 648w, https://ugc.futurelearn.com/uploads/assets/bb/cc/large_hero_bbcc5f8d-477f-481b-ab66-2e8f1692860d.png 729w, https://ugc.futurelearn.com/uploads/assets/bb/cc/large_hero_bbcc5f8d-477f-481b-ab66-2e8f1692860d.png 2x"/></p>
<p>So everything to the right of the vertical blue line is “Yes” and everything to the left is “No”.</p>
<p>Let’s say we get a new training example far to the right as shown below.</p>
<p><img alt="4th Linear diagram has a linear regression fit" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/66/c9/hero_66c9b158-7c84-4e90-9f4c-774bb8d8e3de.png" srcset="https://ugc.futurelearn.com/uploads/assets/66/c9/small_hero_66c9b158-7c84-4e90-9f4c-774bb8d8e3de.png 320w, https://ugc.futurelearn.com/uploads/assets/66/c9/hero_66c9b158-7c84-4e90-9f4c-774bb8d8e3de.png 648w, https://ugc.futurelearn.com/uploads/assets/66/c9/large_hero_66c9b158-7c84-4e90-9f4c-774bb8d8e3de.png 729w, https://ugc.futurelearn.com/uploads/assets/66/c9/large_hero_66c9b158-7c84-4e90-9f4c-774bb8d8e3de.png 2x"/></p>
<p>We now retrain and have new linear regression fit. If we threshold our hypothesis at 0.5 now this has worked out worse!</p>
<p><img alt="Logistic regression - a classification algorithm diagram" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/0a/60/hero_0a60cecc-0bc5-4755-b1fa-3558ea94a8e4.png" srcset="https://ugc.futurelearn.com/uploads/assets/0a/60/small_hero_0a60cecc-0bc5-4755-b1fa-3558ea94a8e4.png 320w, https://ugc.futurelearn.com/uploads/assets/0a/60/hero_0a60cecc-0bc5-4755-b1fa-3558ea94a8e4.png 648w, https://ugc.futurelearn.com/uploads/assets/0a/60/large_hero_0a60cecc-0bc5-4755-b1fa-3558ea94a8e4.png 729w, https://ugc.futurelearn.com/uploads/assets/0a/60/large_hero_0a60cecc-0bc5-4755-b1fa-3558ea94a8e4.png 2x"/></p>
<p>Just by adding this example over to the right caused our LR to shift its fit and give worse model despite the data point added being a good quality data point, i.e. not an outlier. So much then for our hack of linear regression for classification.</p>
<p>So you may strike it lucky with your fit and data or indeed and most likely it won’t work well. Can we do something better?</p>
<p>While our classification and indeed all our training data has <script type="math/tex">y = 0</script> or <script type="math/tex">y= 1</script> our hypothesis <script type="math/tex">h_\Theta(x)</script> can be<script type="math/tex">>1</script> or indeed even <script type="math/tex">% <![CDATA[
< 0 %]]></script> which is odd. We will develop an algorithm called Logistic Regression whose output is always between <script type="math/tex">0</script> and <script type="math/tex">1</script> <br/>
<script type="math/tex">0 \leq h_\Theta(x) \leq 1</script></p>
<p><strong>Note:</strong> Logistic regression is a classification algorithm, not a regression algorithm.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.3&emsp;Decision Boundaries</h2><div class="u-typography-bold-intro">
<p>In this step, we continue on from our previous step and explore Non-Linear Decision Boundaries.</p>
<p>Let’s look at the hypothesis representation below.</p>
<p>We want our classifier to have output between <script type="math/tex">0</script> and <script type="math/tex">1</script> therefore, we want <script type="math/tex">0 \leq h_\Theta(x) \leq 1</script>.</p>
<p>For linear regression we had <script type="math/tex">h_\Theta(x) = \Theta^T x</script>.</p>
<p>Now we are going to modify this a bit.</p>
<p>We will take the <script type="math/tex">\Theta^T x</script> part and distort it a bit to flatten it out above <script type="math/tex">1</script> and below <script type="math/tex">0</script>.</p>
<p>So lets say <script type="math/tex">h_\Theta(x) = g(\Theta ^T x)</script>.</p>
<p>Then, have <script type="math/tex">g(u)</script> = <script type="math/tex">\frac{1}{1+ e^{-u}}</script>. This is called as sigmoidal function or logistic function. So, we can now say <script type="math/tex">h_\Theta (x) = \frac{1}{1 + e^{-\Theta^Tx}}</script>.</p>
<p>From the figure below we can see that it’s nice and linear around u=0 and then it squashes the extreme values. It’s a sort of ”squashing function”.</p>
<p>See that the output asymptotically approaches either 1 or 0 but never exceeds.</p>
<script type="math/tex; mode=display">h_\Theta(u) =g(u) = \frac{1}{1 + e^{-u}}</script>
<p><img alt="A sigmoidal curve representing logistic regression" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/e2/c3/hero_e2c3250e-1533-4a28-9b9e-db043fefd8aa.png" srcset="https://ugc.futurelearn.com/uploads/assets/e2/c3/small_hero_e2c3250e-1533-4a28-9b9e-db043fefd8aa.png 320w, https://ugc.futurelearn.com/uploads/assets/e2/c3/hero_e2c3250e-1533-4a28-9b9e-db043fefd8aa.png 648w, https://ugc.futurelearn.com/uploads/assets/e2/c3/large_hero_e2c3250e-1533-4a28-9b9e-db043fefd8aa.png 729w, https://ugc.futurelearn.com/uploads/assets/e2/c3/large_hero_e2c3250e-1533-4a28-9b9e-db043fefd8aa.png 2x"/></p>
<p><strong>Interpretation of hypothesis output</strong></p>
<p><script type="math/tex">h_\Theta(x)</script> = estimated probability that <script type="math/tex">y=1</script> on input <script type="math/tex">x</script></p>
<p>Example : If  <script type="math/tex">x</script> = <script type="math/tex">\begin{bmatrix}
x_0\\
x_1 
\end{bmatrix}</script>
   = <script type="math/tex">\begin{bmatrix}1\\Size \end{bmatrix}</script>  and <script type="math/tex">h_\Theta(x)</script> = <script type="math/tex">0.7</script></p>
<p>Then, the property has a 70% chance of being long term leased. That is how we are deciding to interpret this hypothesis.</p>
<p>In other words, <script type="math/tex">h_\Theta(x) = p(y=1 \mid x;\Theta)</script></p>
<p>“Probability that <script type="math/tex">y=1</script>, given the <script type="math/tex">x</script> shown, parametrized by theta”</p>
<p>As the output y can be either a <script type="math/tex">0</script> or <script type="math/tex">1</script> if <script type="math/tex">h_\Theta(x) = p(y=1 \mid x;\Theta)</script></p>
<p>Then we can say:</p>
<p><script type="math/tex">p(y=0 \mid x; \Theta)</script> = <script type="math/tex">1 -p(y=1 \mid x;\Theta)</script></p>
<p>This is because it must be either a <script type="math/tex">0</script> or <script type="math/tex">1</script>, i.e.</p>
<script type="math/tex; mode=display">p(y=1 \mid x;\Theta ) + p(y=0 \mid x;\Theta)=1</script>
<p>The Decision Boundary which arises is:</p>
<script type="math/tex; mode=display">h_\Theta(x) = g(\Theta^T x)</script>
<script type="math/tex; mode=display">= p(y = 1 \mid x;\Theta )</script>
<script type="math/tex; mode=display">g(u) = \frac{1}{1+e^-u}</script>
<p><img alt="A sigmoidal curve showing the interpretation of hypothesis when  y = 1 and $$h_\Theta(x) &gt; 0.5$$" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/e2/c3/hero_e2c3250e-1533-4a28-9b9e-db043fefd8aa.png" srcset="https://ugc.futurelearn.com/uploads/assets/e2/c3/small_hero_e2c3250e-1533-4a28-9b9e-db043fefd8aa.png 320w, https://ugc.futurelearn.com/uploads/assets/e2/c3/hero_e2c3250e-1533-4a28-9b9e-db043fefd8aa.png 648w, https://ugc.futurelearn.com/uploads/assets/e2/c3/large_hero_e2c3250e-1533-4a28-9b9e-db043fefd8aa.png 729w, https://ugc.futurelearn.com/uploads/assets/e2/c3/large_hero_e2c3250e-1533-4a28-9b9e-db043fefd8aa.png 2x"/></p>
<p>Suppose we now predict that <script type="math/tex">y=1</script> if <script type="math/tex">h_\Theta (x) \geq 0.5</script> and predict <script type="math/tex">y</script> =<script type="math/tex">0</script> if <script type="math/tex">% <![CDATA[
h_\Theta(x) < 0.5 %]]></script>.</p>
<p>So when does this happen? i.e <script type="math/tex">y=1</script> if <script type="math/tex">h_\Theta (x) \geq 0.5 \:</script></p>
<p><script type="math/tex">y=0</script> if <script type="math/tex">h_\Theta(x) \leq 0.5</script>?</p>
<p>Well, if <script type="math/tex">h_\Theta(x) \geq 0.5</script> when <script type="math/tex">u \geq 0</script>.</p>
<p><img alt="An image showing the cluster of items to be classified without a decision boundary" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/bd/03/hero_bd030b3b-2658-449f-b509-8424eed0f9f6.png" srcset="https://ugc.futurelearn.com/uploads/assets/bd/03/small_hero_bd030b3b-2658-449f-b509-8424eed0f9f6.png 320w, https://ugc.futurelearn.com/uploads/assets/bd/03/hero_bd030b3b-2658-449f-b509-8424eed0f9f6.png 648w, https://ugc.futurelearn.com/uploads/assets/bd/03/large_hero_bd030b3b-2658-449f-b509-8424eed0f9f6.png 729w, https://ugc.futurelearn.com/uploads/assets/bd/03/large_hero_bd030b3b-2658-449f-b509-8424eed0f9f6.png 2x"/></p>
<p>and predict <script type="math/tex">y=0</script> if <script type="math/tex">% <![CDATA[
h_\Theta(x) < 0.5 %]]></script> when <script type="math/tex">% <![CDATA[
u < 0 %]]></script>.</p>
<p><img alt="An image with a decision boundary which separates the crosses and the circles with a decision boundary" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/92/79/hero_9279578b-c3a1-4fa2-93f6-1452606bb643.png" srcset="https://ugc.futurelearn.com/uploads/assets/92/79/small_hero_9279578b-c3a1-4fa2-93f6-1452606bb643.png 320w, https://ugc.futurelearn.com/uploads/assets/92/79/hero_9279578b-c3a1-4fa2-93f6-1452606bb643.png 648w, https://ugc.futurelearn.com/uploads/assets/92/79/large_hero_9279578b-c3a1-4fa2-93f6-1452606bb643.png 729w, https://ugc.futurelearn.com/uploads/assets/92/79/large_hero_9279578b-c3a1-4fa2-93f6-1452606bb643.png 2x"/></p>
<p>In our case we have  <script type="math/tex">u = \Theta ^T x</script></p>
<p>So we say that <script type="math/tex">y=1</script> when <script type="math/tex">\Theta^T x \geq 0</script></p>
<p><script type="math/tex">y=0</script> when <script type="math/tex">% <![CDATA[
\Theta^Tx < 0 %]]></script> .</p>
<p>We can draw a decision boundary based on this realization.</p>
<p>Let’s suppose we have a training set like the Figure below.</p>
<p><img alt="An image showing elements to be classified with non-linear decision boundaries." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/a5/33/hero_a53395ec-4ca0-44ca-a0c0-b49eec6614cc.png" srcset="https://ugc.futurelearn.com/uploads/assets/a5/33/small_hero_a53395ec-4ca0-44ca-a0c0-b49eec6614cc.png 320w, https://ugc.futurelearn.com/uploads/assets/a5/33/hero_a53395ec-4ca0-44ca-a0c0-b49eec6614cc.png 648w, https://ugc.futurelearn.com/uploads/assets/a5/33/large_hero_a53395ec-4ca0-44ca-a0c0-b49eec6614cc.png 729w, https://ugc.futurelearn.com/uploads/assets/a5/33/large_hero_a53395ec-4ca0-44ca-a0c0-b49eec6614cc.png 2x"/></p>
<p>Our hypothesis is as follows:</p>
<script type="math/tex; mode=display">h_\Theta(x) = g(\Theta_0 + \Theta_1x_1 + \Theta_2x_2)</script>
<p>We have not spoken about how to fit parameters yet but we will do that later.</p>
<p>Lets assume magically we choose the values as follows:</p>
<p><script type="math/tex">x = \begin{bmatrix}1\\x_1\\x_2\end{bmatrix}</script> and <script type="math/tex">\Theta = \begin{bmatrix}-3\\1\\1\end{bmatrix}</script></p>
<p>We have decided the vector of weights theta without explanation for now.</p>
<p>We have established that <script type="math/tex">y=1</script> when <script type="math/tex">\Theta^T x ≥0</script> and <script type="math/tex">y=0</script> when <script type="math/tex">% <![CDATA[
\Theta^T x < 0 %]]></script></p>
<p>Therefore <script type="math/tex">y=1</script> if <script type="math/tex">-3+x_1+x_2≥0</script> which we rewrite as <script type="math/tex">x_1+x_2≥3</script></p>
<p>This results in:</p>
<p><img alt="An image showing non-linear decision boundaries which have no boundary between the elements to be classified." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/8a/e2/hero_8ae246f0-8714-4a01-b8b1-6409d32965fa.png" srcset="https://ugc.futurelearn.com/uploads/assets/8a/e2/small_hero_8ae246f0-8714-4a01-b8b1-6409d32965fa.png 320w, https://ugc.futurelearn.com/uploads/assets/8a/e2/hero_8ae246f0-8714-4a01-b8b1-6409d32965fa.png 648w, https://ugc.futurelearn.com/uploads/assets/8a/e2/large_hero_8ae246f0-8714-4a01-b8b1-6409d32965fa.png 729w, https://ugc.futurelearn.com/uploads/assets/8a/e2/large_hero_8ae246f0-8714-4a01-b8b1-6409d32965fa.png 2x"/></p>
<p>The decision boundary is: <script type="math/tex">x_1 + x_2 = 3</script></p>
<p>This is the equation for decision boundary, i.e. points for which  <script type="math/tex">h_\Theta(x) = 0.5</script>.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.4&emsp;Non Linear Decision Boundaries</h2><div class="u-typography-bold-intro">
<p>We now look at non linear decision boundaries. Lets start by looking at the Figure below.</p>
<p>Given a training set like this how can we get logistic regression to work here? Well we do the same thing we did for linear regression when we added basis functions, remember our polynomial approach for rainfall vs grass growth?</p>
<p>So we do this.</p>
<p><img alt="An image showing non-linear decision boundaries which have no boundary between the elements to be classified." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/b9/54/hero_b954785a-5d1e-4d7b-a7f7-7363cb14ee0a.png" srcset="https://ugc.futurelearn.com/uploads/assets/b9/54/small_hero_b954785a-5d1e-4d7b-a7f7-7363cb14ee0a.png 320w, https://ugc.futurelearn.com/uploads/assets/b9/54/hero_b954785a-5d1e-4d7b-a7f7-7363cb14ee0a.png 648w, https://ugc.futurelearn.com/uploads/assets/b9/54/large_hero_b954785a-5d1e-4d7b-a7f7-7363cb14ee0a.png 729w, https://ugc.futurelearn.com/uploads/assets/b9/54/large_hero_b954785a-5d1e-4d7b-a7f7-7363cb14ee0a.png 2x"/></p>
<script type="math/tex; mode=display">h_θ (x)=g(θ_0+θ_1 x_1+θ_2 x_2+θ_3 x_1^2+θ_4 x_2^2 )</script>
<p>So now we have added some higher-order terms.</p>
<p>Now let’s assume that magically we pick some weights.</p>
<p><script type="math/tex">x = \begin{bmatrix}1 \\x_1\\x_2\\x_1^2\\x_2^2\end{bmatrix}</script>  and <script type="math/tex">\Theta = \begin{bmatrix}1\\0\\0\\1\\1\end{bmatrix}</script></p>
<p>So here we are now predicting <script type="math/tex">y=1</script> if <script type="math/tex">-1+x_1^2+ x_2^2≥0</script> which is clearer as <script type="math/tex">x_1^2+ x_2^2≥1</script>.</p>
<p>The decision boundary is the equation of a circle of radius 1, i.e. <script type="math/tex">x_1^2+ x_2^2=1</script>.</p>
<p><img alt="Decison Boundary diagram" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/51/f0/hero_51f081d5-7907-4014-8db5-79121ba4de16.png" srcset="https://ugc.futurelearn.com/uploads/assets/51/f0/small_hero_51f081d5-7907-4014-8db5-79121ba4de16.png 320w, https://ugc.futurelearn.com/uploads/assets/51/f0/hero_51f081d5-7907-4014-8db5-79121ba4de16.png 648w, https://ugc.futurelearn.com/uploads/assets/51/f0/large_hero_51f081d5-7907-4014-8db5-79121ba4de16.png 729w, https://ugc.futurelearn.com/uploads/assets/51/f0/large_hero_51f081d5-7907-4014-8db5-79121ba4de16.png 2x"/></p>
<p>Bear in mind that the decision boundary is a function of the hypothesis and its parameters (<script type="math/tex">\Theta</script>), not the data. The data might (indeed will) be used to choose <script type="math/tex">\Theta</script> though. Through the use of more complex basis functions, you can come up with some very complicated decision boundaries.</p>
<p><img alt="An image showing the decision boundary which has the equation of the circle of radius 1" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/8c/7e/hero_8c7ef078-838a-437f-a4e1-41f318a6e677.png" srcset="https://ugc.futurelearn.com/uploads/assets/8c/7e/small_hero_8c7ef078-838a-437f-a4e1-41f318a6e677.png 320w, https://ugc.futurelearn.com/uploads/assets/8c/7e/hero_8c7ef078-838a-437f-a4e1-41f318a6e677.png 648w, https://ugc.futurelearn.com/uploads/assets/8c/7e/large_hero_8c7ef078-838a-437f-a4e1-41f318a6e677.png 729w, https://ugc.futurelearn.com/uploads/assets/8c/7e/large_hero_8c7ef078-838a-437f-a4e1-41f318a6e677.png 2x"/></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.5&emsp;Exploring the Cost Function in Logistic Regression</h2><div class="u-typography-bold-intro">
<p>We are now going to explore the Cost Function.</p>
<p>Training set: {(<script type="math/tex">x^{(1)} ,y^{(1)}),(x^{(2)},y^{(2)} ),…, (x^{(m)},y^{(m)})</script>}</p>
<p>We have <script type="math/tex">m</script>  examples <script type="math/tex">x</script>= <script type="math/tex">\begin{bmatrix}x_0\\x_1\\ …\\x_n\end{bmatrix}</script><br/>
and <script type="math/tex">x_0=1</script>,<script type="math/tex">y∈</script>{<script type="math/tex">0,1</script>}</p>
<p>Given this training set, how do we choose the parameters <script type="math/tex">\Theta</script> below?</p>
<script type="math/tex; mode=display">h_\Theta (x)= \frac{1}{1 + e^{-\Theta^Tx}}</script>
<p>Recall that in Linear Regression we had:</p>
<script type="math/tex; mode=display">J(\Theta) = \frac{1}{m} \sum_{i=1}^{m} \frac{1}{2} (h_\Theta(x^{(i)}) - y^{(i)})^2</script>
<p>Compare the notation I used here to what I had in Linear Regression  - the only real difference is that I averaged <script type="math/tex">1/m</script> the error.</p>
<p>We can rewrite this as:</p>
<p><script type="math/tex">J(\Theta)</script> = <script type="math/tex">\frac{1}{m} \sum_{i=1}^m (Costf)</script> where <script type="math/tex">Costf = \frac{1}{2}(h_\Theta(x^{(i)}) - y^{(i)})^2</script></p>
<p>If we use this cost function for Linear Regression, it will kind of work but we will have a non-convex situation.</p>
<p><img alt="Non convex example diagram" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/92/6b/hero_926b7dc2-7d58-498e-bc8c-4dd534387b48.png" srcset="https://ugc.futurelearn.com/uploads/assets/92/6b/small_hero_926b7dc2-7d58-498e-bc8c-4dd534387b48.png 320w, https://ugc.futurelearn.com/uploads/assets/92/6b/hero_926b7dc2-7d58-498e-bc8c-4dd534387b48.png 648w, https://ugc.futurelearn.com/uploads/assets/92/6b/large_hero_926b7dc2-7d58-498e-bc8c-4dd534387b48.png 729w, https://ugc.futurelearn.com/uploads/assets/92/6b/large_hero_926b7dc2-7d58-498e-bc8c-4dd534387b48.png 2x"/></p>
<p>We would prefer a convex situation as per the figure below.</p>
<p><img alt="Example of a convex diagram" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/69/68/hero_6968a18e-76f7-40d5-9bb4-779ffd4c3d00.png" srcset="https://ugc.futurelearn.com/uploads/assets/69/68/small_hero_6968a18e-76f7-40d5-9bb4-779ffd4c3d00.png 320w, https://ugc.futurelearn.com/uploads/assets/69/68/hero_6968a18e-76f7-40d5-9bb4-779ffd4c3d00.png 648w, https://ugc.futurelearn.com/uploads/assets/69/68/large_hero_6968a18e-76f7-40d5-9bb4-779ffd4c3d00.png 729w, https://ugc.futurelearn.com/uploads/assets/69/68/large_hero_6968a18e-76f7-40d5-9bb4-779ffd4c3d00.png 2x"/></p>
<p>We need to find a cost function for this logistic regression and our squashy <script type="math/tex">h_\Theta (x)</script>   which is convex.
We will use:</p>
<script type="math/tex; mode=display">Costf= \begin{cases}
  -\log(h_\Theta(x)) \:if \:\: y=1 \\    
  -\log(1-h_\Theta(x))   \:if\: \:y=0 
\end{cases}</script>
<p>Let’s try to understand how it works. (It comes from maximum likelihood estimation but we do not look into this here).</p>
<p>If <script type="math/tex">y=1</script> then <script type="math/tex">Costf</script>= <script type="math/tex">-\log⁡(h_\Theta (x))</script></p>
<p><img alt="Estimation graph diagram" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/cd/cc/hero_cdcc35b9-9eb4-4689-ac78-cf75764029b4.png" srcset="https://ugc.futurelearn.com/uploads/assets/cd/cc/small_hero_cdcc35b9-9eb4-4689-ac78-cf75764029b4.png 320w, https://ugc.futurelearn.com/uploads/assets/cd/cc/hero_cdcc35b9-9eb4-4689-ac78-cf75764029b4.png 648w, https://ugc.futurelearn.com/uploads/assets/cd/cc/large_hero_cdcc35b9-9eb4-4689-ac78-cf75764029b4.png 729w, https://ugc.futurelearn.com/uploads/assets/cd/cc/large_hero_cdcc35b9-9eb4-4689-ac78-cf75764029b4.png 2x"/></p>
<p>This has a nice advantage that if <script type="math/tex">h_\Theta (x)=1</script> and <script type="math/tex">y=1</script> then there is no cost, there is no penalty. However, if <script type="math/tex">h_\Theta (x)=0</script> and of course <script type="math/tex">y=1</script> then there is an enormous (infinite!) penalty or cost!!!</p>
<p>If <script type="math/tex">y=0</script> then <script type="math/tex">Costf</script>= <script type="math/tex">-\log⁡(1-h_\Theta (x))</script></p>
<p><img alt="A similar estimation graph diagram" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/5c/b1/hero_5cb1e958-8c52-41bb-be12-f4e7ba68ce51.png" srcset="https://ugc.futurelearn.com/uploads/assets/5c/b1/small_hero_5cb1e958-8c52-41bb-be12-f4e7ba68ce51.png 320w, https://ugc.futurelearn.com/uploads/assets/5c/b1/hero_5cb1e958-8c52-41bb-be12-f4e7ba68ce51.png 648w, https://ugc.futurelearn.com/uploads/assets/5c/b1/large_hero_5cb1e958-8c52-41bb-be12-f4e7ba68ce51.png 729w, https://ugc.futurelearn.com/uploads/assets/5c/b1/large_hero_5cb1e958-8c52-41bb-be12-f4e7ba68ce51.png 2x"/></p>
<p>This similarly has a nice advantage that if <script type="math/tex">h_\Theta (x)=0</script> and <script type="math/tex">y=0</script> then there is no cost, there is no penalty. However, if <script type="math/tex">h_\Theta (x)=1</script> and of course <script type="math/tex">y=0</script> here then there is an enormous (infinite!) penalty or cost!!!</p>
<p>So, lets put our cost function together as one single piece.</p>
<script type="math/tex; mode=display">Costf(h_\Theta(x), y)= \begin{cases}
  -\log(h_\Theta(x)) \:if \:\: y=1 \\    
  -\log(1-h_\Theta(x))   \:if  \:\:y=0 
\end{cases}</script>
<p>which we rewrite as:</p>
<script type="math/tex; mode=display">Costf(h_\Theta (x),y)= -y\log⁡(h_\Theta (x))-(1-y)log⁡(1-h_\Theta (x))</script>
<p>To get our final overall cost function we just add these up for every prediction/training instance pair to yield the following:</p>
<p><strong>The Logistic Regression Cost Function</strong></p>
<script type="math/tex; mode=display">J(\Theta) = \frac{1}{m} \sum_{i=1}^m(Costf) = -\frac{1}{m}[\sum_{i=1}^m \left \{ y^{(i)}\log(h_\Theta(x^{(i)})) + (1-y^{(i)})\log(1-h_\Theta(x^{(i)})) \right \}]</script>
<p>To fit parameters <script type="math/tex">\Theta</script> we minimize the cost function therefore we calculate:</p>
<script type="math/tex; mode=display">\min_{\Theta}⁡J(\Theta)</script>
<p>To make a prediction then, given new <script type="math/tex">x</script></p>
<p>Output below which we interpret as a probability <script type="math/tex">p(y=1 \mid x; \Theta)</script></p>
<script type="math/tex; mode=display">h_\Theta (x)=\frac{1}{1+e^{-\Theta^T x } }</script>
<p>All that remains now is to minimize the cost function.</p>
<p>In the next step, we will learn about Gradient Descent.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.6&emsp;Gradient Descent </h2><div class="u-typography-bold-intro">
<p>We now follow on from our previous step about the cost function.</p>
<p>All that remains now is to minimize the cost function. Here is the cost function reproduced below:</p>
<script type="math/tex; mode=display">J(\Theta)= \frac{1}{m}\sum_{i=1}^m(Costf) = -\frac{1}{m} [ \sum_{i=1}^m\left \{  y^{(i)}\log(h_\Theta(x^{(i)})) + (1-y^{(i)})\log(1-h_\Theta(x^{(i)}))\right \}]</script>
<p>We want to min <script type="math/tex">J(\Theta)</script> which we can do with the following algorithm.</p>
<p>Repeat {</p>
<script type="math/tex; mode=display">\Theta_{new \:j} = \Theta_{old \: j} - \alpha \frac{ \partial}{\partial \Theta_j}J(\Theta)</script>
<p>and do all <script type="math/tex">\Theta_j</script> together
}</p>
<p>which can be rewritten as:</p>
<p>Repeat {</p>
<script type="math/tex; mode=display">\Theta_{new_j} = \Theta_{old_j} - \alpha\sum_{i=1}^m((h_\Theta(x^{(i)}) - y^{(i)})x_j^{(i)}</script>
<p>}</p>
<p>Clearly, this is the same as what we had for linear regression – the real difference and it is substantial, is in the hypothesis where now instead of a linear term we have a ”squashing” function.</p>
<p>So you now know logistic regression! In the next step we examine the one versus all approach.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.7&emsp;Logistic Regression  - The One vs All Algorithm</h2><div class="u-typography-bold-intro">
<p>We know now how to do binary classification.</p>
<p><img alt="Classification decision boundary diargram" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/b5/d4/hero_b5d4b7d2-3f2e-4843-ac1c-d05d76a2abcf.png" srcset="https://ugc.futurelearn.com/uploads/assets/b5/d4/small_hero_b5d4b7d2-3f2e-4843-ac1c-d05d76a2abcf.png 320w, https://ugc.futurelearn.com/uploads/assets/b5/d4/hero_b5d4b7d2-3f2e-4843-ac1c-d05d76a2abcf.png 648w, https://ugc.futurelearn.com/uploads/assets/b5/d4/large_hero_b5d4b7d2-3f2e-4843-ac1c-d05d76a2abcf.png 729w, https://ugc.futurelearn.com/uploads/assets/b5/d4/large_hero_b5d4b7d2-3f2e-4843-ac1c-d05d76a2abcf.png 2x"/></p>
<p>But what if we have three classes as per the figure below?</p>
<p><img alt="3 classes of a decision boundary diagram using pluses Triangles and dots" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/98/c8/hero_98c88082-e25c-48e7-9039-8c0dc70d0d1c.png" srcset="https://ugc.futurelearn.com/uploads/assets/98/c8/small_hero_98c88082-e25c-48e7-9039-8c0dc70d0d1c.png 320w, https://ugc.futurelearn.com/uploads/assets/98/c8/hero_98c88082-e25c-48e7-9039-8c0dc70d0d1c.png 648w, https://ugc.futurelearn.com/uploads/assets/98/c8/large_hero_98c88082-e25c-48e7-9039-8c0dc70d0d1c.png 729w, https://ugc.futurelearn.com/uploads/assets/98/c8/large_hero_98c88082-e25c-48e7-9039-8c0dc70d0d1c.png 2x"/></p>
<p>We can’t find a single decision boundary to separate all three.</p>
<p><img alt="Classifies the plus symbols based on a decision boundary" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/6f/e7/hero_6fe7623e-77b5-40d6-a629-f70dc96d12da.png" srcset="https://ugc.futurelearn.com/uploads/assets/6f/e7/small_hero_6fe7623e-77b5-40d6-a629-f70dc96d12da.png 320w, https://ugc.futurelearn.com/uploads/assets/6f/e7/hero_6fe7623e-77b5-40d6-a629-f70dc96d12da.png 648w, https://ugc.futurelearn.com/uploads/assets/6f/e7/large_hero_6fe7623e-77b5-40d6-a629-f70dc96d12da.png 729w, https://ugc.futurelearn.com/uploads/assets/6f/e7/large_hero_6fe7623e-77b5-40d6-a629-f70dc96d12da.png 2x"/></p>
<p>The trick is to create three new binary classification problems by taking one existing class and merging the rest into a “rest” class as per the figure below. This means that we have the red crosses versus the blue circles’ class where the blue circles’ class is actually a superset of class 2 and class 3.</p>
<p><img alt="Classification of 3 classes based on decision boundary - Classifies the plus symbols into a group" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/17/c2/hero_17c2d89f-686d-49e1-8a0b-138c4decd481.png" srcset="https://ugc.futurelearn.com/uploads/assets/17/c2/small_hero_17c2d89f-686d-49e1-8a0b-138c4decd481.png 320w, https://ugc.futurelearn.com/uploads/assets/17/c2/hero_17c2d89f-686d-49e1-8a0b-138c4decd481.png 648w, https://ugc.futurelearn.com/uploads/assets/17/c2/large_hero_17c2d89f-686d-49e1-8a0b-138c4decd481.png 729w, https://ugc.futurelearn.com/uploads/assets/17/c2/large_hero_17c2d89f-686d-49e1-8a0b-138c4decd481.png 2x"/></p>
<p>Then, we might do something separately for hypothesis 2 and hypothesis 3, where we have chosen the other permutations of two classes that act like the “rest” class.</p>
<p>This gives us three hypotheses as per the figure below.</p>
<p><img alt="Step by step Classification of 3 classes based on decision boundary - Class 1: Plus
Class 2: Circles - Class 3: Triangles.  y =1 classifies the (Plus symbols) into a group
y = 2 classifies the circles into a group y = 3 classifies the triangles into a group" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/95/a3/hero_95a3acc3-4fe6-45da-9493-6edc00e521e3.png" srcset="https://ugc.futurelearn.com/uploads/assets/95/a3/small_hero_95a3acc3-4fe6-45da-9493-6edc00e521e3.png 320w, https://ugc.futurelearn.com/uploads/assets/95/a3/hero_95a3acc3-4fe6-45da-9493-6edc00e521e3.png 648w, https://ugc.futurelearn.com/uploads/assets/95/a3/large_hero_95a3acc3-4fe6-45da-9493-6edc00e521e3.png 729w, https://ugc.futurelearn.com/uploads/assets/95/a3/large_hero_95a3acc3-4fe6-45da-9493-6edc00e521e3.png 2x"/></p>
<p><strong>One vs all (One vs Rest)</strong></p>
<p>So now we have a situation where we can:</p>
<ul>
<li>Train a logistic regression classifier <script type="math/tex">h_\Theta^i (x)</script> for each class <script type="math/tex">i</script> to predict the probability that <script type="math/tex">y=i</script>.</li>
<li>On a new input <script type="math/tex">x</script>, to make a prediction just pick the class <script type="math/tex">i</script> that maximises <script type="math/tex">\max_{i} h_\Theta^i(x)</script>.</li>
</ul>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>2.8&emsp;Regularization</h2><div class="u-typography-bold-intro">
<p>Overfitting is a common issue in machine learning.</p>
<p>Watch the video above where I take you through the various issues.</p>
</div><p><h2>2.9&emsp;Review of Topic 2</h2><div class="u-typography-bold-intro">
<p>Congratulations on completing Topic 2.</p>
<p>This topic covered the significant subject of logistic regression. This is a useful classification algorithm both from the perspective of being useful and from the perspective of being instructively useful for educational purposes.</p>
<p>We developed the idea from linear regression. We examined how the development of a suitable loss function to facilitate classification can lead to a specific gradient descent algorithm which is suitable for practical use.</p>
<p>We also learned how to extend logistic regression to non-linear decision boundaries and multi-class classification.</p>
<p>Finally, as per linear regression, we introduced the idea of regularization and examined how to incorporate this into our optimization algorithm.</p>
<p>Taken together, you should see a natural progression from a linear regression through to logistic regression which will be carried over into support vector machines in a later course.</p>
</div><p style="page-break-before: always"><h2>3.1&emsp;Welcome to Topic 3</h2><div class="u-typography-bold-intro">
<p>Hello and welcome to Topic 3: Ensembles.</p>
<p>We are now going to examine the power of the collective in machine learning.</p>
<p>More specifically, we are going to look at the idea of ensembling in which a machine learning task is solved by taking a number of separate machine learning algorithms and combining their outputs.</p>
<p>We begin with a general overview of the concept and history of this powerful idea, which has applications far beyond machine learning.</p>
<p>We then proceed to examine different ensemble approaches and the ideas of bagging and boosting in particular.</p>
<p>At this point, you will be much better positioned to understand why the random forest classifier introduced in an earlier course is so powerful.</p>
<p>We complete this topic with a brief examination of another popular algorithm called Adaboost, and an acknowledgement of further powerful extensions to the idea in the form of stacking.</p>
<p><img alt="Statement of funding from Skillnet Ireland stating that this course has been grant-aided by Skillnet Ireland" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/14/0b/hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/14/0b/small_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 320w, https://ugc.futurelearn.com/uploads/assets/14/0b/hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 648w, https://ugc.futurelearn.com/uploads/assets/14/0b/large_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 729w, https://ugc.futurelearn.com/uploads/assets/14/0b/large_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 2x"/></p>
<div class="video_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.2&emsp;What is an ensemble?</h2><div class="u-typography-bold-intro">
<p>If I look up the English word “ensemble” using the dictionary on my computer, I will find the following definition:</p>
<blockquote>
<p><strong>1.</strong> <em>a group of musicians, actors, or dancers who perform together: a Bulgarian folk ensemble.</em> <br/>
- <em>a piece of music or passage was written for performance by a whole cast, choir, or group of instruments: Cherubini’s numbers, with solos and ensembles intermingled, have freedom and originality.</em> <br/>
 - <em>[mass noun] the coordination between performers executing an ensemble passage: a high level of tuning and ensemble is guaranteed.</em> <br/>
<strong>2.</strong> <em>a group of items viewed as a whole rather than individually: the buildings in the square present a charming provincial ensemble.</em> <br/>
 - <em>[usually in singular] a set of clothes chosen to harmonize when worn together: her elegant pink and black ensemble put most outfits in the shade.</em> <br/>
 - <em>chiefly Physics a group of similar systems, or different states of the same system, often considered statistically: we would have to adopt a picture in which there is an ensemble of all possible universes with some probability distribution.</em> <br/>
<strong>ORIGIN</strong> <em>late Middle English (as an adverb (long rare) meaning ‘at the same time’): from French, based on Latin <strong>in simul,</strong> from <strong>in</strong>- ‘in’ + <strong>simul</strong> ‘at the same time’. The noun dates from the mid 18th century.</em></p>
</blockquote>
<hr/>
<p>Ensembles are an important concept in machine learning. I would like you to discuss with your fellow learners what you think ensemble means, in the context of machine learning.</p>
<p>Be sure to “like” or respond to any comments you find particularly insightful.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.3&emsp;Ensembles in Machine Learning</h2><div class="u-typography-bold-intro">
<p>Now that you have all thought a little about what an ensemble is, you might be thinking that when we talk about ensembles in machine learning we are talking about a coordinated effort by a number of entities.</p>
<p>You would be correct! This is exactly what we do in machine learning. Let’s look at what we mean in a classification task.</p>
<p>The basic idea here is to combine the predictions from a number of classifiers with the goal of improving performance. What is interesting about this is that even if we have fairly poor-performing algorithms, what some might term as “weakly performing” algorithms, these can still perform well as an ensemble – i.e. through a committee, it can be a strongly performing ensemble.</p>
<p>This approach can be used with many different classifier types. We illustrate a particular ensemble approach in the figure below which illustrates this combination of classifiers in a very straightforward way.</p>
<p><img alt="Combination of  Classifiers Diagram - Top layer has 3 separate boxes of Classifier. Namely “Classifier 1, Classifier 2 and Classifier n” Each of these has an arrow pointing downwards towards the next 3 boxes namely “Prediction 1, Prediction 2 and Prediction n”.  There is an arrow leading from each “prediction box downwards to a single box called “combination box” From the “Combination box” there is an arrow pointing downwards from this box to the “Ensemble Prediction” box" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/a1/62/hero_a162eb81-b2d9-45e0-982a-7aa3de83bd84.png" srcset="https://ugc.futurelearn.com/uploads/assets/a1/62/small_hero_a162eb81-b2d9-45e0-982a-7aa3de83bd84.png 320w, https://ugc.futurelearn.com/uploads/assets/a1/62/hero_a162eb81-b2d9-45e0-982a-7aa3de83bd84.png 648w, https://ugc.futurelearn.com/uploads/assets/a1/62/large_hero_a162eb81-b2d9-45e0-982a-7aa3de83bd84.png 729w, https://ugc.futurelearn.com/uploads/assets/a1/62/large_hero_a162eb81-b2d9-45e0-982a-7aa3de83bd84.png 2x"/></p>
<p>Does such design work? As it turns out, it works very well. In fact, most Kaggle competitions are won by some sort of ensemble approach. <a href="https://www.kaggle.com/">Kaggle</a> is a website, an online community for data science, which is commonly used to host open datasets and offer competitions. The <a href="https://www.kaggle.com/netflix-inc/netflix-prize-data">Netflix prize</a> for improving recommendations for which movies to watch – a famous prize, given the amount of prize money at stake - was won by researchers who used an ensemble approach – you can read more information about this in Edwin Chen’s article <a href="http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/">Winning the Netflix Prize: A Summary</a>.</p>
<p><sub><strong>References</strong></sub></p>
<p><sub>Chen, Edwin ‘Winning the NetFlix Prize:  A Summary’ <em>Edwin Chen</em>: available: http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/ [accessed 8 Jan 2020] </sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.4&emsp;Why does ensembling work?</h2><div class="u-typography-bold-intro">
<p>You might imagine that this works well if you have a number of already well-performing algorithms.</p>
<p>But what about taking the output of mediocre classifiers, combining them and expecting the output to be any good?  This may not sound right if my local parliament/congress/student union/[insert your favourite non-performing committee example] is anything to go by.</p>
<p>It turns out there is wisdom in crowds, so long as each individual has a probability of being correct <script type="math/tex">p > 0.5</script> then the probability of the majority of voters being correct approaches 1 as the number of individuals approaches infinity. So long as the probability of an expert is greater than <script type="math/tex">50\%</script> <script type="math/tex">(p>0.5)</script> then the probability of the majority being correct increases as the number of experts in the ensemble increases. Let’s look at this in more detail.</p>
<h3 id="the-marquis-of-condorcet">The Marquis of Condorcet</h3>
<table>
<tbody>
<tr>
<td><img alt="Portrait of the Marquis of Condorcet on a stamp" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/5f/b7/hero_5fb7ebf7-9013-4306-b814-2f3ae8fa9658.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/5f/b7/small_hero_5fb7ebf7-9013-4306-b814-2f3ae8fa9658.jpg 320w, https://ugc.futurelearn.com/uploads/assets/5f/b7/hero_5fb7ebf7-9013-4306-b814-2f3ae8fa9658.jpg 648w, https://ugc.futurelearn.com/uploads/assets/5f/b7/large_hero_5fb7ebf7-9013-4306-b814-2f3ae8fa9658.jpg 729w, https://ugc.futurelearn.com/uploads/assets/5f/b7/large_hero_5fb7ebf7-9013-4306-b814-2f3ae8fa9658.jpg 2x"/></td>
<td><img alt="Portrait of the Marquis of Condorcet" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/8b/40/hero_8b40e92e-fc48-411e-b1f1-f0477e2de8eb.png" srcset="https://ugc.futurelearn.com/uploads/assets/8b/40/small_hero_8b40e92e-fc48-411e-b1f1-f0477e2de8eb.png 320w, https://ugc.futurelearn.com/uploads/assets/8b/40/hero_8b40e92e-fc48-411e-b1f1-f0477e2de8eb.png 648w, https://ugc.futurelearn.com/uploads/assets/8b/40/large_hero_8b40e92e-fc48-411e-b1f1-f0477e2de8eb.png 729w, https://ugc.futurelearn.com/uploads/assets/8b/40/large_hero_8b40e92e-fc48-411e-b1f1-f0477e2de8eb.png 2x"/></td>
</tr>
<tr>
<td><sub>Source: <a href="https://www.pinterest.com/pin/327707310364160588/">https://www.pinterest.com/pin/327707310364160588/</a><sub></sub></sub></td>
<td><sub>Source: <a href="https://en.wikipedia.org/wiki/Marquis_de_Condorcet#/media/File:Nicolas_de_Condorcet.PNG">Wikimedia Commons</a></sub></td>
</tr>
</tbody>
</table>
<p>The <a href="https://plato.stanford.edu/entries/histfem-condorcet/">Marquis of Condorecet</a> was an 18th-century French philosopher who developed new ideas in political science. A  creative and influential thinker, he lived during turbulent times in Europe.</p>
<p>In this course, what we are most interested in are his thoughts on majority voting systems. In his 1785 work <strong>Essay on the Application of Analysis to the Probability of Majority Decision</strong>, he demonstrated the conditions in which a committee of voters would arrive at the correct decision in statistical terms. This is Condorcet’s Jury Theorem.</p>
<p>Condorcet’s jury theorem makes the following claims for a set of voters choosing (independently) - through a majority voting system - between a correct outcome and an incorrect outcome. If the probability of each voter choosing the correct outcome is <script type="math/tex">p</script>, where <script type="math/tex">0 \leq p \leq 1</script>.</p>
<p><strong>1.</strong> Then if  <script type="math/tex">p >  0.5</script>  (that is, each voter is more likely than not to choose correctly), adding more voters increases the probability that the majority chooses correctly. The probability of a correct decision approaches 1 as the number of voters increases.</p>
<p><strong>2.</strong> If  <script type="math/tex">p >  0.5</script>  (that is, each voter is more likely to be incorrect than correct), then adding more voters decreases the probability that the majority chooses correctly! In this case, a single juror represents the best performance.</p>
<p>This set of voters is what constitutes the “jury” referred to in the theorem title.</p>
<p>For more insight into Concordet’s jury theorem, take a look at the University of Maryland’s Professor Eric Pacuit’s YouTube video on the subject.</p>
<p></p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<p>Another excellent explanation of Concordet’s jury theorem is <strong>Predicting Media Memorability Using Ensemble Models</strong>, which we have added in the resources section and can be viewed as a PDF attachment at the bottom of this step.</p>
<p>As you have seen in the accompanying material, there are a number of assumptions involved in this theorem. One important assumption is the independence of the experts. There should be diversity in the ensemble of “opinions”, i.e. there should be disagreements which are varied and diverse. In reality, it is very difficult to ensure such diversity as we grow the number of experts and there will be correlations in classification as the numbers of experts become larger.</p>
<p>As a result, the performance of the ensemble will reflect the saturation in diversity among the individual experts and plateau at some point.</p>
<p><sub><strong>Resources</strong></sub></p>
<p><sub>Azcona, D., Moreu, E., Hu, F., Ward, T.E., Smeaton, A.F. (2019) <em>Predicting media memorability using ensemble models.</em> In: MediaEval 2019, 27 - 29 Oct 2019, Sophia Antipolis, France. </sub></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.5&emsp;Ensembles in action</h2><div class="u-typography-bold-intro">
<p>In this step, we look at some well-known winning applications of ensembles in international competitions.</p>
<p>Three good examples are as follows:</p>
<p><strong>Example 1:</strong> MediaEval – this is the competition on which your assignment is based. Take a look at the paper entered by David Azcona and the team at <a href="http://doras.dcu.ie/23833/1/David_Azcona_MediaEval_2019_Memorability_Camera_ready.pdf">DCU for the 2019 competition.</a></p>
<p><strong>Example 2:</strong> <a href="http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/">Netflix</a> – the Netflix competition which we mentioned previously.</p>
<p><strong>Example 3:</strong> Patient Adherence Prediction. This is an example of the use of machine learning in a digital health context.  In this example, an Irish company called HealthBeacon accumulate data on the use of medications through the use of a smart bin for disposal of used injectable medications. This data records when the medications were taken and more importantly when they were not taken but should have been taken. In this Biorxiv paper which is available at the bottom of this step, you can read about the use of an ensemble approach to predict when patients are likely to neglect to take their medication.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.6&emsp;Bias vs Variance</h2><div class="u-typography-bold-intro">
<p>Let’s say we have a machine learning algorithm and we want to present some information regarding its performance.  What might be useful?</p>
<p>We might look at the difference between predicted values and the actual values. We would probably average this to produce a single number. If this is a large number, then we are underperforming and it looks like we are missing important patterns in the data – this is called <strong>bias</strong>.</p>
<p>We could also look at how sensitive our predictions are to the training data. Say we train on subsets of the data, and for each model produced we make predictions on a fixed set of observations. If we measure the variation in performance over these sets of training data, we have a measure called <strong>variance</strong>. If the variance is high, then our machine learning model is overfitting to the data, i.e. it has a high sensitivity to the training data and will perform poorly on observations that it has not been trained on.</p>
<p>We can illustrate this idea in the figure below.</p>
<p><img alt="Diagram of High Variance over Low Variance Performance. There are 4 Circles with inner circles in this diagram. At the top of the Top Left Circle it states “ High Variance” at the Top of the Top right-hand Circle it states “Low Variance” To the left of the first circle it states “High Variance”  At the bottom left of the left circle it states “Low Bias”. All four circles have inner circles all with the same group of colours inside. The first inner circle is white, the second inner circle is purple, the 3rd inner circle is white and the 4th inner circle is pink. The Top left circle has 7 blue dots in the purple circle.  The Top right circle has 6 blue dots outside of the circle, 3 blue dots on the outer rim, 3 blue dots in the white circle and 2 blue dots on the rim of the purple circle.  The bottom left lower circle has one blue dot in the purple circle. One blue dot on the rim between the purple circle and white inner circle. 10 Blue dots in the Inner white circle. One blue dot on the rim of the pink circle. And 2 blue dots in the pink circle.  Bottom right circle - there are 7 blue dots in the pink circle." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/20/9d/hero_209dc83f-a0c2-4b76-ac8b-a68ef5102e8f.png" srcset="https://ugc.futurelearn.com/uploads/assets/20/9d/small_hero_209dc83f-a0c2-4b76-ac8b-a68ef5102e8f.png 320w, https://ugc.futurelearn.com/uploads/assets/20/9d/hero_209dc83f-a0c2-4b76-ac8b-a68ef5102e8f.png 648w, https://ugc.futurelearn.com/uploads/assets/20/9d/large_hero_209dc83f-a0c2-4b76-ac8b-a68ef5102e8f.png 729w, https://ugc.futurelearn.com/uploads/assets/20/9d/large_hero_209dc83f-a0c2-4b76-ac8b-a68ef5102e8f.png 2x"/></p>
<p>This understanding of bias and variance leads to some useful ideas. For example, if bias is high, it means we are missing a “pattern” in the data and we could deal with this by increasing the complexity of the model, i.e. adding additional modelling units to capture this missing structure. As we increase the complexity of the model we should see our bias reduced.</p>
<p>You might then think, “why not just keep doing this? Keep adding more features?” Well, the problem there is that you increase the chances of overfitting as you begin to overfit the training data. As a result, variance will increase. There is a sweet spot where you will gain the best performance on the test data with the lowest possible bias and variance. This is illustrated in the figure below. Typically, you will not drive the test error to zero. This is the minimum classification error and corresponds to issues such as noise in the data and limits in the model itself.</p>
<p><img alt="Graph showing bias, variance and test error - colour code - Orange - Bias, Blue - Variance, Green - test error.   Two-axis horizontal and vertical. At the base of the graph, there are 3 arrows.  Under the arrow that points to the left is the wording ‘underfitting’ (high bias) Under the arrow that points straight up is the wording ‘Optimal balance’ and under the arrow that points to the right is written ‘Overfitting’ (high variance). At the end of the line of the bottom axis to the right is written model complexity (ie, degrees of freedom) In the graph itself there is a Green curved line that starts at the top left and goes around to the top right with the base of the centre point appearing above the ‘Optimal balance’ arrow The Blue line starts at the bottom left of the graph and very gently curves to the top right. Its curved point appears above the ‘Optimal balance’ arrow. The Orange line starts on the top left of the graph and goes down to the bottom right of the graph.   The Orange and Blue lines cross over and at this point where these lines meet is the ‘Optimal balance’" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/3c/9b/hero_3c9b3e3c-cf64-46a0-9365-0f8e6d35618e.png" srcset="https://ugc.futurelearn.com/uploads/assets/3c/9b/small_hero_3c9b3e3c-cf64-46a0-9365-0f8e6d35618e.png 320w, https://ugc.futurelearn.com/uploads/assets/3c/9b/hero_3c9b3e3c-cf64-46a0-9365-0f8e6d35618e.png 648w, https://ugc.futurelearn.com/uploads/assets/3c/9b/large_hero_3c9b3e3c-cf64-46a0-9365-0f8e6d35618e.png 729w, https://ugc.futurelearn.com/uploads/assets/3c/9b/large_hero_3c9b3e3c-cf64-46a0-9365-0f8e6d35618e.png 2x"/></p>
<p>As we will now see, ensembling presents one way for managing bias/variance balance. The precise nature of the tradeoff will depend on the ensembling approach used. We will examine the approaches in the next step.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.7&emsp;Types of Ensembling</h2><div class="u-typography-bold-intro">
<p>There are two basic approaches to ensembling.</p>
<h3 id="parallel">Parallel</h3>
<p>The first approach is to generate the base learners in a parallel fashion. With such an approach we have a number of what are called base learners, which we run in parallel. We exploit independence (diversity) between the base learners, and in so doing improve performance through combining the output. Random Forest is an example of such an approach.</p>
<h3 id="sequential">Sequential</h3>
<p>The second approach is to generate the base learners in a sequential way. In this case, the base learners are exploited through the dependence between the base learners. The overall performance is boosted by weighting previously misclassified examples with higher weight. However, the final classifier still operates as a committee. The figure below illustrates this concept.</p>
<p><img alt="Diagram of Algorithms - 3 separate Columns  - The first column has a single Algorithm  ‘Single Classifier’  -  Single Algorithm processing model. At the base of this column, it states: “Single Iteration”. In the 2nd Column, we have a ‘Bagging’ processing model Algorithm, at the base of this model it states “Parallel” and in the 3rd Column, we have a ‘Boosting’ Algorithm processing model. At the base of this column it states “Sequential”" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/d0/ba/hero_d0ba34b6-90a4-4202-9923-3b898fb5098d.png" srcset="https://ugc.futurelearn.com/uploads/assets/d0/ba/small_hero_d0ba34b6-90a4-4202-9923-3b898fb5098d.png 320w, https://ugc.futurelearn.com/uploads/assets/d0/ba/hero_d0ba34b6-90a4-4202-9923-3b898fb5098d.png 648w, https://ugc.futurelearn.com/uploads/assets/d0/ba/large_hero_d0ba34b6-90a4-4202-9923-3b898fb5098d.png 729w, https://ugc.futurelearn.com/uploads/assets/d0/ba/large_hero_d0ba34b6-90a4-4202-9923-3b898fb5098d.png 2x"/></p>
<p>Most ensemble methods use a single base learning algorithm to produce homogeneous base learners, i.e. learners of the same type, leading to <strong>homogeneous ensembles</strong>.
There are also some methods that use heterogeneous learners, i.e. learners of different types, leading to <strong>heterogeneous ensembles</strong>. In order for ensemble methods to be more accurate than any of its individual members, the base learners have to be as accurate as possible and as diverse as possible.</p>
<p>In the next step, we will look at a common ensemble approach, <strong>bagging</strong>.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.8&emsp;Bagging</h2><div class="u-typography-bold-intro">
<p>Bagging has got nothing to do with bags.</p>
<p>It is a compression of Bootstrap Aggregation. Let’s imagine we are working with decision trees. We can reduce the variance by combining the outputs and aggregating them in some way. We might train <script type="math/tex">K</script> different trees, by randomly sampling from the training data with replacement, and compute the ensemble. We can average the outputs for a regression task and use majority voting for a classification task.</p>
<p>By the way, <a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)">bootstrapping</a> is a term used in statistics to refer to a measure that relies on random sampling with replacement. You may also like to read <a href="https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/">A Gentle Introduction to the Bootstrap Method</a>, Jason Brownlee’s <strong>Bootstrap method tutorial</strong>.</p>
<p>If we have <script type="math/tex">N</script> training samples and we talk about a bootstrap sample size of <script type="math/tex">N</script>, then we are going to have on average approximately 63% of our training examples, as there will be many repetitions. Sometimes, with large training sets, it will not be feasible to use such a large sample and we might see smaller bootstrap sample sizes (0.8, for example, would mean 80% of the size <script type="math/tex">N</script>). The data which has not made it into the bootstrap sample is referred to as “out-of-bag” and could be used for testing as per this <a href="https://en.wikipedia.org/wiki/Out-of-bag_error">Out-of-bag error</a> Wikipedia article.</p>
<p>The table below is an example of bootstrapping from a training dataset – you can clearly see replication which occurs by chance here.</p>
<p><img alt="Diagram chart - 7 columns horizontally and 6 rows vertically. The 7 columns across are titled ‘Original, Apple, Mango, Orange, Pineapple, Grapes, Lime. The 6 vertical layers starting top to bottom are named: ‘Original, Set 1, Set 2, Set 3, Set 4, Set 5." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/33/ce/hero_33ce3ffd-7623-40f5-bc53-9e6f8ae25d42.png" srcset="https://ugc.futurelearn.com/uploads/assets/33/ce/small_hero_33ce3ffd-7623-40f5-bc53-9e6f8ae25d42.png 320w, https://ugc.futurelearn.com/uploads/assets/33/ce/hero_33ce3ffd-7623-40f5-bc53-9e6f8ae25d42.png 648w, https://ugc.futurelearn.com/uploads/assets/33/ce/large_hero_33ce3ffd-7623-40f5-bc53-9e6f8ae25d42.png 729w, https://ugc.futurelearn.com/uploads/assets/33/ce/large_hero_33ce3ffd-7623-40f5-bc53-9e6f8ae25d42.png 2x"/></p>
<p>This sort of approach, i.e. bagging, encourages diversity in the ensemble and is particularly useful for decision trees, and even neural networks.  We illustrate the basic idea in the figure below.</p>
<p><img alt="To the left of the diagram there is a cylindrical box with the wording “Training Examples” written on it.  Leading from this we have 4 columns with 3 boxes in each column. In column 1 the boxes are named: “Sample 1, Sample 2 and Sample 3”.  In Column 2, the boxes are named “Classifier 1, Classifier 2 and Classifier 3” in the 3rd Column the boxes are named “Model 1”, Model 2 and Model 3.” In the final column the boxes are named “Test Data”, Combined Classifier and Prediction” There is an arrow pointing downwards from the “Test data” box to the “Combined Classifier” box and also from the “Classifier” box to the “Prediction” box. There are 3 separate arrows pointing from each Model Box in the 3rd Column to the “Combined Classifier” box in the 4th row" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/d8/3e/hero_d83ee4cb-b0c3-4e84-8ba3-5182186b045f.png" srcset="https://ugc.futurelearn.com/uploads/assets/d8/3e/small_hero_d83ee4cb-b0c3-4e84-8ba3-5182186b045f.png 320w, https://ugc.futurelearn.com/uploads/assets/d8/3e/hero_d83ee4cb-b0c3-4e84-8ba3-5182186b045f.png 648w, https://ugc.futurelearn.com/uploads/assets/d8/3e/large_hero_d83ee4cb-b0c3-4e84-8ba3-5182186b045f.png 729w, https://ugc.futurelearn.com/uploads/assets/d8/3e/large_hero_d83ee4cb-b0c3-4e84-8ba3-5182186b045f.png 2x"/></p>
<h3 id="random-subspace-method">Random Subspace Method</h3>
<p>This interesting idea goes further and uses subsampling of the features (without replacement). This is an attempt to reduce correlation among the base learners. With this subset of features, you then train a classifier on the training data. Your intuition might tell you that due to the subsampling of training data and the subsampling of features that you might reduce sensitivity to the training data, i.e. you might reduce variance. This approach can increase diversity in the learners as they all have different types of information upon which they make their decision. This is an advantage of these bagging approaches. This particular approach is often used with k-NNs, which we learn about later in the course.</p>
<p>Interestingly, k-NN are less sensitive to variation in training samples. They are referred to as stable learners in that regard. Typically, combining stable learners, through subsampling of training data, does not yield significant performance advantages with test data.</p>
<p><img alt="One large box with the wording “Original dataset (5 features)” written above the box. Blue arrow leads from this to the right-pointing to 3 smaller subsets boxes..  Above the first subset box is written ‘Feature Subset 1 (3 Features)’ which points downwards via an arrow to a classifier box which in turn points downwards to another box named “Model 1” Above the second subset box is written ‘Feature Subset  (3 Features)’ which points downwards via an arrow to a classifier box which in turn points downwards to another box named “Model 2”. Above the third subset box, it states ‘Feature Subset 3 (3 Features)’ which points downwards via an arrow to a classifier box which in turn points downwards to another box named “Model 3”" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/e1/e4/hero_e1e4946c-7273-4cb0-9101-8c8c7c8c2840.png" srcset="https://ugc.futurelearn.com/uploads/assets/e1/e4/small_hero_e1e4946c-7273-4cb0-9101-8c8c7c8c2840.png 320w, https://ugc.futurelearn.com/uploads/assets/e1/e4/hero_e1e4946c-7273-4cb0-9101-8c8c7c8c2840.png 648w, https://ugc.futurelearn.com/uploads/assets/e1/e4/large_hero_e1e4946c-7273-4cb0-9101-8c8c7c8c2840.png 729w, https://ugc.futurelearn.com/uploads/assets/e1/e4/large_hero_e1e4946c-7273-4cb0-9101-8c8c7c8c2840.png 2x"/></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.9&emsp;Combining the output from ensembles</h2><div class="u-typography-bold-intro">
<p>We previously mentioned that we should combine the output of the Machine Learning algorithms to produce an output.</p>
<p>From our discussions so far, it is apparent that majority voting can work for classification and that we might average outputs for regression. For the sake of being explicit, we will take a closer look at how to combine outputs.</p>
<h3 id="majority-voting-for-classification">Majority Voting for Classification</h3>
<p>This is the simplest approach. Once trained we run all our base learners in parallel and combine the output. For a binary classification task, the figure below illustrates the idea.</p>
<p><img alt="Binary Classification Task Diagram. Box to the left named ‘New example X’ this leads to 5 separate Classifier boxes classified as boxes 1-5.  Each has an arrow pointing from each classier to another box. Classifier 1 points to a green box with “1” in it, Classifier 2 points to a green box with “0” in it. Classifier 3 points to a green box with “1” in it. Classifier 4 points to a box with “1” written in it. Classifier 5 points to a green box with “0” written in it. All these results lead to a box named “Majority voting” with an arrow leading to the right-pointing to a green box with the number “1” written inside the box. At the base of all the green boxes is written ‘prediction’ and to the right of the diagram is written “Ensemble Votes for label “1” for X by 3:2" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/3b/df/hero_3bdf09ea-e1ab-4342-aaab-e7d53f022eb2.png" srcset="https://ugc.futurelearn.com/uploads/assets/3b/df/small_hero_3bdf09ea-e1ab-4342-aaab-e7d53f022eb2.png 320w, https://ugc.futurelearn.com/uploads/assets/3b/df/hero_3bdf09ea-e1ab-4342-aaab-e7d53f022eb2.png 648w, https://ugc.futurelearn.com/uploads/assets/3b/df/large_hero_3bdf09ea-e1ab-4342-aaab-e7d53f022eb2.png 729w, https://ugc.futurelearn.com/uploads/assets/3b/df/large_hero_3bdf09ea-e1ab-4342-aaab-e7d53f022eb2.png 2x"/></p>
<h3 id="weighted-voting">Weighted Voting</h3>
<p>This quite common-sense idea includes the concept of giving more weight to better performing base learners. This is illustrated nicely in the figure below.</p>
<p><img alt="Here we have two separate diagrams. The diagram on the right has 3 columns and  5 Rows. The headings in the columns are namely: ‘Classifier’ ‘Accuracy’ and ‘Weight’. Under the Classifier column, we have ‘1, 2, 3, 4 and 5’.  Under the ‘Accuracy’ Column we have written in each row from 1 to 5 the following-: 0.52, 1.00, 0.57, 0.55 and 0.95  - this column totals 3.59.   Under the weight column written in each row from 1 to 5 the following appears: 0.14, 0.28, 0.16, 0.15 and 0.26. This column totals 1.00. Written under this diagram is “e.g C1:0.52/3.59 = 0.14” and underneath written in green is “Vote “0”: 0.28 + 0.26 = 0.54” Next we move onto the 2nd diagram which appears as follows: Box to the left named ‘New example X’ this via an arrow to the right leads into 5 separate Classifier boxes classified as boxes 1-5.  Each has an arrow pointing from each classier to another box. Classifier 1 points to a green box with “1” in it, Classifier 2 points to a green box with “0” in it. Classifier 3 points to a green box with “1” in it. Classifier 4 points to a box with “1” written in it. Classifier 5 points to a green box with “0” written in it. All these results lead to a box named “Weighted voting” with an arrow leading to the right-pointing to a green box with the number “0” written inside the box. At the base of all this diagram is written in green is “Vote “1”: 0.14 + 0.16 + 0.15 = 0.46" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/d4/d2/hero_d4d21299-58b8-4e4c-a115-73d47acf3bea.png" srcset="https://ugc.futurelearn.com/uploads/assets/d4/d2/small_hero_d4d21299-58b8-4e4c-a115-73d47acf3bea.png 320w, https://ugc.futurelearn.com/uploads/assets/d4/d2/hero_d4d21299-58b8-4e4c-a115-73d47acf3bea.png 648w, https://ugc.futurelearn.com/uploads/assets/d4/d2/large_hero_d4d21299-58b8-4e4c-a115-73d47acf3bea.png 729w, https://ugc.futurelearn.com/uploads/assets/d4/d2/large_hero_d4d21299-58b8-4e4c-a115-73d47acf3bea.png 2x"/></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.10&emsp;Random Forests revisited</h2><div class="u-typography-bold-intro">
<p>Many of you will be thinking that Random Forest classifiers seem to be a clear example of ensembles in action.</p>
<p>You would be entirely correct. You should now understand much better why this works, but just in case, we will revisit this topic.</p>
<p>With Random Forests we have a bunch of decision trees. Each base learner, i.e. each decision tree, is built using training data selected with a replacement (that is a bootstrap sample) and a random subset of features (random subspace method). Since we have reduced correlations in the trees, we should have less variance. Note that Random Forests can be considered an example of a homogeneous ensemble.</p>
<p><img alt="3 decision trees named Tree 1, Tree 2 and Tree 3. Each tree has 5 boxes. The top box has 2 arrows pointing downwards to the next two boxes underneath.  The box to the right has two arrows pointing downwards from this box to the two boxes underneath this box. This is the layout for all 3 trees. From each tree, there is a blue arrow pointing downwards. In Tree 1 this points to figure 0.2 in Tree 2 this points to the figure -0.1 and in Tree 3 this points to figure 0.5. These 3 figures all have arrows pointing from them to one figure below in a blue box 0.2" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/5c/88/hero_5c88c069-ee6d-4a86-ba3c-9784a46ee2b9.png" srcset="https://ugc.futurelearn.com/uploads/assets/5c/88/small_hero_5c88c069-ee6d-4a86-ba3c-9784a46ee2b9.png 320w, https://ugc.futurelearn.com/uploads/assets/5c/88/hero_5c88c069-ee6d-4a86-ba3c-9784a46ee2b9.png 648w, https://ugc.futurelearn.com/uploads/assets/5c/88/large_hero_5c88c069-ee6d-4a86-ba3c-9784a46ee2b9.png 729w, https://ugc.futurelearn.com/uploads/assets/5c/88/large_hero_5c88c069-ee6d-4a86-ba3c-9784a46ee2b9.png 2x"/>
<sub>Source: <a href="https://databricks.com/blog/2015/01/21/random-forests-and-boosting-in-mllib.html">https://databricks.com/blog/2015/01/21/random-forests-and-boosting-in-mllib.html</a><sub></sub></sub></p>
<p><img alt="Structure of Random Forest Classification.  3 Decision trees -  Tree 1, Tree 2 and Tree 3. The Tree to the left has ‘Random Forest’  appearing above it. The Middle Tree has ‘Instance’ written above it, the right tree has nothing written above it.  Underneath the word ‘Instance,’ there are 3 arrows each arrow points to each diagram. Each decision tree has two child nodes. The output of each decision tree is considered and the majority voted output is finalized to be the output of the entire model." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/ef/82/hero_ef822669-6471-4c47-83a7-3e549f4f1d19.png" srcset="https://ugc.futurelearn.com/uploads/assets/ef/82/small_hero_ef822669-6471-4c47-83a7-3e549f4f1d19.png 320w, https://ugc.futurelearn.com/uploads/assets/ef/82/hero_ef822669-6471-4c47-83a7-3e549f4f1d19.png 648w, https://ugc.futurelearn.com/uploads/assets/ef/82/large_hero_ef822669-6471-4c47-83a7-3e549f4f1d19.png 729w, https://ugc.futurelearn.com/uploads/assets/ef/82/large_hero_ef822669-6471-4c47-83a7-3e549f4f1d19.png 2x"/>
<sub>Source: <a href="https://towardsdatascience.com/random-forest-classification-and-its-implementation-d5d840dbead0">https://towardsdatascience.com/random-forest-classification-and-its-implementation-d5d840dbead0</a><sub></sub></sub></p>
</div><p><h2>3.11&emsp;Boosting</h2><div class="u-typography-bold-intro">
<p>Boosting is an idea based on what we termed earlier as a sequential approach.</p>
<p>The base learners are exploited through the dependence between the base learners. The performance overall is boosted by weighting previously misclassified examples with higher weights.</p>
<p>The basic approach is as follows:</p>
<p><strong>(a)</strong> In the beginning, all training examples are treated equally, they are weighted equally.</p>
<p><strong>(b)</strong> Next, we iterate through our base learners (we will have a fixed number) as follows:</p>
<ul>
<li><strong>(i)</strong> Train classifier using the current weights.</li>
<li><strong>(ii)</strong> For incorrect classification training examples increase their weights.</li>
<li><strong>(iii)</strong> For correct classification examples decrease their weights.</li>
<li><strong>(iv)</strong> Go to the next classifier in the sequence continuing from step <strong>(i)</strong>.</li>
</ul>
<p><strong>(c)</strong> We now have a final model which is used in a committee fashion as before, except now it is typical to weight the classifiers’ votes according to their performance during training.  i.e. the better base learners are given more weight in voting (classification) or averaging (regression).</p>
<h3 id="adaboost">Adaboost</h3>
<p>A great example of boosting is the famous algorithm Adaboost. We will look at using Adaboost in the practical sessions so all the nitty-gritty details will come up there. For now, you should have the general idea although the example below should help with your intuition.</p>
<p>Let’s consider the following example which uses the Adaboost algorithm: Apply a classifier to a training set with 6 examples {Apple, Mango, Orange, Pineapple, Grapes, Lime} where Apples is an outlier and difficult to classify.</p>
<ul>
<li>Selected training sets for 4 runs of bagging - i.e. simple random sampling with replacement.</li>
<li>All examples are equally weighted.</li>
</ul>
<p>(The two tables below also appear in the PDF at the bottom of this step).</p>
<p><img alt="Diagram chart - 7 columns horizontally and 6 layers vertically. The 7 columns across are titled ‘Original, Apple, Mango, Orange, Pineapple, Grapes, Lime. The 6 vertical layers starting top to bottom are named: ‘Original, Set 1, Set 2, Set 3, Set 4, Set 5.  The Word ‘Apple’ is highlighted at every point in the diagram. Namely on the top row, at Set 5 under the ‘Orange’ Column and at Set 1 and 2 under the ‘lime’  column." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/a1/39/hero_a139f2d5-ff8a-42fb-9462-a7abaf3b7cfe.png" srcset="https://ugc.futurelearn.com/uploads/assets/a1/39/small_hero_a139f2d5-ff8a-42fb-9462-a7abaf3b7cfe.png 320w, https://ugc.futurelearn.com/uploads/assets/a1/39/hero_a139f2d5-ff8a-42fb-9462-a7abaf3b7cfe.png 648w, https://ugc.futurelearn.com/uploads/assets/a1/39/large_hero_a139f2d5-ff8a-42fb-9462-a7abaf3b7cfe.png 729w, https://ugc.futurelearn.com/uploads/assets/a1/39/large_hero_a139f2d5-ff8a-42fb-9462-a7abaf3b7cfe.png 2x"/></p>
<ul>
<li>Selected training sets for 4 runs of boosting - i.e. increase weights for misclassified examples.</li>
<li>The “hard” example Apple appears more frequently in later sets.</li>
</ul>
<p><img alt="Diagram chart - 7 columns horizontally and 6 layers vertically. The 7 columns across are titled ‘Original, Apple, Mango, Orange, Pineapple, Grapes, Lime. The 6 vertical layers starting top to bottom are named: ‘Original, Set 1, Set 2, Set 3, Set 4, Set 5.  The Word ‘Apple’ is highlighted at every point in the diagram. Namely on the top row, at Set 1 under the ‘lime’ Column at Set 2 under the ‘apple and ‘pineapple’ columns’. At set 3 under the ‘Mango, Pineapple and grape’ Columns and at setting 4 under the ‘Apple, Mango, Pineapple and Grape’ Columns" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/e9/fa/hero_e9fa1a4b-8558-41c8-ba8e-229ddbc10db3.png" srcset="https://ugc.futurelearn.com/uploads/assets/e9/fa/small_hero_e9fa1a4b-8558-41c8-ba8e-229ddbc10db3.png 320w, https://ugc.futurelearn.com/uploads/assets/e9/fa/hero_e9fa1a4b-8558-41c8-ba8e-229ddbc10db3.png 648w, https://ugc.futurelearn.com/uploads/assets/e9/fa/large_hero_e9fa1a4b-8558-41c8-ba8e-229ddbc10db3.png 729w, https://ugc.futurelearn.com/uploads/assets/e9/fa/large_hero_e9fa1a4b-8558-41c8-ba8e-229ddbc10db3.png 2x"/></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.12&emsp;Stacking</h2><div class="u-typography-bold-intro">
<p>Stacked Generalization, more commonly known as stacking, is a classifier which uses an ensemble of classifiers whose outputs are subsequently used to create a feature vector for a second classifier stage.</p>
<p>You can take this common heterogeneous approach to explore a set of different models. It is premised on the idea that different machine learning model approaches might work better for different parts of the learning problem, rather than working well for the complete problem. Therefore, you use a bunch of different base learners and the outputs of these form an intermediate prediction. There will be one prediction per model. This then constitutes a set of features which are fed into the second model which uses these to predict the target.</p>
<p>This second model is stacked on top of the first layer as shown, in the figure below.</p>
<p><img alt="Stacked Layer Diagram.  Top Layer box with the wording ‘Training Data (m*n)’ written in the box. This box leads to 4 separate boxes underneath on the next layer. Namely Model 1, Model 2. Model 3 and Model 4. Next layer box has the wording ‘New training set for a second-level model consisting of predictions from First level model’ Arrow leading downwards to the next box named ‘ Second Level Model’ - Arrow leading downwards from this box to the bottom box named ‘Final Prediction’." sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/c0/c3/hero_c0c3bc14-45ef-4af8-9221-f64f30b2f0d3.png" srcset="https://ugc.futurelearn.com/uploads/assets/c0/c3/small_hero_c0c3bc14-45ef-4af8-9221-f64f30b2f0d3.png 320w, https://ugc.futurelearn.com/uploads/assets/c0/c3/hero_c0c3bc14-45ef-4af8-9221-f64f30b2f0d3.png 648w, https://ugc.futurelearn.com/uploads/assets/c0/c3/large_hero_c0c3bc14-45ef-4af8-9221-f64f30b2f0d3.png 729w, https://ugc.futurelearn.com/uploads/assets/c0/c3/large_hero_c0c3bc14-45ef-4af8-9221-f64f30b2f0d3.png 2x"/></p>
<p>Stacking can be computationally expensive for small returns. However, it is a consistently strong approach in producing robust, high-performance machine learning.  If you want to know more about stacking and its use in practice I do encourage you to watch the following short video on <strong>Stacking, How to Win a Data Science Competition: Learn from Top Kagglers</strong> which discusses stacking in the context of data science competitions.</p>
<p></p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<p>In the next step, we review what we have learned in Topic 3.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>3.13&emsp;Review of Topic 3</h2><div class="u-typography-bold-intro">
<p>Congratulations on completing Topic 3.</p>
<p>So, in summary, you should now think of ensemble methods as algorithms, which are in reality a set of individual machine learning algorithms which work together as a committee to produce a single output.</p>
<p>Bagging involves multiple, similar, models with high variances which are averaged to decrease variance. Boosting builds multiple incremental models to decrease the bias, while keeping variance small. We can use meta-classifiers to improve over both to improve performance overall via stacking.</p>
</div><p style="page-break-before: always"><h2>4.1&emsp;Welcome to Topic 4</h2><div class="u-typography-bold-intro">
<p>Hello and welcome to the final topic of this course.</p>
<p>In what I hope is a refreshing break from theory, you will have an opportunity to practise some of your skills with hands-on activities.</p>
<p>We will continue our use of notebooks in Python, but this time we will mix up the platforms a bit with some focus on the use of the Kaggle platform for exploring datasets, practising methods and sharing ideas.</p>
<p>At the end of this topic, you should have put linear and logistic regression to use with reasonably realistic datasets, as well as exploring the power of ensemble methods.</p>
<p><img alt="Statement of funding from Skillnet Ireland stating that this course has been grant-aided by Skillnet Ireland" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/14/0b/hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg" srcset="https://ugc.futurelearn.com/uploads/assets/14/0b/small_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 320w, https://ugc.futurelearn.com/uploads/assets/14/0b/hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 648w, https://ugc.futurelearn.com/uploads/assets/14/0b/large_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 729w, https://ugc.futurelearn.com/uploads/assets/14/0b/large_hero_140bfdc0-2f0f-408d-bf43-4ed1e4240646.jpg 2x"/>]</p>
<div class="video_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.2&emsp;Kaggle</h2><div class="u-typography-bold-intro">
<p>It is hands-on time again and an opportunity to both apply what you have learned, and explore new ideas.</p>
<p>We are not going to abandon Google Colab, and indeed some of our steps this week will revert to Colab. However, to mix things up a little we will also explore <strong>Kaggle</strong> which provides great opportunities for sharing and accessing datasets as well as ideas via notebooks and code.</p>
<p>Let’s begin with Kaggle.</p>
<p><a href="https://www.kaggle.com/">Kaggle</a> is an online community of data scientists and is used for sharing ideas and data, particularly in the context of machine learning.</p>
<p>It is competition-oriented, in the sense that datasets are often provided by companies, and machine learners compete to develop the best solution to the challenge set with the data. This is probably what Kaggle is best known for, but educators find it a wonderful platform for sharing, learning and developing skills.</p>
<p>You can also learn very effectively, in a tutorial-driven way, via the <a href="https://www.kaggle.com/learn/overview">Micro Courses</a> provided by Kaggle, such as:</p>
<ul>
<li><a href="https://www.kaggle.com/learn/python">Python</a></li>
<li><a href="https://www.kaggle.com/learn/intro-to-machine-learning">Intro to Machine Learning</a></li>
<li><a href="https://www.kaggle.com/learn/intermediate-machine-learning">Intermediate Machine Learning</a></li>
<li><a href="https://www.kaggle.com/learn/data-visualization">Data Visualization</a></li>
<li><a href="https://www.kaggle.com/learn/pandas">Pandas</a></li>
<li><a href="https://www.kaggle.com/learn/feature-engineering">Feature Engineering</a></li>
<li><a href="https://www.kaggle.com/learn/deep-learning">Deep Learning</a></li>
<li><a href="https://www.kaggle.com/learn/intro-to-sql">Intro to SQL</a></li>
<li><a href="https://www.kaggle.com/learn/advanced-sql">Advanced SQL</a></li>
<li><a href="https://www.kaggle.com/learn/geospatial-analysis">Geospatial Analysis</a></li>
<li><a href="https://www.kaggle.com/learn/microchallenges">Micro challenges</a></li>
<li><a href="https://www.kaggle.com/learn/machine-learning-explainability">Machine Learning Explainability</a></li>
</ul>
<p>You should make use of these in conjunction with any material you learn here. We will dip into these as required.</p>
<p>This <a href="https://en.wikipedia.org/wiki/Kaggle">Kaggle article</a> provides further information.</p>
<p>Alternatively, you may prefer to watch the following ‘What’s Kaggle?’ YouTube video.</p>
<p></p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<h3 id="register-on-kaggle">Register on Kaggle</h3>
<p>You will need to set up a <a href="https://www.kaggle.com/">Kaggle account</a> to complete the exercises we will be working through in the following steps. Setting up a Kaggle account is very easy. Do spend a little time adding your profile photo and filling out other aspects of your profile that you might want the world to see should you enter Kaggle competitions.</p>
<p><strong>Note:</strong> If you get particularly excited by the machine learning competitions in Kaggle you can try your hand in further commercial competitions via websites such as <a href="https://www.innocentive.com/">Innocentive</a>. Also, you can investigate the many other competing websites that are emerging.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.3&emsp;Kaggle and Kernels</h2><div class="u-typography-bold-intro">
<p>In the previous step, we advised you to register on Kaggle.</p>
<p>Now that you have set up a Kaggle account we would like you to spend some time familiarising yourself with what is on offer on the Kaggle site.</p>
<p>Watch the following ‘Getting Started on Kaggle: A quick tour’ video. This video provides a tour of the Kaggle platform and takes learners briefly through datasets, <strong>Kernels</strong> (Kaggle’s online data analytics environment) and the <strong>Learn</strong> platform, where you’ll find Kaggle’s education resources.</p>
<p></p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<h3 id="kaggle-jargon">Kaggle jargon</h3>
<p>If you are new to Kaggle, you may be confused by some of the vocabulary used on the site.</p>
<p>The following video will help you familiarise yourself with Kaggle jargon.</p>
<p></p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<p>Finally, we would like you to watch the following ‘Getting Started on Kaggle: Python coding in Kernels’ video which demonstrates how to use Kaggle’s notebook environment.</p>
<p></p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.4&emsp;Kernel practical</h2><div class="u-typography-bold-intro">
<p>In this step you have an opportunity to practise on Kaggle.</p>
<p>To begin, you should watch the following video clip which demonstrates how to write code on a dataset hosted on Kaggle and explains the basic Kernel concepts.</p>
<p></p><div><div class="u-responsive-embed">

</div>
<p class="u-italic">
  This is an additional video, hosted on YouTube.
</p>
</div>
<h3 id="introduction-to-machine-learning-on-kaggle-learn">Introduction to Machine Learning on Kaggle Learn</h3>
<p>To get you started coding on Kaggle, we recommend that you work through <a href="https://www.kaggle.com/learn/intro-to-machine-learning">Introduction to Machine Learning</a>. This is a 3 hour tutorial written by Dan Becker on Kaggle Learn.</p>
<p>In course 2, <strong>Bayesian and Information Based Learning</strong>, you will recall that we introduced <a href="https://www.futurelearn.com/courses/bayesian-and-information-based-learning/1/steps/662145">Decision Trees</a>. Dan Becker introduces the Decision Tree in lesson 3. In this case it is being used for regression, so this is a great opportunity for you to try this out. It is clear that there is not a significant amount of information on the theory and concepts behind the decision tree in the material given, but you already have that from this course. What is most valuable about Dan’s course is that you are given a very effective introduction to the nuts and bolts of implementing the decision tree with real data using Pandas in a notebook direct in your browser.</p>
<p>In lesson 1, there is a great hands on exercise which encourages you to participate in the Kaggle discussion thread and thereby partake in the Kaggle community discussion. So join in and converse with your fellow Kagglers!</p>
<p>Lesson 6 is also very exciting as here you can see ensembles in action in the form of the Random Forests approach. Here again, we see Random Forest <em>Regression</em> rather than <em>Classification</em>, so we are adding to our experiences here in terms of regression approaches.</p>
<p>Once you have completed the “Introduction to Machine Learning” Kaggle practical, it is time to take a break!</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.5&emsp;Linear Regression and Colab</h2><div class="u-typography-bold-intro">
<p>We are now going to look at Linear Regression.</p>
<p>In this step we are going to leave <strong>Kaggle</strong> and revert to <strong>Colab</strong>. We will again use Jake VanderPlas’ wonderful book <a href="https://jakevdp.github.io/PythonDataScienceHandbook/"><strong>Python Data Science Handbook</strong></a>, chapter 5.</p>
<p>In this step we want you to work through the <a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.06-Linear-Regression.ipynb">Linear Regression</a> example set by Jake VanderPlas.</p>
<p>As you go through the cells don’t just blindly click through them. Think about them. For example, the first cell includes some standard imports such as Matplotlib and Seaborn. Can you recall what they were for?</p>
<p>It is worth noting that the third cell uses SciKit Learn’s Linear Regression estimator and it immediately produces a great fit. But please experiment here. Consider looking at some of the online resources around SciKit Learn, particular the information contained in the following  example,  <a href="https://scikit-learn.org/stable/modules/linear_model.html"><strong>Linear Models</strong></a>.</p>
<p>Also of note, is the <a href="https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py">Linear Regression</a> example on that page. Notice at the bottom of that link you will see something called “Launch Binder” – Try clicking on that. Neat eh? Another world of interactive machine learning resources! It will look like the image below.</p>
<p><img alt="Screen Grab of Launch Binder" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/32/1e/hero_321ead66-60bb-4ed4-a892-b583a659e309.JPG" srcset="https://ugc.futurelearn.com/uploads/assets/32/1e/small_hero_321ead66-60bb-4ed4-a892-b583a659e309.JPG 320w, https://ugc.futurelearn.com/uploads/assets/32/1e/hero_321ead66-60bb-4ed4-a892-b583a659e309.JPG 648w, https://ugc.futurelearn.com/uploads/assets/32/1e/large_hero_321ead66-60bb-4ed4-a892-b583a659e309.JPG 729w, https://ugc.futurelearn.com/uploads/assets/32/1e/large_hero_321ead66-60bb-4ed4-a892-b583a659e309.JPG 2x"/></p>
<p>You should now return to VanderPlas’ <a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.06-Linear-Regression.ipynb">Linear Regression</a></p>
<p>As you work through this notebook you will get to the section called <strong>Feature Engineering</strong> which I have crudely underlined in the figure below. There is a link to a notebook through the link “Feature Engineering”</p>
<p><img alt="Homepage of Linear regression Colab Notebook" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/5a/aa/hero_5aaacc36-3552-4836-ba46-f55e45750ba6.png" srcset="https://ugc.futurelearn.com/uploads/assets/5a/aa/small_hero_5aaacc36-3552-4836-ba46-f55e45750ba6.png 320w, https://ugc.futurelearn.com/uploads/assets/5a/aa/hero_5aaacc36-3552-4836-ba46-f55e45750ba6.png 648w, https://ugc.futurelearn.com/uploads/assets/5a/aa/large_hero_5aaacc36-3552-4836-ba46-f55e45750ba6.png 729w, https://ugc.futurelearn.com/uploads/assets/5a/aa/large_hero_5aaacc36-3552-4836-ba46-f55e45750ba6.png 2x"/></p>
<p>This useful <a href="https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.04-Feature-Engineering.ipynb">notebook</a> pulls together, in practical form, many of the feature engineering ideas we look at in an earlier course. It is a great time to pull this altogether, and does not take long. It will fill in a practical gap in your knowledge. Don’t skip it.</p>
<p>Once you have done that Feature Engineering book return to the Linear Regression notebook. At this stage you should proceed to complete the Polynomial and Gaussian Basis functions cells and, if you like, you can take a breather at this point.</p>
<p>We will continue on with our Linear Regression notebook in the next step.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.6&emsp;Linear regression notebook</h2><div class="u-typography-bold-intro">
<p>We will now return to our <a href="https://drive.google.com/open?id=1b8PsKpatp8Hgd1FOGEh0OEbVS2VEIcIq">Linear Regression</a> notebook.</p>
<p>We recommend that you run through your cells again, refreshing your own brain cells as you go until you reach the Regularization section. At this point you should look over your theory on regularization again and perhaps take a look at the excellent notes on <a href="https://scikit-learn.org/stable/modules/linear_model.html">Regularized regression methods</a> available on Scikit-Learn.</p>
<p>Returning to your <a href="https://drive.google.com/open?id=1h7R349rz8Gp1CqOAdQ4nGfP4fqrIogi0">Linear Regression</a> notebook, you should run the Gaussian example in <strong>Regularization</strong> and proceed to the <strong>Ridge Regression</strong> section. Make sure you don’t skip over any hidden cells. Click on these to expand them and run the cells. Experiment with the value <script type="math/tex">\alpha</script>. Make it very large and see what happens. Now, make it several orders of magnitude smaller. I hope you understand what is happening here.</p>
<p>Next, you should look at <strong>Lasso Regression</strong>. This has a different norm and results in many weights being zero and therefore sparse models. As you might imagine, this is useful where we want to reduce the size of our models for computational reasons.</p>
<p>Finally, we have a nice example in this notebook where Jake VanderPlas predicts cycling traffic based on weather data. If you are running the notebook in your browser you might have some problems with the missing BicycleWeather.csv file? However, if you go to Jake’s Github you will find that file and you can upload it to your Colab instance. Try to problem solve this yourself.</p>
<p>The next step is Logistic Regression!</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.7&emsp;Linear regression and TensorFlow</h2><div class="u-typography-bold-intro">
<p>We are now going to look at Logistic Regression.</p>
<p>We will do this in Colab. However, rather than just using SciKit-Learn, we will use TensorFlow.</p>
<h3 id="tensorflow">TensorFlow</h3>
<p>TensorFlow is a library of super-optimised tools and utilities for deep learning - primarily through Keras (which we should come across in the final course in our series) - but it does support the implementation of any machine learning model. We will use it more intensively in a later course but now is a good time just to try it out relatively painlessly. I say relatively, as we are only going to explore a Google provided notebook on <a href="https://drive.google.com/open?id=1pEy95JSeaybm-69H3aepckecpoOBja6T">Logistic Regression</a> which just so happens to use TensorFlow for implementation.</p>
<p>Let’s take a look through it.</p>
<p><img alt="TensorFlow" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/0a/76/hero_0a76a799-35c0-44f2-8b92-d017c6ba617a.png" srcset="https://ugc.futurelearn.com/uploads/assets/0a/76/small_hero_0a76a799-35c0-44f2-8b92-d017c6ba617a.png 320w, https://ugc.futurelearn.com/uploads/assets/0a/76/hero_0a76a799-35c0-44f2-8b92-d017c6ba617a.png 648w, https://ugc.futurelearn.com/uploads/assets/0a/76/large_hero_0a76a799-35c0-44f2-8b92-d017c6ba617a.png 729w, https://ugc.futurelearn.com/uploads/assets/0a/76/large_hero_0a76a799-35c0-44f2-8b92-d017c6ba617a.png 2x"/></p>
<h3 id="training-and-validation-sets">Training and validation sets</h3>
<p>There are a few things you may not be familiar with just yet; For example, and most significantly, the idea of a training set and a validation set. The idea of taking our available data and breaking it into two disjoint sets of training data and validation data is conceptually simple but subtle. What we are trying to do is use as much of the data as possible to build a model, with the assumption that every training data point is yielding some information about a suitable model. However, we need to balance this with the requirement that the model makes good predictions for data it has not been trained on. The more of the available data we set aside for this, the better the estimate we can make of the final model’s performance on future data, i.e. the useful thing we want our prediction algorithm to do after all!</p>
<p>Therefore, some of the available labelled data in a supervised learning task are set aside for training the model and some are reserved for testing the trained model. This is the basic idea behind training and validation sets. We will explore this in much more depth in the next course, as it is a very important topic.</p>
<p>Also, note that Tensorflow has its own implementation of machine learning algorithms which are packaged differently to what you have seen in SciKit-Learn. Even the degree of documentation is quite different. For example, within this Colab notebook, you use TensorFlow’s LinearRegressor class. Take a look at its documentation <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor">here</a>. It is less user-friendly than what you saw for SciKit-Learn <a href="https://scikit-learn.org/stable/modules/linear_model.html">here</a>.  You can, therefore, understand why we start with SciKit-Learn, right?</p>
<p>Please work through this notebook and complete Task 2 within the notebook. This should bring you to output as per the figure below.</p>
<p><img alt="A graph showing the Log Loss of both training and validation data" sizes="(min-width: 1695px) 729px, (min-width: 680px) 648px, 320px" src="https://ugc.futurelearn.com/uploads/assets/5f/c0/hero_5fc0925b-8af3-4d13-99ff-657336ca20d8.png" srcset="https://ugc.futurelearn.com/uploads/assets/5f/c0/small_hero_5fc0925b-8af3-4d13-99ff-657336ca20d8.png 320w, https://ugc.futurelearn.com/uploads/assets/5f/c0/hero_5fc0925b-8af3-4d13-99ff-657336ca20d8.png 648w, https://ugc.futurelearn.com/uploads/assets/5f/c0/large_hero_5fc0925b-8af3-4d13-99ff-657336ca20d8.png 729w, https://ugc.futurelearn.com/uploads/assets/5f/c0/large_hero_5fc0925b-8af3-4d13-99ff-657336ca20d8.png 2x"/></p>
<p>You should now be in a good position regarding Logistic Regression. It is not necessary to work through Task 3, as we have not yet covered ROC yet, but if you are feeling adventurous give it a go. The concepts involved are intuitive.</p>
<p>If you have gone through the steps in this topic and immersed yourself in:</p>
<ul>
<li>exploring the notebooks;</li>
<li>breaking things;</li>
<li>fixing things; and</li>
<li>generally messing around with the code;</li>
</ul>
<p>you will have built up some practical skills which you should now be able to put to use in your assignment. Details about this assignment appeared in the second course, <strong>Bayesian and Information Based Learning</strong>. You can also get details on this assignment on LOOP <a href="https://loop.dcu.ie/">here</a>.</p>
<p>Hopefully, you are now well prepared for the next course - <strong>Similarity-Based Approaches and Evaluation Metrics.</strong></p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.8&emsp;Review of Topic 4</h2><div class="u-typography-bold-intro">
<p>Congratulations on completing Topic 4.</p>
<p>In what I hope was a refreshing break from theory, you had an opportunity to practise some of your skills with hands-on activities.</p>
<p>We continued our use of notebooks in Python, but this time we spent a considerable amount of time on Kaggle. Kaggle is very competition-oriented which is a motivating way to learn. This sort of competitive machine learning approach is behind our assignments too and it is a great way to generate our own personal “loss function” and push ourselves on to improve our skills. We will continue this pattern of hands-on practical skills across all our courses.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div><p><h2>4.9&emsp;Next Course</h2><div class="u-typography-bold-intro">
<p>In the next course, we will focus on two new algorithms which are based to some extent on the idea of measurement of similarity.</p>
<p>One method, in particular, called Support Vector Machines, develops naturally from some of the ideas we looked at when considering logistic regression. It is a very powerful approach and a great technique to be able to understand and deploy.</p>
<p>The other method, k-Nearest Neighbours, is very different from what you have seen to date but is also very intuitive to understand so you will have no conceptual problems with it I am sure.</p>
<p>We will also, and this is important, spend some useful time, examining evaluation ideas for machine learning algorithms. While we have used concepts related to performance and evaluation throughout the course to date, we had not spent any considerable time examining the issue in detail. We will rectify this in the next course - <strong>Similarity-Based Approaches and Evaluation Metrics</strong>.</p>
<div class="body_copyright">
<p>© Dublin City University</p>
</div>
</div></body></html>